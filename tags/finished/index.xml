<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Finished | BIG TU Wien</title><link>https://big.tuwien.ac.at/tags/finished/</link><atom:link href="https://big.tuwien.ac.at/tags/finished/index.xml" rel="self" type="application/rss+xml"/><description>Finished</description><generator>Source Themes Academic (https://sourcethemes.com/academic/)</generator><language>en-us</language><copyright>© by Business Informatics Group (BIG), TU Wien, 2020</copyright><lastBuildDate>Tue, 19 May 2020 12:38:56 +0000</lastBuildDate><image><url>https://big.tuwien.ac.at/images/logo_hub5239f9a002a777103d549dfca2a9392_18033_300x300_fit_lanczos_2.png</url><title>Finished</title><link>https://big.tuwien.ac.at/tags/finished/</link></image><item><title>An Enabler for Real-time Business Intelligence</title><link>https://big.tuwien.ac.at/project/archive/an-enabler-for-real-time-business-intelligence/</link><pubDate>Tue, 19 May 2020 12:38:56 +0000</pubDate><guid>https://big.tuwien.ac.at/project/archive/an-enabler-for-real-time-business-intelligence/</guid><description>&lt;h3 id="topic">Topic&lt;/h3>
&lt;p>The dynamic business environment of many organizations require to monitor their business, IT and organizational processes in real-time in order to proactively respond to exceptions and to take advantage of time-sensitive business opportunities. The ability to sense and interpret events about a changing business environment or customer needs require an event-driven IT infrastructure for making fast and well-informed decisions and putting them into action. The proposed project aims to build an infrastructure that can efficiently and seamlessly meet the demanding requirements of business event stream-based analytical applications. We introduce Sense &amp;amp; Respond loops that support a complete Business Intelligence process to sense, interpret, predict, automate and respond to business processes and aim to decrease the time it takes to make the business decisions. Our approach enables real-time analytics across corporate business processes, notifies the business of actionable recommendations or automatically triggers business operations, effectively closing the gap between Business Intelligence systems and business processes. We propose a ZELESSA system for executing and managing Sense &amp;amp; Respond loops and illustrate our approach with a transportation service monitoring scenario.&lt;/p>
&lt;h3 id="term">Term&lt;/h3>
&lt;p>01.01.2006 - 30.06.2007&lt;/p>
&lt;h3 id="partner">Partner&lt;/h3>
&lt;ul>
&lt;li>
&lt;a href="http://www.big.tuwien.ac.at/projects/SENACTIVE%20IT%20-%20Dienstleistungs%20GmbH" target="_blank" rel="noopener">SENACTIVE IT – Dienstleistungs GmbH&lt;/a>&lt;/li>
&lt;/ul></description></item><item><title>Vienna Informatics Living Lab</title><link>https://big.tuwien.ac.at/project/archive/vienna-informatics-living-lab/</link><pubDate>Tue, 19 May 2020 12:38:55 +0000</pubDate><guid>https://big.tuwien.ac.at/project/archive/vienna-informatics-living-lab/</guid><description>&lt;h3 id="topic">Topic&lt;/h3>
&lt;p>Mit dem Vienna Informatics Living Lab macht die Fakultät für Informatik einen Brückenschlag zu Schulen und baut ab Herbst 2018 ein systematisches Angebot auf: Schulklassen und Lehrpersonen können an kostenfreien, didaktisch abgestimmten Workshops zu aktuellen und vielfältigen Informatikthemen teilnehmen. Als erste Ausbaustufe wird die 
&lt;a href="https://abenteuer.informatik.tuwien.ac.at/" target="_blank" rel="noopener">permanente Ausstellung Abenteuer Informatik&lt;/a> im Institutsgebäude Favoritenstr. 7-9 installiert. 40 Ausstellungstafeln mit 20 Experimentierplätzen machen spannende Themen wie Binärdarstellung, Informationsdarstellung, effiziente Algorithmen oder Grenzen der Berechenbarkeit interaktiv und hands-on erlebbar. Im aktuellen Projekt werden zielgruppengerechte Workshops entwickelt und fachliche Unterlagen erstellt, ein Stakeholder-Netzwerk aufgebaut, breit angelegt intensive Werbung betrieben und die Ausstellung feierlich eröffnet. Das Lab bietet wichtige fachliche Impulse für die Jugend, erlaubt einen niederschwelligen Zugang zur TU Wien und vermittelt Informatik als zukunftsweisend, spannend und vielfältig. Es weckt Begeisterung, Neugier und Interesse – bei Mädchen gleichermaßen wie Burschen.&lt;/p>
&lt;h3 id="term">Term&lt;/h3>
&lt;p>01.08.2018 - 31.07.2019&lt;/p>
&lt;h3 id="funding">Funding&lt;/h3>
&lt;p>Wirtschaftsagentur Wien. Ein Fonds der Stadt Wien. Antrags-ID: 2337865&lt;/p>
&lt;h3 id="partner">Partner&lt;/h3>
&lt;p>TU Darmstadt, Prof. Dr. Jens Gallenbacher&lt;/p></description></item><item><title>Web of Needs INfrastructure</title><link>https://big.tuwien.ac.at/project/archive/web-of-needs-infrastructure/</link><pubDate>Tue, 19 May 2020 12:38:55 +0000</pubDate><guid>https://big.tuwien.ac.at/project/archive/web-of-needs-infrastructure/</guid><description>&lt;h3 id="topic">Topic&lt;/h3>
&lt;p>Der wirtschaftlich genutzte Teil des World Wide Web leidet an einer fundamentalen Asymmetrie. Während eine große Zahl an kommerziellen Angeboten online verfügbar ist, sind die Bedürfnisse der KonsumentInnen nur in seltenen Fällen explizit repräsentiert. Daher ist der am häufigsten angewandte Prozess, der KonsumentInnen mit AnbieterInnen verbindet, die Web-Suche. Wir entwickeln im vorliegenden Projekt eine Infrastruktur, die es KonsumentInnen ermöglichen soll, ihre Bedürfnisse im Web so zu publizieren, dass AnbieterInnen in einem semi-automatischen Prozess mit ihnen interagieren können. Dadurch sollen die Notwendigkeit der manuellen Web-Suche reduziert und neue, disruptive Applikationen ermöglicht werden.&lt;/p>
&lt;h3 id="term">Term&lt;/h3>
&lt;p>01.07.2012 - 30.06.2014&lt;/p>
&lt;h3 id="funding">Funding&lt;/h3>
&lt;p>Funded by the Österreichische Forschungsförderungsgesellschaft mbH (FFG) under project number 836531.&lt;/p></description></item><item><title>Women's Postgraduate College for Internet Technologies</title><link>https://big.tuwien.ac.at/project/archive/womens-postgraduate-college-for-internet-technologies/</link><pubDate>Tue, 19 May 2020 12:38:55 +0000</pubDate><guid>https://big.tuwien.ac.at/project/archive/womens-postgraduate-college-for-internet-technologies/</guid><description>&lt;h3 id="topic">Topic&lt;/h3>
&lt;p>WIT stands for Women’s Postgraduate College for Internet Technologies (WIT), and is the only programme of its kind in Austria. WIT is a five-year programme and gets financed by the Austrian government and the European Union. WIT offers 8 PhD positions for women in the area of internet technology and builds up a special support programme to encourage young girls and women to study computer science.&lt;/p>
&lt;p>More information:
&lt;a href="http://wit.tuwien.ac.at" target="_blank" rel="noopener">http://www.wit.at/&lt;/a>&lt;/p>
&lt;h3 id="term">Term&lt;/h3>
&lt;p>01.01.2003 - 31.12.2007&lt;/p></description></item><item><title>V-Code Hot Code Reload</title><link>https://big.tuwien.ac.at/project/archive/v-code-hot-code-reload/</link><pubDate>Tue, 19 May 2020 12:38:54 +0000</pubDate><guid>https://big.tuwien.ac.at/project/archive/v-code-hot-code-reload/</guid><description>&lt;h3 id="topic">Topic&lt;/h3>
&lt;h3 id="term">Term&lt;/h3>
&lt;p>01.03.2018 - 30.09.2018&lt;/p></description></item><item><title>V-Code Hot Code Reload Extended</title><link>https://big.tuwien.ac.at/project/archive/v-code-hot-code-reload-extended/</link><pubDate>Tue, 19 May 2020 12:38:54 +0000</pubDate><guid>https://big.tuwien.ac.at/project/archive/v-code-hot-code-reload-extended/</guid><description>&lt;h3 id="topic">Topic&lt;/h3>
&lt;p>Das Ziel des Projektes ist es, ein Konzept zur partiellen Aktualisierung von QML (Qt Modeling Language) Programmen zur Laufzeit auszuarbeiten, welches es ermöglicht, QML Programminstanzen während der Laufzeit entsprechend der Programmänderungen zu aktualisieren. Dabei wird in diesem Projekt als Anwendungsgebiet die Entwicklung jeglicher Software mittels QML betrachtet. Die Anwendbarkeit des ausgearbeiteten Konzeptes soll an Hand eines Prototyps und Fallstudien demonstriert und evaluiert werden.&lt;/p>
&lt;p> &lt;/p>
&lt;p>Zur Ausarbeitung des Konzepts werden Typ-Instanz Co-Evolutionstheorien aus dem Gebiet der modellgetriebenen Softwareentwicklung, welche von der Business Informatics Group an der TU Wien bereits in der Vergangenheit untersucht wurden, auf QML übertragen. Dies umfasst die Definition der Konformitätsbeziehung zwischen QML Programmen und QML Programminstanzen, die Klassifizierung von möglichen QML Programmcodeänderungen und ihre Auswirkungen auf laufende QML Programminstanzen, sowie die Definition von Programm-Instanz Co-Evolutionsoperationen (in Folge als Migrationsregeln bezeichnet).&lt;/p>
&lt;h3 id="term">Term&lt;/h3>
&lt;p>01.10.2018 - 30.04.2019&lt;/p>
&lt;h3 id="funding">Funding&lt;/h3>
&lt;p>V-Play GmbH&lt;/p>
&lt;h3 id="partner">Partner&lt;/h3>
&lt;p>V-Play GmbH&lt;/p></description></item><item><title>End-User Based Web Augmentation Models</title><link>https://big.tuwien.ac.at/project/archive/end-user-based-web-augmentation-models/</link><pubDate>Tue, 19 May 2020 12:38:53 +0000</pubDate><guid>https://big.tuwien.ac.at/project/archive/end-user-based-web-augmentation-models/</guid><description>&lt;h3 id="topic">Topic&lt;/h3>
&lt;p>Immersed in social and mobile Web, users are expecting personalized browsing experiences, based on their needs, goals, and preferences. This may be complex since the users’ Web navigation usually implies several (related) Web applications. A very popular technique to tackle this challenge isWeb augmentation. Previously, we presented an approach to orchestrate user tasks over multiple websites, by recording &amp;amp; replaying so-called procedures. While the development of procedures is supported by end-users, their maintenance and composition with other services is currently a major challenge. To tackle these limitations, we argue for recording &amp;amp; replaying procedures in an end-user based fashion but having an explicit model representation of the procedures as well. For this purpose, we propose to follow a modeling by-demonstration approach, i.e., the tasks to be automated are demonstrated by the user and from these demonstrations models are inferred. In this proposed project VAMOS (enduser driVen web AugmentationMOdelS), we plan to develop an enhanced version of our modeling language for Web augmentation tasks, a Web browsers based front-end to allow the creation and maintenance of Web augmenters, as well as integration means with traditional Web engineering methods, such as hypertext modeling languages, UML, and the emerging standard IFML. The methodology for evaluating the proposed approach builds on three major pillars. First, it will be implemented as a proof-of-concept prototype as a Firefox Plug-in. Second, the prototype will be applied in case studies using real-world examples, and third, it will be applied in an empirical study with students from our Web engineering course at the Vienna University of Technology (around 250 students every year) to show its usability.&lt;/p>
&lt;h3 id="term">Term&lt;/h3>
&lt;p>01.03.2015 - 28.02.2017&lt;/p>
&lt;h3 id="funding">Funding&lt;/h3>
&lt;p>Funded by the Austrian agency for international mobility and cooperation in education, science and research (OeAD) under grand number AR 13/2015.&lt;/p></description></item><item><title>End-User Driven Web Augmentation Models</title><link>https://big.tuwien.ac.at/project/archive/end-user-driven-web-augmentation-models/</link><pubDate>Tue, 19 May 2020 12:38:53 +0000</pubDate><guid>https://big.tuwien.ac.at/project/archive/end-user-driven-web-augmentation-models/</guid><description>&lt;h3 id="topic">Topic&lt;/h3>
&lt;p>Immersed in social and mobile Web, users are expecting personalized browsing experiences, based on their needs, goals, and preferences. This may be complex since the users’ Web navigation usually implies several (related) Web applications. A very popular technique to tackle this challenge isWeb augmentation. Previously, we presented an approach to orchestrate user tasks over multiple websites, by recording &amp;amp; replaying so-called procedures. While the development of procedures is supported by end-users, their maintenance and composition with other services is currently a major challenge.&lt;/p>
&lt;p>To tackle these limitations, we argue for recording &amp;amp; replaying procedures in an end-user based fashion but having an explicit model representation of the procedures as well. For this purpose, we propose to follow a modeling by-demonstration approach, i.e., the tasks to be automated are demonstrated by the user and from these demonstrations models are inferred. In this proposed project VAMOS (enduser driVen web AugmentationMOdelS), we plan to develop an enhanced version of our modeling language for Web augmentation tasks, a Web browsers based&lt;br>
front-end to allow the creation and maintenance of Web augmenters, as well as integration means with traditional Web engineering methods, such as hypertext modeling languages, UML, and the emerging standard IFML.&lt;/p>
&lt;h3 id="term">Term&lt;/h3>
&lt;p>01.05.2015 - 30.06.2017&lt;/p>
&lt;h3 id="funding">Funding&lt;/h3>
&lt;p>&lt;span class="input bigWidth">Österreichischer Austauschdienst (ÖAD)&lt;/span>&lt;/p>
&lt;h3 id="partner">Partner&lt;/h3>
&lt;div class="facility-header-info lf">&lt;p>&lt;span title="National University of La Plata">National University of La Plata, Argentina&lt;/span>&lt;/p>&lt;/div></description></item><item><title>A Framework for Model Transformations on Petri Nets in Color</title><link>https://big.tuwien.ac.at/project/archive/a-framework-for-model-transformations-on-petri-nets-in-color/</link><pubDate>Tue, 19 May 2020 12:38:52 +0000</pubDate><guid>https://big.tuwien.ac.at/project/archive/a-framework-for-model-transformations-on-petri-nets-in-color/</guid><description>&lt;h3 id="topic">Topic&lt;/h3>
&lt;p>Model transformations play an important role in software engineering in general and in the area of model-driven engineering in particular, representing the key mechanisms for model translations (e.g., translating an ER model into a UML class model), model augmentations (e.g., weaving aspects into a UML class model), and model alignments (e.g., mapping a content model to its GUI view), to mention just a few. Several kinds of dedicated model transformation languages have emerged during the last years, which allow specifying and executing transformations between source and target metamodels and their corresponding models, respectively. However, none of these languages, not even the QVT-standard proposed by the OMG, became generally accepted as a state-of-the-art technology for model transformations. This rare adoption of model transformation languages in practice is due to several reasons. First, existing model transformation languages do not provide appropriate abstraction mechanisms to deal with the complexity of structural heterogeneities of different metamodels. Second, they lack suitable reuse mechanisms in order to reduce the high and error-prone effort of specifying recurring transformations. And finally, these languages exhibit an inherent impedance mismatch between the specification and the execution of model transformations in terms of a one-to-many derivation of concepts, thus hampering both, understandability and debuggability. The aim of this project is to establish a framework called TROPIC (Transformations on Petri Nets in Color) for developing model transformations which tackles these limitations. First, TROPIC allows to specify model transformations on different abstraction levels, providing both a declarative mapping language based on UML 2 component diagrams which hides implementation details, and derived from that, an executable transformation language using Coloured Petri Nets. Second, TROPIC facilitates reusability by providing an initial library of generic transformation operators which can be bound to arbitrary metamodels and by allowing to extend this library on demand with new, user-defined, transformation operators, optionally composed out of already existing ones. Finally, TROPIC overcomes the impedance mismatch by supporting a dedicated runtime model in terms of Coloured Petri Nets, allowing for a homogeneous representation of all transformation artefacts (i.e., models, metamodels and the transformation logic itself), which fosters understandability and debuggability of model transformations. The methodology for evaluating the proposed framework builds on three major pillars. First, appropriate case studies for transforming heterogeneous structural as well as behavioural models will be set up and implemented with different existing model transformation languages, including TROPIC, the results being evaluated on basis of a suitable subset of the ISO 9126 software quality model. Second, the findings of these case studies will be further critically reflected by conducting an empirical study with students from our model engineering courses (around 200 master students every year). Third, dedicated workshops will be held together with internationally renowned inventors of other model transformation languages to additionally review the value of our proposed framework.&lt;/p>
&lt;p>More information: &lt;a href="http://www.modeltransformation.net/">http://www.modeltransformation.net/&lt;/a>&lt;/p>
&lt;h3 id="term">Term&lt;/h3>
&lt;p>01.03.2009 - 31.08.2012&lt;/p>
&lt;h3 id="funding">Funding&lt;/h3>
&lt;p>Austrian Science Fund (FWF) under grant P21374-N13&lt;/p>
&lt;h3 id="partner">Partner&lt;/h3>
&lt;ul class="partnerList">&lt;li>&lt;a href="http://www.daimi.au.dk">University of Aarhus, Dänemark&lt;/a>&lt;/li>&lt;li>&lt;a href="http://www.es.tu-darmstadt.de/">Darmstadt University of Technology, Deutschland&lt;/a>&lt;/li>&lt;li>&lt;a href="http://www.jku.at/">Johannes Kepler Universität Linz, Österreich&lt;/a>&lt;/li>&lt;li>&lt;a href="http://www.univ-nantes.fr">Université de Nantes, Frankreich&lt;/a>&lt;/li>&lt;/ul></description></item><item><title>Creating a Data Mart for Floating Car Data</title><link>https://big.tuwien.ac.at/project/archive/creating-a-data-mart-for-floating-car-data/</link><pubDate>Tue, 19 May 2020 12:38:52 +0000</pubDate><guid>https://big.tuwien.ac.at/project/archive/creating-a-data-mart-for-floating-car-data/</guid><description>&lt;h3 id="topic">Topic&lt;/h3>
&lt;p>With the number of vehicles, both private and commercial, in urban areas steadily increasing, accurate traffic information becomes an increasingly important commodity A change in transport policy, e.g., increased use of public transport and efficient inter-modal transport, will only have a medium to long-term effect on improving the traffic situations in inner-city areas. To create high-quality content for traffic management applications and mobility services, reliable and inexpensive real-time traffic is essential. The TRACK&amp;amp;TRADE project relies on floating car data (FCD) to solve a number of well-known problems generating traffic content. While conventional traffic data collection systems have a high infrastructure maintenance and communication expense, exploits the FCD approach synergies with existing GPS-based fleet disposition systems. The scope of the project is to develop an FCD data mart that allows for the collection and integration of FCD data from as many data suppliers as possible. In turn, the data mart will supply aggregated datasets as well as valued-added services. Services include the provision of maps visually illustrating travel times and the provision of current and predicted travel times for parts of the road network. These services will be provided using XML and Web services and should simplify the creation of more complex services such routing and navigation as well as traffic forecasts. Trading FCD data and the provision of related services would serve two main purposes. (i) It creates an additional income stream for the data producers from an otherwise worthless resource and (ii) given that such data becomes generally available, it allows for the provision of improved traffic information services through a series of more or less technological means. With an increasing number of commercial vehicles (e.g., taxi fleets) being equipped with GPS, a successful business case for the FCD technology can be demonstrated.&lt;/p>
&lt;p>More information: &lt;a href="http://www.trackandtrade.org">http://www.trackandtrade.org&lt;/a>&lt;/p>
&lt;h3 id="term">Term&lt;/h3>
&lt;p>01.10.2006 - 30.09.2008&lt;/p>
&lt;h3 id="partner">Partner&lt;/h3>
&lt;ul class="partnerList">&lt;li>&lt;a href="http://www.cti.gr/">Research Academic Computer Technology Institute&lt;/a>&lt;/li>&lt;li>&lt;a href="http://www.talent.gr/">Talent S. A.&lt;/a>&lt;/li>&lt;li>&lt;a href="http://www.geomatics.gr/">Geomatics&lt;/a>&lt;/li>&lt;li>&lt;a href="http://emphasisnet.gr/">Emphasis Telematics&lt;/a>&lt;/li>&lt;li>&lt;a href="http://wigeogis.at/">WIGeoGIS&lt;/a>&lt;/li>&lt;li>&lt;a href="http://www.greenway-systeme.com/">GreenWay Systeme&lt;/a>&lt;/li>&lt;li>&lt;a href="http://www.dlr.de/">Deutsches Zentrum für Luft- und Raumfahrt&lt;/a>&lt;/li>&lt;li>&lt;a href="http://www.tuwien.ac.at">Technische Universität Wien&lt;/a>&lt;/li>&lt;/ul></description></item><item><title>A Generic White-Box Testing Framework for Model Transformations</title><link>https://big.tuwien.ac.at/project/archive/a-generic-white-box-testing-framework-for-model-transformations/</link><pubDate>Tue, 19 May 2020 12:38:51 +0000</pubDate><guid>https://big.tuwien.ac.at/project/archive/a-generic-white-box-testing-framework-for-model-transformations/</guid><description>&lt;h3 id="topic">Topic&lt;/h3>
&lt;p>Model transformations are crucial for the success of Model-Driven Engineering (MDE), comparable in role and importance to compilers for programming languages, allowing to transform models between languages and abstraction levels, e.g., to generate platform-dependent models from platform-independent ones. Given their prominent role in MDE and their increasing use in safety critical areas such as the aviation industry, proper means for testing the correctness of model transformations are inevitable.&lt;/p>
&lt;p>Although first testing frameworks have been proposed, they fall short with respect to the crucial phases of test source model generation and fault localization, and they are typically hardly configurable and tightly coupled to a certain transformation language. Second, apart of these frameworks, first isolated approaches for the phase of test source model generation have been proposed, which, however, rely mostly on black-box testing techniques, thus, incorporating the source metamodels and the requirements, but neglect the transformation definition, which may lead to untested parts of the transformation definition. Finally, means for fault localization are missing, since testing approaches identify the failing of a test case, but miss to provide the failing parts of the transformation definition.&lt;/p>
&lt;p>For tackling these limitations, the aim of this project is to establish a comprehensive testing framework for model transformations called TETRABox (A Generic White-Box TEsting Framework for Model TRAnsformations), whereby we base on the experiences gained in our previous FWF-funded project TROPIC. TETRABox supports all testing phases, ranging from test source model generation to fault localization especially focusing on configurable components. To keep the framework broadly applicable, the envisioned components for testing are independent of a transformation language, allowing new languages to be incorporated by providing a transformation to the common formalism of a control flow graph. Second, to leverage white-box testing, TETRABox allows the automatic generation of test source models on basis of the transformation definition by means of symbolic execution. Finally, for fault localization, oracles offering a dedicated failure trace are employed, which are used to provide an entry point for debugging by slicing techniques.&lt;/p>
&lt;p>The methodology for evaluating the TETRABox framework builds on three major pillars. First, transformations of the ATL model transformation zoo will be systematically tested by means of mutation testing and the results will be compared to existing testing techniques. Second, an empirical study with students from our model engineering courses (around 200 master students every year) will be conducted, whereby errors will be seeded into existing transformations, and the students will have to spot these errors with and without the help of the TETRABox framework. Finally, dedicated workshops will be held with (inter-)national partners.&lt;/p>
&lt;p>More information here: &lt;a href="http://modeltransformation.net/tetrabox/">http://modeltransformation.net/tetrabox/&lt;/a>&lt;/p>
&lt;h3 id="term">Term&lt;/h3>
&lt;p>01.08.2016 - 28.02.2019&lt;/p>
&lt;h3 id="funding">Funding&lt;/h3>
&lt;p>Austrian Science Fund (FWF), grant number P28519-N31&lt;/p></description></item><item><title>TheHiddenU – A Social Nexus for Privacy-Assured Personalisation Brokerage</title><link>https://big.tuwien.ac.at/project/archive/thehiddenu-a-social-nexus-for-privacy-assured-personalisation-brokerage/</link><pubDate>Tue, 19 May 2020 12:38:51 +0000</pubDate><guid>https://big.tuwien.ac.at/project/archive/thehiddenu-a-social-nexus-for-privacy-assured-personalisation-brokerage/</guid><description>&lt;h3 id="topic">Topic&lt;/h3>
&lt;p>Social networks on the Web have seen enormous growth over the past few years reaching now truly widespread adoption. Since every social network is focused on serving specific human needs, social networkers are present in a number of different networks, leading to scattered social content. This restraint view on social content carries the potential pitfall of untargeted services like indiscriminated product offers of service providers, being a major obstacle in generating revenue. This situation is aggravated by the fact that social networkers are particularly reluctant to share social content with service providers – which would be, however, necessary to enable personalization – at least as long as it is obscure and beyond their control, if and how their social content is being exploited. The main goal of our research project TheHiddenU – A Social Nexus for Privacy-Assured Personalization Brokerage is to exploit the encouraging win-win situation between social networkers and service providers with respect to personalization, by inventing semantic-based mechanisms to leverage techniques for integrating, profiling and privatising social content. The innovative character of TheHiddenU stretches over three unique but highly interwoven research goals. Firstly, TheHiddenU aims at providing a single point of access to social networks in terms of an integrated semantic representation of scattered social content by employing a hybrid integration approach for schema level and instance level. Secondly, TheHiddenU foresees semantic-based profiling mechanisms in order to discover the „hidden“ you and brokerage facilities bringing together social networkers and service providers in a controlled way, thus enabling highly personalized services. Thirdly, TheHiddenU focuses on privacy concerns by providing social networkers with awareness and ample control regarding disclosure and usage of their social content. The solutions for these challenges are realized by means of TheHiddenU prototype and provide the technical prerequisites for a brand new, sustainable business model for the Social Web „personalisation brokerage“. The method for evaluating TheHidden builds on three major pillars, comprising experiments, empirical studies, and a case study, which will be conducted in cooperation with our demonstrators. Thus, TheHiddenU will represent a research test bed as well as an industrial showcase for further commercial exploitation.&lt;/p>
&lt;p>More information: &lt;a href="http://www.social-nexus.net/">http://www.social-nexus.net/&lt;/a>&lt;/p>
&lt;h3 id="term">Term&lt;/h3>
&lt;p>01.09.2010 - 31.08.2013&lt;/p>
&lt;h3 id="funding">Funding&lt;/h3>
&lt;p>Funded by the Austrian Federal Ministry of Transport, Innovation and Technology (BMVIT) and FFG under grant FIT-IT-825070.&lt;/p>
&lt;h3 id="partner">Partner&lt;/h3>
&lt;ul class="partnerList">&lt;li>&lt;a href="http://www.jku.at/">Johannes Kepler Universität Linz&lt;/a>&lt;/li>&lt;li>&lt;a href="http://www.netural.com">Netural GmbH&lt;/a>&lt;/li>&lt;/ul></description></item><item><title>Mandantenfähiges ERP System in der Cloud: Ein modellgetriebener Ansatz auf Basis der Resource-Event-Agent Ontologie</title><link>https://big.tuwien.ac.at/project/archive/mandantenfhiges-erp-system-in-der-cloud-ein-modellgetriebener-ansatz-auf-basis-der-resource-event-agent-ontologie/</link><pubDate>Tue, 19 May 2020 12:38:50 +0000</pubDate><guid>https://big.tuwien.ac.at/project/archive/mandantenfhiges-erp-system-in-der-cloud-ein-modellgetriebener-ansatz-auf-basis-der-resource-event-agent-ontologie/</guid><description>&lt;h3 id="topic">Topic&lt;/h3>
&lt;p>Cloud Computing führte in den letzten fünf Jahren zu einem Paradigmenwechsel in der IT-Branche. Über die Cloud werden Rechenkapazität, Datenspeicher, Netzwerkkapazitäten oder auch fertige Software zur Verfügung gestellt. In diesem Projekt adressieren wir die letztere Variante von cloud-basierten Lösungen, welche auch als Software-as-a-Service (SaaS) bekannt ist. In SaaS Lösungen werden Applikationen zentral verwaltet und können von überall aus aufgerufen werden. Die Lösungen bieten eine hohe Verfügbarkeit und automatische, zentrale Sicherung. Der Kunde hat somit immer eine aktuelle Version und kann sich auf das Wesentliche, das Benutzen der Applikation, konzentrieren. Prinzipiell können alle Arten von Software als cloud-basierte Lösung angeboten werden, so auch ERP Systeme. Im Falle von ERP Systemen bedeutet dies, statt eine eigene Instanz der ERP Software an Kunden auszuliefern, wird in der Cloud zentral eine einzelne Instanz des ERP Systems gehostet. Dementsprechend greifen alle Kunden über die Cloud auf diese Instanz zu. Aus diesem Grund ist es von zentraler Bedeutung, dass das ERP System in der Cloud mandantenfähig ist. Ein wesentlicher Aspekt bei ERP Systemen ist die interne Prozessunterstützung und der grundsätzlich brancheneutrale Ansatz. Obwohl auf abstrakter Ebene die Geschäftsprozesse unterschiedlicher Unternehmen sehr ähnlich ablaufen und auf gemeinsamen Kernbausteinen beruhen, sind im Detail die konkreten Ausprägungen von Unternehmen zu Unternehmen sehr unterschiedlich. Daraus folgt, dass eine individuelle und rasche Adaptierung an unterschiedliche Bedürfnisse unterschiedlicher Unternehmen mittels Customizing (Anpassung) zu erfolgen hat. Idealerweise erfolgt diese Anpassung durch Parametrisierung ohne Programmierung. Ziel dieses Projekts ist ein kostengünstiger Ansatz zur unternehmensspezifischen Anpassung eines mandantenfähigen ERP Systems. Die Mandantenfähigkeit stellt in diesem Zusammenhang eine zusätzliche Herausforderung dar, weil zwar für jeden Mandanten individuelle User Interfaces mit individuellen Ausprägungen zur Verfügung gestellt werden, aber alle Mandanten eine gemeinsame Infrastruktur, wie zum Beispiel eine generische Datenbank nutzen sollen. Zum Zweck der unternehmensspezifischen Anpassungen wird ein modellgetriebener Ansatz verfolgt. Das heißt, Standardgeschäftsfälle werden mit Hilfe einer grafischen Modellierungssprache als Referenzmodelle beschrieben. Zudem können mit der grafischen Modellierungssprache unternehmensspezifische Anpassungen der Referenzmodelle vorgenommen werden. Auf Basis dieser Modelle können User Interfaces und Datenbankmappings erzeugt werden. Als Sprache zur Beschreibung der Geschäftsmodelle verwenden wir die REA (Resource-Event-Agent) Ontologie. REA ist eine universelle Sprache, die eindeutige Kommunikation ermöglicht und ein gemeinsames Verständnis für alle am Softwareentwicklungsprozess Beteiligten schafft. Der Projektname REAlist spiegelt einerseits den Bezug zur REA Ontologie wieder und andererseits nimmt er darauf Bezug, dass Auswertungen (Saldenlisten) wie im klassischen ERP erstellt werden können. Wir möchten aber auch betonen, dass wir beim Projekt realistisch bleiben wollen. Es ist klar, dass mit der Anzahl der am Projekt beteiligten Personen innerhalb von 2 Jahren kein ERP System in vollem Funktionalitätsumfang umgesetzt werden kann. Vordergründig geht es im Projekt darum REA Konzepte mittels eines modellgetriebenen Ansatzes auf ein ERP Systems umzulegen und dieses als mandantenfähige SaaS Lösung zu konzipieren.&lt;/p>
&lt;h3 id="term">Term&lt;/h3>
&lt;p>01.09.2013 - 31.08.2015&lt;/p>
&lt;h3 id="funding">Funding&lt;/h3>
&lt;p>Funded by the Österreichische Forschungsförderungsgesellschaft mbH (FFG) under project number 841287.&lt;/p>
&lt;h3 id="partner">Partner&lt;/h3>
&lt;ul>
&lt;li>
&lt;a href="http://www.eventus.at/" target="_blank" rel="noopener">eventus Marketingservice GmbH&lt;/a>&lt;/li>
&lt;/ul></description></item><item><title>Rail track gauging Austrian Federal Railways</title><link>https://big.tuwien.ac.at/project/archive/rail-track-gauging-austrian-federal-railways/</link><pubDate>Tue, 19 May 2020 12:38:50 +0000</pubDate><guid>https://big.tuwien.ac.at/project/archive/rail-track-gauging-austrian-federal-railways/</guid><description>&lt;h3 id="topic">Topic&lt;/h3>
&lt;p>The project SWITCH09 aims at capturing the processes of rail track gauging at the Austrian Federal Railways in a formalized manner. The captured process model facilitates the communication of existing processes between different departments and may be used to detect bottle-necks in the current process flow. The rail track gauging process detects damaged parts of railway tracks and railway track switches in particular. The repair process of the damaged track parts is currently done manually. With the investment in a new maintenance machine the repair process will be done in a semi-automatic manner in the future. Apart from capturing the actual process, the process to-be under consideration of the new maintenance machine shall be captured as well.&lt;/p>
&lt;h3 id="term">Term&lt;/h3>
&lt;p>01.07.2009 - 31.08.2009&lt;/p></description></item><item><title>Feasibility Study: ERP System Based on the Resource-Event-Agent (REA) Ontology</title><link>https://big.tuwien.ac.at/project/archive/feasibility-study-erp-system-based-on-the-resource-event-agent-rea-ontology/</link><pubDate>Tue, 19 May 2020 12:38:49 +0000</pubDate><guid>https://big.tuwien.ac.at/project/archive/feasibility-study-erp-system-based-on-the-resource-event-agent-rea-ontology/</guid><description>&lt;h3 id="topic">Topic&lt;/h3>
&lt;h3 id="term">Term&lt;/h3>
&lt;p>01.11.2012 - 30.04.2013&lt;/p></description></item><item><title>Public Private Interoperability</title><link>https://big.tuwien.ac.at/project/archive/public-private-interoperability/</link><pubDate>Tue, 19 May 2020 12:38:49 +0000</pubDate><guid>https://big.tuwien.ac.at/project/archive/public-private-interoperability/</guid><description>&lt;h3 id="topic">Topic&lt;/h3>
&lt;p>The research studio Public Private Interoperability (PPI) develops methods and tools targeting the inter-organizational integration of enterprises and organizations of the public sector. Service-oriented architectures and their implementation by Web Services are the current state-of-the-art technologies for this kind of integration problems. However, Web Services are agnostic toward the structure of the information / documents being exchanged. The studio PPI focuses on the exchanged business documents and considers a model-driven approach for the definition of the interfaces. The resulting method and a corresponding tool set have to provide a mix between re-usable document building blocks and business context specific adaptation of business documents. The method must not be limited to a single business document standard language or business document ontology. PPI delivers concepts for the platform-independent definition of business documents as well as for the transformation between different business document standards / ontologies. Evidently, PPI integrates existing, well accepted business document standards, like UBL 2.0, into its prototypical implementation of a tool set. The re-engineering of existing business document standards will reduce time and costs in the development of new business interoperability interfaces and will allow the platform-specific transformation between business document standards.&lt;/p>
&lt;h3 id="term">Term&lt;/h3>
&lt;p>01.10.2008 - 30.11.2011&lt;/p>
&lt;h3 id="funding">Funding&lt;/h3>
&lt;p>Funded by the Austrian Research Promotion Agency (FFG) under project number 818639.&lt;/p>
&lt;h3 id="partner">Partner&lt;/h3>
&lt;ul>
&lt;li>
&lt;a href="http://www.researchstudios.at" target="_blank" rel="noopener">Research Studios Austria Forschungsgesellschaft mbH&lt;/a>&lt;/li>
&lt;/ul></description></item><item><title>Model Execution based on fUML</title><link>https://big.tuwien.ac.at/project/archive/model-execution-based-on-fuml/</link><pubDate>Tue, 19 May 2020 12:38:48 +0000</pubDate><guid>https://big.tuwien.ac.at/project/archive/model-execution-based-on-fuml/</guid><description>&lt;h3 id="topic">Topic&lt;/h3>
&lt;p>In model-driven development models are considered as the key artifacts and, as a result, the success of the whole development process relies on these models and their quality. Consequently, there is an urgent need for adequate methods to ensure high quality of models. Model execution can serve as the crucial basis for such methods by enabling to automatically test and debug models. Therefore, lessons learned from testing and debugging of code may serve as a valuable source of inspiration. However, the peculiarities of models in comparison to code, such as multiple views and different abstraction levels, impede the direct adoption of existing methods for models. Thus, we claim that the currently available tool support for model testing and debugging is still insufficient because these peculiarities are not adequately addressed. In this project, we aim at tackling these shortcomings by proposing a novel model execution environment based on fUML, which enables to efficiently test and debug models.&lt;/p>
&lt;p>More information:
&lt;a href="http://www.modelexecution.org" target="_blank" rel="noopener">Project Homepage&lt;/a>&lt;/p>
&lt;h3 id="heading">&lt;/h3>
&lt;p> &lt;/p>
&lt;h3 id="term">Term&lt;/h3>
&lt;p>01.07.2011 - 31.12.2018&lt;/p>
&lt;h3 id="funding">Funding&lt;/h3>
&lt;p>First year funded by
&lt;a href="http://www.lieberlieber.com" target="_blank" rel="noopener">LieberLieber Software GmbH&lt;/a>&lt;/p></description></item><item><title>Multi-Paradigm Modelling for Cyber-Physical Systems</title><link>https://big.tuwien.ac.at/project/archive/multi-paradigm-modelling-for-cyber-physical-systems/</link><pubDate>Tue, 19 May 2020 12:38:48 +0000</pubDate><guid>https://big.tuwien.ac.at/project/archive/multi-paradigm-modelling-for-cyber-physical-systems/</guid><description>&lt;h3 id="topic">Topic&lt;/h3>
&lt;p>Truly complex, designed systems, known as Cyber Physical Systems (CPS), are emerging that integrate physical, software, and network aspects. To date, no unifying theory nor systematic design methods, techniques and tools exist for such systems. Individual (mechanical, electrical, network or software) engineering disciplines only offer partial solutions. Multi-paradigm Modelling (MPM) proposes to model every part and aspect of a system explicitly, at the most appropriate level(s) of abstraction, using the most appropriate modelling formalism(s). Modelling languages engineering, including model transformation, and the study of their semantics, are used to realize MPM. MPM is seen as an effective answer to the challenges of designing CPS. We aim to promote the sharing of foundations, techniques, and tools and to provide educational resources, to both academia and industry. This will be achieved by bringing together and disseminating knowledge and experiments on CPS problems and MPM solutions.&lt;/p>
&lt;p>More information:
&lt;a href="http://www.cost.eu/COST_Actions/ict/Actions/IC1404" target="_blank" rel="noopener">Project Website&lt;/a>&lt;/p>
&lt;h3 id="term">Term&lt;/h3>
&lt;p>01.10.2014 - 31.01.2019&lt;/p>
&lt;h3 id="funding">Funding&lt;/h3>
&lt;p>ICT COST Action IC1404&lt;/p></description></item><item><title>A Semantic Infrastructure for Model-based Tool Integration</title><link>https://big.tuwien.ac.at/project/archive/a-semantic-infrastructure-for-model-based-tool-integration/</link><pubDate>Tue, 19 May 2020 12:38:47 +0000</pubDate><guid>https://big.tuwien.ac.at/project/archive/a-semantic-infrastructure-for-model-based-tool-integration/</guid><description>&lt;h3 id="topic">Topic&lt;/h3>
&lt;p>With the rise of model-driven software development, more and more development tasks are being performed on models. A rich variety of modeling tools is available supporting different tasks, such as model creation, model simulation, model checking, and code generation. Seamless exchange of models among different modeling tools increasingly becomes a crucial prerequisite for effective software development processes. Due to lack of interoperability, however, it is often difficult to use tools in combination, thus the potential of model-driven software development cannot be fully utilized, unless we find some scalable way of integration. We are aiming at providing a semantic infrastructure for model-based tool integration, enabling to facilitate any tool appropriate for the modeling task at hand. The key innovations provided are a set of scalable architectural model integration patterns supported by a high-level metamodel integration language, thus going beyond existing low-level model transformation approaches. Ontology-based metamodel integration considerably lowers the manual effort required for tool integration, enabling a novel synergic use of technologies from the model engineering and ontology engineering domains. An open knowledge base for tool integration captures essential knowledge about modeling languages and tools in terms of ontologies, fostering reuse within and beyond the scope of this project. These innovations will be realized within the ModelCVS prototype and case study. The core of the system will be based on a versioning system such as CVS, thus providing a loosely-coupled and well-proofed integration architecture. Transparent transformation of models between different tools, languages and exchange formats, as well as versioning capabilities exploiting the rich syntax and semantics of models represent the key functionalities of ModelCVS. In this way, ModelCVS will serve as both, a research vehicle and testbed for exploring applications of semantic technologies in model-based tool integration and a prototype for a succeeding industrial product.&lt;/p>
&lt;h3 id="term">Term&lt;/h3>
&lt;p>01.10.2006 - 31.12.2007&lt;/p>
&lt;h3 id="funding">Funding&lt;/h3>
&lt;p>This work has been partly funded by the Austrian Federal Ministry of Transport, Innovation and Technology (BMVIT) and FFG under grant FIT-IT-810806.&lt;/p>
&lt;h3 id="partner">Partner&lt;/h3>
&lt;ul class="partnerList">&lt;li>&lt;a href="http://www.tuwien.ac.at">Technische Universität Wien&lt;/a>&lt;/li>&lt;li>&lt;a href="http://www.jku.at">Johannes Kepler University Linz&lt;/a>&lt;/li>&lt;li>&lt;a href="http://www.arikan.at/apg_olb/zeigeNewsListeAction.do">Arikan Ges.m.b.H.&lt;/a>&lt;/li>&lt;li>&lt;a href="http://www.bmlv.gv.at">BMLV&lt;/a>&lt;/li>&lt;/ul></description></item><item><title>Metainformation im modellbasierten Variantenmanagement</title><link>https://big.tuwien.ac.at/project/archive/metainformation-im-modellbasierten-variantenmanagement/</link><pubDate>Tue, 19 May 2020 12:38:47 +0000</pubDate><guid>https://big.tuwien.ac.at/project/archive/metainformation-im-modellbasierten-variantenmanagement/</guid><description>&lt;h3 id="topic">Topic&lt;/h3>
&lt;p>Das Forschungsvorhaben umfasst eine Konzeptentwicklung, sowie die Leistung von Vorabeiten für ein prototypisches Entwicklungsvorhaben, mit dem Ziel technologische und ökonomische Aspekte im modellbasierten Variantenmanagement aufzuzeigen. Dabei sollen neben dem modellbasierten Variantenmanagement auch die Validierung von Varianten und die Annotation von Metainformationen (Gewicht, Stromverbrauch, Kosten) in Modellvarianten untersucht, sowie erste Ideen für eine technologische Umsetzung des erkannten Potenzials skizziert werden.&lt;/p>
&lt;h3 id="term">Term&lt;/h3>
&lt;p>01.04.2014 - 31.10.2014&lt;/p>
&lt;h3 id="funding">Funding&lt;/h3>
&lt;p>FFG Österreichische Forschungsförderungsgesellschaft mbH Innovationsscheck Plus&lt;/p>
&lt;h3 id="partner">Partner&lt;/h3>
&lt;ul>
&lt;li>
&lt;a href="http://www.sparxsystems.at/" target="_blank" rel="noopener">SparxSystems Software GmbH&lt;/a>&lt;/li>
&lt;/ul></description></item><item><title>Model-Based Adaptation Engineering in Automation Systems Engineering</title><link>https://big.tuwien.ac.at/project/archive/model-based-adaptation-engineering-in-automation-systems-engineering/</link><pubDate>Tue, 19 May 2020 12:38:47 +0000</pubDate><guid>https://big.tuwien.ac.at/project/archive/model-based-adaptation-engineering-in-automation-systems-engineering/</guid><description>&lt;h3 id="topic">Topic&lt;/h3>
&lt;p>Model-Based Adaptation Engineering (MAE) in Automation Systems Engineering (ASE) (MAE4ASE) is a module of the Christian Doppler Laboratory on Software Engineering Integration for Flexible Automation Systems. It addresses the upcoming need of ASE to raise the level of flexibility of automation systems even further in order to better react to changing environments. For instance, this is of particular importance in the context of the emerging Industry 4.0 initiative which aims, amongst other goals, at providing increased flexibility for production systems to better adapt to the changing needs of customers, organizations, and society. As a consequence, systems are no longer designed to be, but they have to be designed to evolve. Of course, raising the level of flexibility by switching to evolvable systems directly impacts the requirements on and complexity of the engineering process for such systems. To cope with this new kind complexity in ASE, dedicated concepts, techniques, and tools are needed to enable change and to ensure a systematic, safe, and predictable adaptation of systems to prevent the negative side effects of ad-hoc changes. A promising way to tackle this problem is to apply modeling and simulation approaches in combination with the establishment of adaptations as first class entities throughout the whole engineering process which is the mission of MAE4ASE.&lt;/p>
&lt;p>More information: &lt;a href="https://www.sysml4industry.org">https://www.sysml4industry.org&lt;/a>&lt;/p>
&lt;h3 id="term">Term&lt;/h3>
&lt;p>01.01.2015 - 31.12.2016&lt;/p>
&lt;h3 id="funding">Funding&lt;/h3>
&lt;p>Module 3 in &lt;a href="http://cdl.ifs.tuwien.ac.at" target="_blank">CDL-Flex&lt;/a> funded by the Christian Doppler Research Association (Christian Doppler Forschungsgesellschaft)&lt;/p>
&lt;h3 id="partner">Partner&lt;/h3>
&lt;ul>
&lt;li>
&lt;a href="http://www.lieberlieber.com/" target="_blank" rel="noopener">LieberLieber&lt;/a>&lt;/li>
&lt;/ul></description></item><item><title>Language Engineering for Analyzable Executable DSMLs</title><link>https://big.tuwien.ac.at/project/archive/language-engineering-for-analyzable-executable-dsmls/</link><pubDate>Tue, 19 May 2020 12:38:46 +0000</pubDate><guid>https://big.tuwien.ac.at/project/archive/language-engineering-for-analyzable-executable-dsmls/</guid><description>&lt;h3 id="topic">Topic&lt;/h3>
&lt;p>The project LEA-xDSML (Language Engineering for Analyzable Executable Domain-Specific Modeling Languages) resides in the context of Model-Driven Engineering (MDE), which proposes the use of domain-specific modeling languages (DSMLs) to reduce the complexity associated with the development of complex software-intensive systems, as, for instance, found in the automation domain, production domain, and automotive domain.&lt;/p>
&lt;p>DSMLs are increasingly being developed to continuously leverage the domain-specific expertise of the various stakeholders involved in the development of complex system. Thereby, the integration of domain-specific knowledge into DSMLs can significantly improve the productivity of the development process and the quality of the final system. However, the development of DSMLs has also been recognized as a challenging and significant software engineering task itself.&lt;/p>
&lt;p>In this project, we focus on the challenges associated with the development of executable DSMLs (xDSMLs) that support the modeling and analysis of complex system behaviors through model execution. In particular, we aim at overcoming the following three challenges: the lack of foundations for formalizing xDSMLs in a way that allows for model-level analyses; the high efforts associated with the development of domain-specific analysis tools for xDSMLs; and the lack of fault localization techniques for efficiently identifying faults in models defined with xDSMLs.&lt;/p>
&lt;p>To overcome these challenges, the aim of this project is to develop a novel engineering framework for xDSMLs that will provide (i) concepts, techniques and processes to formalize xDSMLs usable for model-level behavior analyses, (ii) automation techniques for efficiently developing domain-specific model analysis tools for xDSMLs, (iii) and fault localization mechanisms for xDSMLs that allow an efficient debugging of models.&lt;/p>
&lt;p>The framework will be iteratively developed and evaluated. The methodology for evaluating the framework builds on three major pillars, namely case studies, experiments with our master students, and collaborative studies with international collaborators.&lt;/p>
&lt;p>The results of the project will significantly ease the development of xDSMLs and accompanying model analysis tools, and thus lead to reduced development costs of xDSMLs and at the same time increased quality of systems developed with xDSMLs. This will present a major cornerstone in the model-based development of complex software-intensive systems.&lt;/p>
&lt;p>More details may be found at &lt;a href="http://www.modelexecution.org/lea">http://www.modelexecution.org/lea&lt;/a>.&lt;/p>
&lt;h3 id="term">Term&lt;/h3>
&lt;p>01.07.2018 - 28.02.2019&lt;/p>
&lt;h3 id="funding">Funding&lt;/h3>
&lt;p>Funded by the Austrian Science Fund (FWF) under the grant number P 30525-N31.&lt;/p></description></item><item><title>Training the Next Generation of Experts in Scalable Low-Code Engineering Platforms</title><link>https://big.tuwien.ac.at/project/archive/training-the-next-generation-of-experts-in-scalable-low-code-engineering-platforms/</link><pubDate>Tue, 19 May 2020 12:38:46 +0000</pubDate><guid>https://big.tuwien.ac.at/project/archive/training-the-next-generation-of-experts-in-scalable-low-code-engineering-platforms/</guid><description>&lt;h3 id="topic">Topic&lt;/h3>
&lt;p>EU project&lt;/p>
&lt;h3 id="term">Term&lt;/h3>
&lt;p>01.01.2019 - 28.02.2019&lt;/p>
&lt;h3 id="funding">Funding&lt;/h3>
&lt;p>founded by EU, grant number 813884&lt;/p></description></item><item><title>InteGra 4.0 - Horizontal and Vertical Interface Integration 4.0</title><link>https://big.tuwien.ac.at/project/archive/integra-4-0-horizontal-and-vertical-interface-integration-4-0/</link><pubDate>Tue, 19 May 2020 12:38:45 +0000</pubDate><guid>https://big.tuwien.ac.at/project/archive/integra-4-0-horizontal-and-vertical-interface-integration-4-0/</guid><description>&lt;h3 id="topic">Topic&lt;/h3>
&lt;p>InteGra 4.0 focuses on the horizontal integration throughout value chains as well as on the vertical integration of networked production systems as identified by the German working committee for Industrie 4.0. Thereby, we build up from (i) the ISA-95 industry standard (ANSI/ISA-95; DIN EN 62264) to describe the vertical integration between ERP- and MES-systems as well as from (ii) the REA (Resource-Event-Agent) business ontology (ISO 15944-4) for the modeling of value creation networks between different companies, i.e., the horizontal integration. This exploratory project envisions the merging of concepts and models of ISA-95 and REA and to evaluate its benefit for a universal model-driven system engineering approach throughout the entire value chain. InteGra 4.0 will involve production companies of the steel industry as well as software companies in order to accomodate different views on the research topic and to get a better understanding of open demands on vertical and horizontal integration in these domains.&lt;/p>
&lt;p>More information:
&lt;a href="http://integra.big.tuwien.ac.at" target="_blank" rel="noopener">http://integra.big.tuwien.ac.at &lt;/a>&lt;/p>
&lt;h3 id="term">Term&lt;/h3>
&lt;p>01.10.2015 - 30.09.2016&lt;/p></description></item><item><title>Research Studio Inter-Organisational Systems</title><link>https://big.tuwien.ac.at/project/archive/research-studio-inter-organisational-systems/</link><pubDate>Tue, 19 May 2020 12:38:45 +0000</pubDate><guid>https://big.tuwien.ac.at/project/archive/research-studio-inter-organisational-systems/</guid><description>&lt;h3 id="topic">Topic&lt;/h3>
&lt;h3 id="term">Term&lt;/h3>
&lt;p>01.10.2008 - 31.12.2014&lt;/p>
&lt;h3 id="funding">Funding&lt;/h3>
&lt;p>BMWF&lt;/p>
&lt;h3 id="partner">Partner&lt;/h3>
&lt;p>More information:
&lt;a href="http://ios.researchstudio.at" target="_blank" rel="noopener">Research Studio Inter-Organisational Systems&lt;/a>&lt;/p></description></item><item><title>E-business Registry Permitting Enterprise Liaisons</title><link>https://big.tuwien.ac.at/project/archive/e-business-registry-permitting-enterprise-liaisons/</link><pubDate>Tue, 19 May 2020 12:38:44 +0000</pubDate><guid>https://big.tuwien.ac.at/project/archive/e-business-registry-permitting-enterprise-liaisons/</guid><description>&lt;h3 id="topic">Topic&lt;/h3>
&lt;p>The project ERPEL targets at an e-business registry serving as a backbone for executing on-the-fly e-business transactions between semantically enabled ERP systems. By on-the-fly e-business transactions we understand transactions that are conducted between companies, which are not yet in a partnership and dynamically find each other in order to engage in e-business transactions. These business partners have to find each other according to both their business needs and technical capabilities. This is supported by the ERPEL registry. Today, registries are often successfully used within a company, but there are hardly any success stories on public registries to support B2B. One reason is that registry entries may not be considered trustworthy. In order to avoid fake entries, the ERPEL registry will reconcile data with business directories of legal authorities. Furthermore, companies usually do not trust other unknown companies. In order to foster trust in this context we build upon techniques known from social networks. Thereby, we aim at establishing business networks within the ERPEL registry. Finding an appropriate business partner, it is important to know her business capabilities or in other words which products she offers. Usually companies maintain their product portfolio in their ERP system, but hardly anyone is willing to maintain this portfolio in another data store, i.e., the registry. Thus, we develop a seamless integration of the product portfolios, held in the ERP systems of the project partners, into the ERPEL registry. In order to avoid a proliferation of different naming and descriptions of the same products, we apply semantic techniques for product classifications. A search in the registry has to disclose the technical capabilities of a potential business partner in order to ensure interoperability. Overloaded business document standards, missing process choreographies, and a variety of communication protocols hamper an effective search. Thus, ERPEL follows a bottom-up approach starting from core documents with well-defined extension mechanisms, and unambiguous business choreography specifications. Furthermore, ERPEL comes with a default communication protocol specifically targeting SMEs. These unambiguous specifications allow the development of business service interfaces (BSI) that are integrated into the ERP systems. BSIs guarantee the execution of e-business transactions between customers of different ERP systems.&lt;/p>
&lt;p>More information:
&lt;a href="http://www.erpel.at/" target="_blank" rel="noopener">ERPEL&lt;/a>&lt;/p>
&lt;h3 id="term">Term&lt;/h3>
&lt;p>01.05.2010 - 31.10.2012&lt;/p>
&lt;h3 id="funding">Funding&lt;/h3>
&lt;p>Funded by the Austrian Federal Ministry of Transport, Innovation and Technology (BMVIT) and FFG under grant FIT-IT-825064.&lt;/p>
&lt;h3 id="partner">Partner&lt;/h3>
&lt;ul class="partnerList">&lt;li>&lt;a href="http://www.bmd.at">BMD Systemhaus&lt;/a>&lt;/li>&lt;li>&lt;a href="http://www.mesonic.at">Mesonic&lt;/a>&lt;/li>&lt;li>&lt;a href="http://www.bluemonkeys.at">Blue Monkeys&lt;/a>&lt;/li>&lt;li>&lt;a href="http://www.paradigma.at">Paradigma Unternehmensberatung&lt;/a>&lt;/li>&lt;li>&lt;a href="http://www.boc-group.com/at">BOC Group&lt;/a>&lt;/li>&lt;li>&lt;a href="http://www.infotechnik-smejkal.at">Infotechnik Smejkal&lt;/a>&lt;/li>&lt;li>&lt;a href="http://www.megaelektro.at/">Mega Elektro&lt;/a>&lt;/li>&lt;/ul></description></item><item><title>Formalizing and Managing Evolution in Model-Driven Engineering</title><link>https://big.tuwien.ac.at/project/archive/formalizing-and-managing-evolution-in-model-driven-engineering/</link><pubDate>Tue, 19 May 2020 12:38:44 +0000</pubDate><guid>https://big.tuwien.ac.at/project/archive/formalizing-and-managing-evolution-in-model-driven-engineering/</guid><description>&lt;h3 id="topic">Topic&lt;/h3>
&lt;p>Like traditional program code, software models are not resistant to change, but evolve over time by undergoing continuous extensions, corrections, and modifications. In model-driven engineering (MDE), evolution is multidimensional leading to the model management tasks of synchronization, versioning, and co-evolution. Whereas each of these tasks has recently received increased research interest, a systematic comparison and evaluation of the different approaches is missing. Within the FAME project, we aim at establishing a uniform framework characterizing changes and their impacts. The resulting findings will provide the basis for a suite of efficient techniques for avoiding unexpected side-effects of evolution. We will use different, well-explored formalisms with powerful inference engines exploiting concise semantic definitions of the modeling languages. By this, FAME will contribute to reliable change propagation indispensable for automatic quality assurance in MDE.&lt;/p>
&lt;p>More information: &lt;a href="http://www.modelevolution.org">http://www.modelevolution.org&lt;/a>&lt;/p>
&lt;h3 id="term">Term&lt;/h3>
&lt;p>01.01.2011 - 31.12.2014&lt;/p>
&lt;h3 id="funding">Funding&lt;/h3>
&lt;p>Funded by the Wiener Wissenschafts-, Forschungs- und Technologiefonds (WWTF) under grant ICT10-018.&lt;/p>
&lt;h3 id="partner">Partner&lt;/h3>
&lt;ul class="partnerList">&lt;li>&lt;a href="http://www.lcc.uma.es/">Universidad de Málaga&lt;/a>&lt;/li>&lt;li>&lt;a href="http://www.disi.unitn.it/">University of Trento&lt;/a>&lt;/li>&lt;li>&lt;a href="http://www.di.univaq.it/">Università degli Studi dell’Aquila&lt;/a>&lt;/li>&lt;li>&lt;a href="http://www.se-rwth.de/">RWTH Aachen&lt;/a>&lt;/li>&lt;li>&lt;a href="http://www.informatik.uni-bremen.de">Universität Bremen&lt;/a>&lt;/li>&lt;/ul></description></item><item><title>Design and Realization of Know-How Transfer for electronic Billing based on ebInterface</title><link>https://big.tuwien.ac.at/project/archive/design-and-realization-of-know-how-transfer-for-electronic-billing-based-on-ebinterface/</link><pubDate>Tue, 19 May 2020 12:38:42 +0000</pubDate><guid>https://big.tuwien.ac.at/project/archive/design-and-realization-of-know-how-transfer-for-electronic-billing-based-on-ebinterface/</guid><description>&lt;h3 id="topic">Topic&lt;/h3>
&lt;p>The definition of the Austrian e-Billing Standard ebInterface was successfully conducted by well-known ERP system vendors under the lead ot the TU Vienna. The project ebInvoice resulted in the implementation of the ebInterface standard in their ERP systems. A success of the ebInterface standard requires a wide-spread adoption by potential users of the ERP systems. In order to stimulate the adoption the ebTransfer project will design and realize an know-how transfer on ebInterface to consultants and multipliers.&lt;/p>
&lt;h3 id="term">Term&lt;/h3>
&lt;p>01.01.2007 - 30.11.2007&lt;/p>
&lt;h3 id="partner">Partner&lt;/h3>
&lt;ul>
&lt;li>
&lt;a href="http://www.cti.gr/" target="_blank" rel="noopener">Research Academic Computer Technology Institute&lt;/a>&lt;/li>
&lt;/ul></description></item><item><title>ebInterface 3.0 - electronic invoicing</title><link>https://big.tuwien.ac.at/project/archive/ebinterface-3-0-electronic-invoicing/</link><pubDate>Tue, 19 May 2020 12:38:42 +0000</pubDate><guid>https://big.tuwien.ac.at/project/archive/ebinterface-3-0-electronic-invoicing/</guid><description>&lt;h3 id="topic">Topic&lt;/h3>
&lt;p>The Austrian e-billing standard ebInterface has been supported by major Austrian ERP-vendors. Thus, the XML-based ebInterface standard may be used in Austria to exchange invoices by electronic means. However, the critical mass of adopters has not yet been reached, which limits the full potential of electronic e-billing in Austria. In order to become more attrective to potential adopters the ebInterface standard have to be revisited according to the following issues: * Update of the standard to incorporate requirements reported from the ERP-vendors, early adopters and potential adopters. * Evaluation of a concept for plug-ins into the standard that allow industry-specific extensions to the standards * Simplification of those parts of the standard that cause misinterpretation and hinder adoption of the standard&lt;/p>
&lt;h3 id="term">Term&lt;/h3>
&lt;p>01.01.2009 - 28.02.2010&lt;/p></description></item><item><title>ebInterface 2012 - electronic invoicing</title><link>https://big.tuwien.ac.at/project/archive/ebinterface-2012-electronic-invoicing/</link><pubDate>Tue, 19 May 2020 12:38:41 +0000</pubDate><guid>https://big.tuwien.ac.at/project/archive/ebinterface-2012-electronic-invoicing/</guid><description>&lt;h3 id="topic">Topic&lt;/h3>
&lt;p>Am nationalen eBilling Standard ebInterface haben seit dem Jahr 2004 namhafte ERP-Hersteller mitgewirkt und dieser besteht derzeit in der Version 4.0. Im Rahmen von ebInterface 4.0 sind erstmals auch domänenspezifische Erweiterungen vorgesehen, die eine Einbindung von zusätzlichen, vom Kernstandard unabhängigen Elementen erlauben. Basierend auf der Standarddefinition haben ERP Hersteller begonnen entsprechende Interfaces zu Schreiben bzw. Lesen von ebInterface in ihre Software zu integrieren. …&lt;/p>
&lt;h3 id="term">Term&lt;/h3>
&lt;p>01.03.2012 - 21.12.2012&lt;/p></description></item><item><title>ebInterface 2013 - electronic invoicing</title><link>https://big.tuwien.ac.at/project/archive/ebinterface-2013-electronic-invoicing/</link><pubDate>Tue, 19 May 2020 12:38:41 +0000</pubDate><guid>https://big.tuwien.ac.at/project/archive/ebinterface-2013-electronic-invoicing/</guid><description>&lt;h3 id="topic">Topic&lt;/h3>
&lt;h3 id="term">Term&lt;/h3>
&lt;p>01.01.2013 - 28.02.2014&lt;/p>
&lt;h3 id="partner">Partner&lt;/h3>
&lt;p>Am nationalen eBilling Standard ebInterface haben seit dem Jahr 2004 namhafte ERP-Hersteller mitgewirkt und dieser besteht derzeit in der Version 4.0.&lt;/p></description></item><item><title>ebInterface 2015 - electronic invoicing</title><link>https://big.tuwien.ac.at/project/archive/ebinterface-2015-electronic-invoicing/</link><pubDate>Tue, 19 May 2020 12:38:41 +0000</pubDate><guid>https://big.tuwien.ac.at/project/archive/ebinterface-2015-electronic-invoicing/</guid><description>&lt;h3 id="topic">Topic&lt;/h3>
&lt;h3 id="term">Term&lt;/h3>
&lt;p>01.01.2015 - 31.12.2017&lt;/p></description></item><item><title>ebInterface 2010 - electronic invoicing</title><link>https://big.tuwien.ac.at/project/archive/ebinterface-2010-electronic-invoicing/</link><pubDate>Tue, 19 May 2020 12:38:40 +0000</pubDate><guid>https://big.tuwien.ac.at/project/archive/ebinterface-2010-electronic-invoicing/</guid><description>&lt;h3 id="topic">Topic&lt;/h3>
&lt;p>The Austrian e-billing standard ebInterface has been supported by major Austrian ERP-vendors. Thus, the XML-based ebInterface standard may be used in Austria to exchange invoices by electronic means. New expertise in daily use led to new standard requirements which should be taken into account. In some branches the standard has to be adapted without changing the kernel of the standard. The general Plug-Ins should be replaced by a well-defined methodology. The EU project PEPPOL is working on a solution for the public sector on basis of the Universal Business Language (UBL). As a partner of the PEPPOL Project the Bundesrechenzentrum GmbH is developing a transformation between ebInterface and UBL Invoice. This transformation has to be evaluated to enable the Bundesrechenzentrum GmbH wether the transformation can be reccomended to KMUs or not.&lt;/p>
&lt;h3 id="term">Term&lt;/h3>
&lt;p>02.11.2010 - 31.12.2010&lt;/p></description></item><item><title>ebInterface 2011 - electronic invoicing</title><link>https://big.tuwien.ac.at/project/archive/ebinterface-2011-electronic-invoicing/</link><pubDate>Tue, 19 May 2020 12:38:40 +0000</pubDate><guid>https://big.tuwien.ac.at/project/archive/ebinterface-2011-electronic-invoicing/</guid><description>&lt;h3 id="topic">Topic&lt;/h3>
&lt;p>The Austrian e-billing standard ebInterface has been supported by major Austrian ERP-vendors. Because of ongoing market changes the new version ebInterface 4.0 shall be realised. The corresponding XSLT has to be adapted for Web-Browsers. Former projects have already shown possible alternatives to extend the kernel of the standard with sectoral extensions. In the course of this project the dicsussion with ERP vendors and interested users featured alternatives will be integraded into the standard. Aditionally there will be an extension for a concrete branch. This extions also has to be integrated into the XSLT. Furthermore all implementations of the ERP vondors or users, respectively have always to be checked according to the standard to guarantee a smooth integration of new partners. For this purpose an automatic checking service should be developed that should enable to check the kernel standard as well es existing extensions and partner specific restrictions, respectively, given that they have been provided to the checking service in an appropriate form.&lt;/p>
&lt;h3 id="term">Term&lt;/h3>
&lt;p>13.04.2011 - 28.02.2012&lt;/p></description></item><item><title>Doctoral College "Cyber Physical Production Systems"</title><link>https://big.tuwien.ac.at/project/archive/doctoral-college-cyber-physical-production-systems/</link><pubDate>Tue, 19 May 2020 12:38:39 +0000</pubDate><guid>https://big.tuwien.ac.at/project/archive/doctoral-college-cyber-physical-production-systems/</guid><description>&lt;h3 id="topic">Topic&lt;/h3>
&lt;p>The Doctoral College „Cyber-Physical Production Systems“ aims at further positioning TU Wien with TUWin4.0 as the leading research institute in Austria in this domain and to help to position the university as one of the highest ranked European research institutes in this highly relevant area.&lt;/p>
&lt;p>More information: &lt;a href="http://dc-cpps.tuwien.ac.at/">http://dc-cpps.tuwien.ac.at/&lt;/a>&lt;/p>
&lt;h3 id="term">Term&lt;/h3>
&lt;p>01.12.2014 - 31.03.2018&lt;/p>
&lt;h3 id="funding">Funding&lt;/h3>
&lt;p>The Doctoral College „Cyber-Physical Production Systems“ is funded by the Vienna University of Technology.&lt;/p></description></item><item><title>ebCrossborder - crossborder e-Billing in Austria</title><link>https://big.tuwien.ac.at/project/archive/ebcrossborder-crossborder-e-billing-in-austria/</link><pubDate>Tue, 19 May 2020 12:38:39 +0000</pubDate><guid>https://big.tuwien.ac.at/project/archive/ebcrossborder-crossborder-e-billing-in-austria/</guid><description>&lt;h3 id="topic">Topic&lt;/h3>
&lt;p>A large number of Austrian ERP-companies already endorsed the ebInterface standardfor e-Billing. The goal of the ebCrossBorder project is to establish a broader use of the standard not only by Austrian small and medium enterprises (SMEs) but also on an international level. Thus the project aims at developing an ebInterface version for electronic cross-border invoicing. Primary target are companies and organizations in the neighbouring countries of Austria.&lt;/p>
&lt;h3 id="term">Term&lt;/h3>
&lt;p>01.01.2007 - 31.01.2008&lt;/p>
&lt;h3 id="funding">Funding&lt;/h3>
&lt;p>BM für Wirtschaft, Familie und Jugend (bm:wfj) &amp;amp; Bereich Forschung und Innovation“ under grant number BMWA-98.362/0062-C1/10/2006&lt;/p></description></item><item><title>Doctoral College "Adaptive Distributed Systems"</title><link>https://big.tuwien.ac.at/project/archive/doctoral-college-adaptive-distributed-systems/</link><pubDate>Tue, 19 May 2020 12:38:38 +0000</pubDate><guid>https://big.tuwien.ac.at/project/archive/doctoral-college-adaptive-distributed-systems/</guid><description>&lt;h3 id="topic">Topic&lt;/h3>
&lt;p>The Doctoral College „Adaptive Distributed Systems“ intends to work on the challenging questions of today’s distributed computer systems by bringing together experts from various fields of computer science, mathematics and statistics, thus, fostering a multidisciplinary approach.&lt;/p>
&lt;p>More information: &lt;a href="http://www.big.tuwien.ac.at/adaptive">http://www.big.tuwien.ac.at/adaptive&lt;/a>&lt;/p>
&lt;h3 id="term">Term&lt;/h3>
&lt;p>01.10.2012 - 30.09.2015&lt;/p>
&lt;h3 id="funding">Funding&lt;/h3>
&lt;p>The Doctoral College „Adaptive Distributed Systems“ is funded by the Vienna University of Technology together with the Industriellenvereinigung.&lt;/p></description></item><item><title>Innovationslehrgang zur Gestaltung der Digitalen Transformation in der Produktentwicklung und Produktion (DigiTrans 4.0)</title><link>https://big.tuwien.ac.at/project/archive/innovationslehrgang-zur-gestaltung-der-digitalen-transformation-in-der-produktentwicklung-und-produktion-digitrans-4-0/</link><pubDate>Tue, 19 May 2020 12:38:38 +0000</pubDate><guid>https://big.tuwien.ac.at/project/archive/innovationslehrgang-zur-gestaltung-der-digitalen-transformation-in-der-produktentwicklung-und-produktion-digitrans-4-0/</guid><description>&lt;h3 id="topic">Topic&lt;/h3>
&lt;p>Qualifizierungsziel ist es, die Unternehmen in ihrer Gesamtheit in das Zeitalter von Industrie 4.0 zu führen. Dazu haben sich die Lehrenden fakultätsübergreifend vernetzt, um im Sinne einer Integration von Fachabteilung, Business-IT und Produktions-IT und zur Vernetzung sämtlicher Informationsströme entlang der Wertschöpfungskette unterrichten zu können. Die Zielerreichung dieser schrittweisen Umsetzung von Industrie 4.0 wird durch den modularen und interdisziplinären Aufbau des Innovationslehrgangs erreicht. Unter dem Motto „Crossover Lectures for Cross Innovation“ werden die Module (1) Product Lifecycle Management, (2) Modelle und Methoden zur Digitalen Transformation, (3) Industrielle Kommunikation und automatisierte Fertigungssysteme, (4) Wertschöpfungsnetzwerke, (5) Integration Engineering und (6) Gender und Arbeitsplatz 4.0, theoretisch und praktisch, unter Einbeziehung der TU Wien Pilotfabrik I4.0, abgehalten. Durch die Größe des Konsortiums und dem dadurch möglichen multidisziplinären Austausch erwarten wir uns Erkenntnisgewinne (i) in der gemeinsamen Entwicklung neuer Anwendungsfelder im Themenfeld Industrie 4.0, (ii) in der Adressierung wirtschaftsnaher Themen im Qualifizierungsprofil der TU Wien und (iii) in der Umsetzung zukunftsrelevanter Technologiefelder, wie z.B. CPPS, IoT und IIoT. Nicht zuletzt wird als Ergebnis eine Etablierung nachhaltiger Kooperationen sowohl zwischen den wissenschaftlichen und wirtschaftlichen Partnern, als auch zwischen den teilnehmenden Unternehmen angestrebt.&lt;/p>
&lt;p>Additional Information: &lt;a href="http://digitrans.at">http://digitrans.at&lt;/a>&lt;/p>
&lt;p>More information:
&lt;a href="http://www.tuwien.ac.at/aktuelles/news_detail/article/10072/" target="_blank" rel="noopener">http://www.tuwien.ac.at/aktuelles/news_detail/article/10072/&lt;/a>&lt;/p>
&lt;h3 id="term">Term&lt;/h3>
&lt;p>01.09.2016 - 30.11.2018&lt;/p>
&lt;h3 id="funding">Funding&lt;/h3>
&lt;p>DigiTrans 4.0 wird mit Mitteln des Bundesministeriums für Wissenschaft, Forschung und Wirtschaft (BMWFW) durch die Österreichische Forschungsförderungsgesellschaft (FFG) in der Programmlinie Innovationslehrgänge unter der Projektnummer 854157 gefördert.&lt;/p>
&lt;h3 id="partner">Partner&lt;/h3>
&lt;ul class="partnerList">&lt;li>&lt;a href="http://www.abf.at/">ABF – Industrielle Automation GmbH&lt;/a>&lt;/li>&lt;li>&lt;a href="http://at.atos.net/de-at/home.html">Atos IT Solutions and Services GmbH&lt;/a>&lt;/li>&lt;li>&lt;a href="https://at.boc-group.com/">BOC Information Technologies Consulting GmbH&lt;/a>&lt;/li>&lt;li>&lt;a href="https://www.rotax.com/de/home.html">BRP – Powertrain GmbH &amp;amp; Co KG&lt;/a>&lt;/li>&lt;li>&lt;a href="http://www.csc.com/de">CSC Computer Sciences Consulting Austria GmbH&lt;/a>&lt;/li>&lt;li>&lt;a href="http://eclipsesource.com/en/home/">EclipseSource&lt;/a>&lt;/li>&lt;li>&lt;a href="https://ecosio.com/de/">ecosio GmbH&lt;/a>&lt;/li>&lt;li>&lt;a href="http://www.etm.at/">ETM professional control GmbH&lt;/a>&lt;/li>&lt;li>&lt;a href="https://www.evn.at/Privatkunden.aspx"> EVN AG&lt;/a>&lt;/li>&lt;li>&lt;a href="http://www.evva.at/">EVVA Sicherheitstechnologie GmbH&lt;/a>&lt;/li>&lt;li>&lt;a href="http://www.kmt.co.at/">Kunststoff- / Metalltechnik GmbH&lt;/a>&lt;/li>&lt;li>&lt;a href="http://www.lieberlieber.com/"> LieberLieber Software GmbH&lt;/a>&lt;/li>&lt;li>&lt;a href="http://www.novomatic.com/de">Novomatic Gaming Industries&lt;/a>&lt;/li>&lt;li>&lt;a href="http://www.proalpha.at/at/home.html">ProALPHA Software Austria GmbH&lt;/a>&lt;/li>&lt;li>&lt;a href="https://www.siemens.com/entry/at/de">Siemens Aktiengesellschaft Österreich&lt;/a>&lt;/li>&lt;/ul></description></item><item><title>Collaborative Configuration Systems Integration and Modeling</title><link>https://big.tuwien.ac.at/project/archive/collaborative-configuration-systems-integration-and-modeling/</link><pubDate>Tue, 19 May 2020 12:38:37 +0000</pubDate><guid>https://big.tuwien.ac.at/project/archive/collaborative-configuration-systems-integration-and-modeling/</guid><description>&lt;h3 id="topic">Topic&lt;/h3>
&lt;p>The goal of the project COSIMO is to build up a portfolio configurator platform for leveraging tool integration for railway automation systems and, in general, for production systems at Siemens. The core of this framework comprehensively bases on model-driven concepts and semantic system’s techniques.&lt;/p>
&lt;p>COSIMO stretches over three unique but highly interwoven research goals:&lt;/p>
&lt;ul>
&lt;li>First, support roundtripable and reusable model exchange among heterogeneous engineering for using tool metamodels and tool adapters with model transformations.&lt;/li>
&lt;li>Second, facilitate consistent collaborative modeling between teams in a non-intrusive way, by model virtualization mechanisms together with redundancy and detection mechanisms that are based on specialized model management operators.&lt;/li>
&lt;li>Third, enable guided reconfiguration of evolving component versions across tool boundaries to ensure compatibility of component versions and validity of configurations, by explicitly representing component versions and providing proper reasoning mechanisms and reconfiguration languages.&lt;/li>
&lt;/ul>
&lt;p>More information: &lt;a href="http://cosimo.big.tuwien.ac.at/">http://cosimo.big.tuwien.ac.at/&lt;/a>&lt;/p>
&lt;h3 id="term">Term&lt;/h3>
&lt;p>01.01.2014 - 31.12.2015&lt;/p>
&lt;h3 id="funding">Funding&lt;/h3>
&lt;p>Funded by the „Zentrum für Innovation und Technologie (ZIT) – Die Technologieagentur der Stadt Wien“ under project number 967327.&lt;/p>
&lt;h3 id="partner">Partner&lt;/h3>
&lt;ul>
&lt;li>
&lt;a href="http://www.siemens.com/answers/at/de/" target="_blank" rel="noopener">Siemens AG Österreich&lt;/a>&lt;/li>
&lt;/ul></description></item><item><title>Model-driven Development and Evolution of Semantic Infrastructures</title><link>https://big.tuwien.ac.at/project/archive/model-driven-development-and-evolution-of-semantic-infrastructures/</link><pubDate>Tue, 19 May 2020 12:38:37 +0000</pubDate><guid>https://big.tuwien.ac.at/project/archive/model-driven-development-and-evolution-of-semantic-infrastructures/</guid><description>&lt;h3 id="topic">Topic&lt;/h3>
&lt;p>The main goal of DARWIN is to provide an extensible framework based on well-established conceptual modeling languages and model-driven engineering techniques enabling developers to entirely develop and evolve SIs at an appropriate level of abstraction. To accomplish this goal, a prototype will be developed. Case studies will be conducted in cooperation with “JoinVision”, as well as “Team Communication Technology Management Gmbh (Team)” a company currently conducting a FIT-IT Semantic Systems project to leverage ontology-driven situation awareness in large-scale control systems. Together with these demonstrators and external experts from academia, namely Jordi Cabot (École des Mines de Nantes), Dragan Gaševic (Athabasca University), and Steffen Staab (University of Koblenz-Landau) and from industry (“Franz Inc.”, supplier of commercial, scalable RDF Graph Database products) we intend to evaluate the applicability of our prototype for developing and maintaining the Semantic Infrastructures of Semantic Web applications as well as traditional applications. Along this overall research focus, DARWIN pursues three key research goals: Model-driven Semantic Infrastructure Development, Change-Aware Development Environment, Semi-Automatd Co-Evolution.&lt;/p>
&lt;p>More information: &lt;a href="http://model-evolution.net/">http://model-evolution.net/&lt;/a>&lt;/p>
&lt;h3 id="term">Term&lt;/h3>
&lt;p>01.03.2012 - 28.02.2015&lt;/p>
&lt;h3 id="funding">Funding&lt;/h3>
&lt;p>Funded by the Österreichische Forschungsförderungsgesellschaft mbH (FFG) under project number 832160.&lt;/p>
&lt;h3 id="partner">Partner&lt;/h3>
&lt;ul class="partnerList">&lt;li>&lt;a href="http://www.jku.at/">JKU Linz&lt;/a>&lt;/li>&lt;li>&lt;a href="http://www.lieberlieber.com/">LieberLieber Software GmbH&lt;/a>&lt;/li>&lt;li>&lt;a href="http://www.joinvision.com/">JoinVision&lt;/a>&lt;/li>&lt;li>&lt;a href="http://www.te-am.at/">Team Communication&lt;/a>&lt;/li>&lt;/ul></description></item><item><title>COMBINE – Concurrent Multi-Viewpoint Building Information Modeling</title><link>https://big.tuwien.ac.at/project/archive/combine-concurrent-multi-viewpoint-building-information-modeling/</link><pubDate>Tue, 19 May 2020 12:38:36 +0000</pubDate><guid>https://big.tuwien.ac.at/project/archive/combine-concurrent-multi-viewpoint-building-information-modeling/</guid><description>&lt;h3 id="topic">Topic&lt;/h3>
&lt;p>The processes in the Architecture, Engineering and Construction (AEC) and Facility Management (FM) industries are iterative – components are created, revised or discarded. There are many stakeholders with a multitude of domain-specific requirements and tools – for calculation, information visualisation and exchange, using a variety of standards (e.g. DXF, STEP, IFC, COLLADA, XML, etc.). This makes efficient and timely communication critical. The project COMBINE explores some of its requirements, such as selectivity in the communication, domain-specific adaptation to changes as well as monitoring and versioning, with a particular focus on the loss- and corruption-free translation between standards. The challenges this translation has to address are, among others, the rapid development of new technologies and the relatively slow adaptation of the relevant standards, the varying and disparate levels of detail across standards, and the lack of common ontological platform. The project COMIBINE aims to apply the tools of multilevel model driven development in the search for ontological similarities between standards on various meta-levels. It examines the methods of extracting semantics not only from the formal specification but also from the artefacts of a standard. Finally, it examines visualization techniques that enable the understanding and development of complex multilevel modelling hierarchies.&lt;/p>
&lt;h3 id="term">Term&lt;/h3>
&lt;p>01.02.2017 - 31.01.2020&lt;/p>
&lt;h3 id="funding">Funding&lt;/h3>
&lt;p>TU Wien (Innovative Projekte), project number 1438717&lt;/p>
&lt;h3 id="partner">Partner&lt;/h3>
&lt;p>Prof. Thomas Bednar (TU Wien)&lt;/p></description></item><item><title>Configuration and Operation data optimization using Data Analytics</title><link>https://big.tuwien.ac.at/project/archive/configuration-and-operation-data-optimization-using-data-analytics/</link><pubDate>Tue, 19 May 2020 12:38:36 +0000</pubDate><guid>https://big.tuwien.ac.at/project/archive/configuration-and-operation-data-optimization-using-data-analytics/</guid><description>&lt;h3 id="topic">Topic&lt;/h3>
&lt;p>Die industrienahe Dissertation CODA adressiert innovative, wichtige Forschungsfragen um aus den Laufzeitdaten (Betriebsdaten) und den Entwicklungszeitdaten (Konfigurationsdaten) einer Anlage Optimierungen für Betrieb und Systemkonfiguration abzuleiten. Die Resultate von CODA sind neue Methoden und Algorithmen vorwiegend aus dem Bereich Data Analytics, die anhand von realen Daten aus dem Anwendungsgebiet Bahnautomatisierung evaluiert werden. CODA hilft einerseits Siemens, um den Bahnbetrieb sicherer und effizienter zu machen, und ermöglicht es andererseits einem jungen Forscher, eine Karriere in der industriellen Forschung zu entwickeln.&lt;/p>
&lt;p>The dissertation project CODA addresses new, important research questions to combine operation data and configuration models/data for optimization of system configuration (engineering, planning, construction, maintenance) and operation. The results of CODA will be novel analytics methods and algorithms which will be exemplary evaluated for railway automation, but will be applicable to other domains as well. CODA will help Siemens to make rail traffic safer and more efficient, and support a promising young researcher to develop a career in industrial research.&lt;/p>
&lt;h3 id="heading">&lt;/h3>
&lt;p> &lt;/p>
&lt;h3 id="term">Term&lt;/h3>
&lt;p>01.04.2016 - 31.03.2019&lt;/p>
&lt;h3 id="funding">Funding&lt;/h3>
&lt;p>FFG – Foerderschiene Industrienahe Dissertationen 2015&lt;/p>
&lt;h3 id="partner">Partner&lt;/h3>
&lt;ul class="partnerList">&lt;li>&lt;a href="http://www.siemens.com/entry/at/de/">SIEMENS AG Österreich&lt;/a>&lt;/li>&lt;/ul></description></item><item><title>Business Semantics on top of Process Technology</title><link>https://big.tuwien.ac.at/project/archive/business-semantics-on-top-of-process-technology/</link><pubDate>Tue, 19 May 2020 12:38:35 +0000</pubDate><guid>https://big.tuwien.ac.at/project/archive/business-semantics-on-top-of-process-technology/</guid><description>&lt;h3 id="topic">Topic&lt;/h3>
&lt;p>The BSopt project will deliver an integrated methodology for inter-organizational systems spanning from business models over business process models to their execution in a service-oriented architecture (SOA). Integrating business processes into a SOA is certainly a hot topic. However, most current approaches are limited to the technical process aspects, disregarding the economic drivers of the information society. In contrary, BSopt will consider the formalization of the semantics of new business models due to faster changing business environments, their support by appropriate business processes and their implementation in flexible architectures. We will incorporate state-of-the-art approaches to describe business models, business process models and deployment artifacts in SOAs. However, we will go beyond the state-of-the-art by connecting the dots between these approaches allowing for a semi-automatic mapping between them. This will result in an integrated methodology spanning over all layers that is based on a meta model incorporating the semantics of the assimilated approaches. Furthermore, we demonstrate the customization of the BSopt approach by integrating a domain (= industry) specific ontology by means of the print media industry. A critical point in reaching user acceptance is tool support for the BSopt methodology. Following advanced software engineering concepts, we will implement the integrated BSopt approach as a software factory based on a so-called domain specific language (DSL). For this purpose we have to use a meta-modeling tool, that allows us to specify the BSopt meta model within this tool. Furthermore, the software factory will guide a modeler in a wizard-driven style through the BSopt methodology requiring not as much modeling know-how as in traditional modeling languages such as UML. The meta-modeling tools being used in BSopt are the Microsoft DSL tools for Visual Studio and ADONIS. The goal of a software factory-based approach is creating high quality code in shorter time. Code created by the BSopt tools are deployment artifacts (BPEL, WSDL, XAML,etc..) to be consumed by existing software environments ¿ in our case the Oracle SOA Suite and the Microsoft Workflow Foundation. The BSopt approach will be validated by case studies in the print media industry.&lt;/p>
&lt;p>More information: &lt;a href="http://www.bsopt.at/">http://www.bsopt.at/&lt;/a>&lt;/p>
&lt;h3 id="term">Term&lt;/h3>
&lt;p>01.04.2008 - 30.09.2010&lt;/p>
&lt;h3 id="funding">Funding&lt;/h3>
&lt;p>Funded by the Austrian Federal Ministry of Transport, Innovation and Technology (BMVIT) and FFG under grant FIT-IT-815124&lt;/p>
&lt;h3 id="partner">Partner&lt;/h3>
&lt;ul class="partnerList">&lt;li>&lt;a href="http://www.mediaprint.at/">Mediaprint Zeitungs- u. Zeitschriftenverlag GmbH&lt;/a>&lt;/li>&lt;li>&lt;a href="http://www.big.tuwien.ac.at/projects/8">BOC Unternehmensberatung GmbH&lt;/a>&lt;/li>&lt;li>&lt;a href="http://www.big.tuwien.ac.at/projects/8">Thomas Gerhardt&lt;/a>&lt;/li>&lt;li>&lt;a href="http://www.paradigma.net/">Paradigma Unternehmensberatung&lt;/a>&lt;/li>&lt;/ul></description></item><item><title>Christian Doppler Laboratory for Model-Integrated Smart Production</title><link>https://big.tuwien.ac.at/project/archive/christian-doppler-laboratory-for-model-integrated-smart-production/</link><pubDate>Tue, 19 May 2020 12:38:35 +0000</pubDate><guid>https://big.tuwien.ac.at/project/archive/christian-doppler-laboratory-for-model-integrated-smart-production/</guid><description>&lt;h3 id="topic">Topic&lt;/h3>
&lt;p>Production systems are becoming more and more software-intensive, thus turning into cyber-physical production systems (CPPS). This is also highlighted and reflected by Industrie 4.0, which is seen as the next industrial revolution. As with the previous industrial revolutions, new demands have to be satisfied, e.g., virtually exploring variants, finding optimal solutions, and making dynamic runtime decisions, to allow companies to be more competitive. As a consequence, however, the complexity of CPPS is increasing. To deal with this increased complexity, modeling is a promising approach in this context. However, current modeling foundations and practices are still lacking behind the emerging requirements of Industrie 4.0. First of all, models are still defined and used in isolation within a specific discipline, although it is known that CPPS are inherently multi-disciplinary systems and their optimization has to take this into account. Moreover, models are considered as static entities, mostly used as system blueprints in the early design phases, but they are basically neglected in later lifecycle phases, which drastically limits their value during the systems‘ operation for propagating important runtime information back to engineering.&lt;/p>
&lt;p>The proposed Christian Doppler Laboratory (CDL) Model-Integrated Smart Production (CDL-MINT) will contribute to the foundations of modeling in general and in particular of modeling smart CPPS. The main goal is to reach a revolutionary new notion of models, so-called liquid models, which implies going from isolated and static descriptions to cooperative and evolutionary prescriptions. By doing so, we stimulate a paradigm shift in modeling knowledge creation, dissemination, and evaluation leading to truly model-integrated smart production.&lt;/p>
&lt;p>The work of CDL-MINT is divided into two project modules, whereby each will be conducted with one industrial partner. The topics of the two modules are all concerned with model-integrated smart production, thus using the notion of liquid models as a key research driver. Module 2 Cooperative Simulation Megamodels is focusing on the cooperative nature of models by providing schemes for managing related models and their co-simulations in order to optimize production systems. Module 3 Reactive Model Repositories is dealing with the extended usage of models also during operation time by providing a novel kind of model repository which allows for runtime monitoring, model mining, and design model enhancement. By this, both modules contribute to the notion of liquid models by providing (i) cooperation, and (ii) evolution mechanisms for models in general and in particular for the domain of CPPS. Consequently, these modules enable end-to-end integration of engineering which provides end-to-end transparency in real-time.&lt;/p>
&lt;p> &lt;/p>
&lt;p>More information: &lt;a href="https://cdl-mint.big.tuwien.ac.at/">https://cdl-mint.big.tuwien.ac.at/&lt;/a>&lt;/p>
&lt;h3 id="term">Term&lt;/h3>
&lt;p>01.01.2017 - 28.02.2019&lt;/p>
&lt;h3 id="funding">Funding&lt;/h3>
&lt;p>&lt;span class="input bigWidth">Christian Doppler Forschungsgesellschaft (CDG)&lt;/span>&lt;/p>
&lt;h3 id="partner">Partner&lt;/h3>
&lt;p>Certicon&lt;/p>
&lt;p>LieberLieber&lt;/p></description></item><item><title>Adaptable Model Versioning</title><link>https://big.tuwien.ac.at/project/archive/adaptable-model-versioning/</link><pubDate>Tue, 19 May 2020 12:38:34 +0000</pubDate><guid>https://big.tuwien.ac.at/project/archive/adaptable-model-versioning/</guid><description>&lt;h3 id="topic">Topic&lt;/h3>
&lt;p>The development of complex software systems requires appropriate abstraction mechanisms in terms of model-driven engineering techniques (MDE) and proper support for allowing developers to work in parallel in terms of version control systems (VCS). For realizing the vision of MDE, a bundle of standards for model transformations, model storage, and model exchange has been made available recently, whereas the versioning of models has not gained the necessary attention yet, although being of paramount importance for the success of MDE in practice. Existing VCS in the area of MDE suffer from three main deficiencies comprising erroneous conflict detection, unsupportive conflict resolution and inflexibility with respect to domain-specific modeling languages (DSLs) and associated tools. With AMOR (Adaptable Model Versioning) we propose novel semantic-based methods and techniques to leverage version control in the area of MDE. The innovations of AMOR are manifested in three key research goals. Firstly, AMOR aims at precise conflict detection, i.e. previously undetected as well as wrongly indicated conflicts should be avoided. For this, we incorporate knowledge about the type of modifications the models have undergone and knowledge about the semantics of the modeling concepts used. Secondly, AMOR focuses on an intelligent conflict resolution by providing techniques for the representation of conflicting modifications as well as relieving users from repetitive tasks by suggesting proper resolution strategies. Thirdly, AMOR targets at an adaptable versioning framework, empowering the user to flexibly balance between reasonable adaptation effort and proper versioning support while ensuring generic applicability to various DSLs and associated tools. The solutions to these challenges are realized by means of the AMOR prototype. The method for evaluating AMOR builds on three major pillars, comprising experiments, empirical studies and a case study, integrating AMOR into the commercial UML-tool Enterprise Architect. Thus, AMOR will represent a research test bed as well as an industrial showcase for further commercial exploitation.&lt;/p>
&lt;p>More information: &lt;a href="http://www.modelversioning.org">http://www.modelversioning.org&lt;/a>&lt;/p>
&lt;h3 id="term">Term&lt;/h3>
&lt;p>01.02.2009 - 30.09.2011&lt;/p>
&lt;h3 id="funding">Funding&lt;/h3>
&lt;p>Funded by the Austrian Federal Ministry of Transport, Innovation and Technology (BMVIT) and FFG under grant FIT-IT-819584.&lt;/p>
&lt;h3 id="partner">Partner&lt;/h3>
&lt;ul class="partnerList">&lt;li>&lt;a href="http://www.jku.at/">Johannes Kepler Universität Linz&lt;/a>&lt;/li>&lt;li>&lt;a href="http://www.sparxsystems.at/">SparxSystems Software GmbH&lt;/a>&lt;/li>&lt;/ul></description></item><item><title>Advanced software-based seRvice provisioning and migraTIon of legacy SofTware</title><link>https://big.tuwien.ac.at/project/archive/advanced-software-based-service-provisioning-and-migration-of-legacy-software/</link><pubDate>Tue, 19 May 2020 12:38:34 +0000</pubDate><guid>https://big.tuwien.ac.at/project/archive/advanced-software-based-service-provisioning-and-migration-of-legacy-software/</guid><description>&lt;h3 id="topic">Topic&lt;/h3>
&lt;p>Successful software has to evolve to keep it compatible and up to date. Up to 90% of software cost is spent on maintenance and of this 75% is spent on the development of new features for staying competitive. The industry progresses through periods of incremental development interlaced with true paradigm shifts. We are currently experiencing one of these paradigm shifts, as remarked by the European Commission: “The speed of change in Internet technologies continues to be impressive. Software is becoming more and more pervasive: it runs on the devices that we use every day …[opening] a new world of possible applications” cf. Cloud computing, Internet of Services and Advanced Software Engineering, European Union, 2011 (doi:10.2759/47598).&lt;/p>
&lt;p>Accordingly, more and more traditional software vendors notice the need to transform their current business and technology model in order to remain competitive. Software-as-a-Service (SaaS) is seen as the most promising way to achieve this change. However, this transition from Software-off-the-shelf (often residing as legacy applications) to SaaS is a tremendous challenge comprising business, application and technical issues. Having an automated, vendor, technology and hardware independent way to migrate an application would permit the software to evolve easily even in case of transition to new paradigms.&lt;/p>
&lt;p>ARTIST proposes a software migration approach covering the premigration and postmigration phases. The premigration phase analyzes the technical and non-technical consequences of migrations, supporting the decision-making process on how a migration should be done. The migration phase itself is based on Model Driven Engineering techniques to automate the reverse engineering of the legacy applications to platform independent models. These models are the input for the forward engineering process to generate and deploy modernized applications and to support future migrations. In the postmigration phase, the modernized applications are certified with respect to the stated goals of the premigration phase.&lt;/p>
&lt;p>ARTIST will reduce the risk, time and cost of migrating legacy software. It will lower the barriers for companies (with existing software) wanting to take advantage of the latest technologies and business models, particularly when considering the current benefits of Cloud Computing and SaaS.&lt;/p>
&lt;p>More information: &lt;a href="http://www.artist-project.eu">http://www.artist-project.eu&lt;/a>&lt;/p>
&lt;h3 id="term">Term&lt;/h3>
&lt;p>01.10.2012 - 30.09.2015&lt;/p>
&lt;h3 id="funding">Funding&lt;/h3>
&lt;p>EU FP-7 project, grant number: 317859.&lt;/p>
&lt;h3 id="partner">Partner&lt;/h3>
&lt;ul class="partnerList">&lt;li>&lt;a href="http://atos.net/">ATOS SPAIN&lt;/a>&lt;/li>&lt;li>&lt;a href="http://www.tecnalia.com/">FUNDACIÓN TECNALIA RESEARCH &amp;amp; INNOVATION&lt;/a>&lt;/li>&lt;li>&lt;a href="http://www.inria.fr/">INSTITUT NATIONAL DE RECHERCHE EN INFORMATIQUE ET AUTOMATIQUE&lt;/a>&lt;/li>&lt;li>&lt;a href="http://www.fraunhofer.de/">FRAUNHOFER-GESELLSCHAFT ZUR FOERDERUNG DER ANGEWANDTEN FORSCHUNG E.V&lt;/a>&lt;/li>&lt;li>&lt;a href="http://www.eng.it/web/eng/home">Engineering Ingegneria Informatica SpA&lt;/a>&lt;/li>&lt;li>&lt;a href="http://www.iccs.gr/eng/">Institute of Communication and Computer Systems&lt;/a>&lt;/li>&lt;li>&lt;a href="http://www.sparxsystems.at/">SparxSystems Software GmbH&lt;/a>&lt;/li>&lt;li>&lt;a href="http://www.atc.gr/">ATHENS TECHNOLOGY CENTER SA &lt;/a>&lt;/li>&lt;li>&lt;a href="http://www.spikes.be/">Spikes NV &lt;/a>&lt;/li>&lt;/ul></description></item><item><title>Towards Systematic and Efficient Language Engineering for xDSMLs</title><link>https://big.tuwien.ac.at/project/archive/towards-systematic-and-efficient-language-engineering-for-xdsmls/</link><pubDate>Tue, 19 May 2020 12:38:34 +0000</pubDate><guid>https://big.tuwien.ac.at/project/archive/towards-systematic-and-efficient-language-engineering-for-xdsmls/</guid><description>&lt;h3 id="topic">Topic&lt;/h3>
&lt;p>Domain-specific modeling languages are increasingly being developed to continuously leverage the domain-specific expertise of the various stakeholders involved in the development of complex software-intensive system as, for instance, found in the automation, production, and automotive domains. Although there are many examples of the successful adoption of DSMLs to improve development productivity and system quality, it has been also recognized that the development of DSMLs is itself a challenging and significant software engineering task. In this project, we focus on challenges associated with the development of executable DSMLs (xDSMLs) that support the model-level analysis of complex systems through model execution. In particular, the main goal of this project is to develop a systematic approach for engineering xDSMLs facilitating the automated development of domain-specific model analysis tooling for xDSMLs.&lt;/p>
&lt;h3 id="term">Term&lt;/h3>
&lt;p>01.01.2017 - 31.12.2018&lt;/p>
&lt;h3 id="funding">Funding&lt;/h3>
&lt;p>Funded by the Austrian Agency for Cooperation in Education and Research (OeAD-GmbH) under grand number FR 08/2017.&lt;/p>
&lt;h3 id="partner">Partner&lt;/h3>
&lt;p>
&lt;a href="http://www.inria.fr/centre/rennes" target="_blank" rel="noopener">INRIA Rennes&lt;/a>&lt;/p></description></item><item><title>Admina.at goes Austria</title><link>https://big.tuwien.ac.at/project/archive/admina-at-goes-austria/</link><pubDate>Tue, 19 May 2020 12:38:33 +0000</pubDate><guid>https://big.tuwien.ac.at/project/archive/admina-at-goes-austria/</guid><description>&lt;h3 id="topic">Topic&lt;/h3>
&lt;p>Admina is the short female form of system administrator. The Admina.at project offered by the Women’s Postgraduate College for Internet Technologies provides a number of hands-on practical experience system administation workshops, created and held by women exclusively for women. Admina.at follows the example of the highly successful admina project created 1995 at the University of Hamburg. Admina.at workshops offer currect, immediately useful computer science knowledge outside of the regulations and exam pressure of the ordinary university course program. The focus on practical application on the one hand rapidly gives the participants a sense of achievement and allows them to identify their personal strengths, while on the other hand it also emphasizes the relevance of theoretical knowledge. Admina.at workshops are organized in small groups, allowing strong individual support for every participant. The workshops are offered on two different levels, for teenagers and university students. Their main focus lies on improving the communication between female students of the same peer group, thus encouraging networking activities, which are crucial for success in the academic and the professional world. Admina.at introduces the workshop participants to the large variety of topics in the world of computer science and hopes to stimulate their interest. Students at the workshops have fun and make new friends, while at the same time learning useful skills, all in line with the project’s goals to increase the number of female beginners as well as graduates at the Faculty of Informatics as well as improving the students‘ academic success and career entry opportunities. Currently, Admina.at offers the following courses: * PC Hardware. How to take a computer apart and put it back together again. Includes the characteristics of the components, installation and basic configuration of an operating system, command line interaction, and tipps and advice for buying hardware and trouble shooting.&lt;/p>
&lt;h3 id="term">Term&lt;/h3>
&lt;p>01.12.2005 - 30.09.2007&lt;/p></description></item><item><title>Conflict-tolerant Model Versioning</title><link>https://big.tuwien.ac.at/phd-thesis/archive/conflict-tolerant-model-versioning/</link><pubDate>Tue, 19 May 2020 12:38:30 +0000</pubDate><guid>https://big.tuwien.ac.at/phd-thesis/archive/conflict-tolerant-model-versioning/</guid><description>&lt;p>This work has been finished in December 2011.&lt;/p>
&lt;p>Model-driven software engineering (MDSE), which has recently gained momentum in academia as well as in industry, changed the way in which modern software systems are built. In MDSE, the task of programming, i.e., writing code in a textual programming language, is replaced by modeling in a language such as the Unified Modeling Language (UML). The powerful abstraction mechanisms of models are not only used for documentation purposes, but also for compiling executable code directly out of models. With the rise of MDSE, several problems solved for traditional software engineering became urgent again because well established solutions are not directly transferable from code to models. Among others, the collaborative development of models is currently only limited supported by modeling tools and, consequently, it is mostly a one-(wo)man show. Especially in the field of model versioning, which supports the asynchronous modification of modeling artifacts by multiple developers, only first solutions start to emerge.&lt;/p>
&lt;p>The urgent need for a suitable infrastructure supporting effective model versioning has been widely recognized by researchers as well as practitioners. Currently, however, there is a lack of empirical studies on the needs of software developers in practice concerning the collaborative development of software systems. The first contribution of this thesis tackles this problem and provides an extensive survey about versioning in practice by the means of an online questionnaire and qualitative expert interviews. One result of the empirical study shows that conflicts due to parallel modifications are considered harmful and, thus, developers try to avoid them. Conflicts, however, should not be seen as negative result of collaboration but as chance for discussing ideas and for improving the system under development. As consequence, the second contribution is a conflict-tolerant model versioning approach, where the developers may commit their changes in the central repository without worrying about possible conflicts. This approach merges two or more parallel versions by applying dedicated merge rules and, by this, it incorporates all modifications of the developers. This builds a good basis for discussing and resolving conflicts collaboratively. Finally, when resolving conflicts a high degree of user interaction is required. When setting models under version control with state-of-the art tools, however, conflicts are hardly accessible for the users. Also the empirical study has shown, that current version control systems lack for a dedicated representation and visualization. Moreover, user support is required to better understand the reasons behind the conflicting changes. The third contribution tackles these deficiencies by visualizing occurred conflicts in terms of model annotations and enriching them automatically with additional meta information to better understand the parallel evolution of the model under development. The implemented prototype is evaluated by means of a quasi-experimental study, which demonstrates the advantages of developing models in a collaborative manner.&lt;/p>
&lt;p>Abstract and paper may be found in our &lt;a class="external" href="http://publik.tuwien.ac.at/showentry.php?ID=209022&amp;amp;lang=2">publication database&lt;/a>.&lt;/p></description></item><item><title>From Mining to Mapping and Roundtrip Transformations – A Systematic Approach to Model-based Tool Integration</title><link>https://big.tuwien.ac.at/phd-thesis/archive/from-mining-to-mapping-and-roundtrip-transformations-a-systematic-approach-to-model-based-tool-integration/</link><pubDate>Tue, 19 May 2020 12:38:30 +0000</pubDate><guid>https://big.tuwien.ac.at/phd-thesis/archive/from-mining-to-mapping-and-roundtrip-transformations-a-systematic-approach-to-model-based-tool-integration/</guid><description>&lt;p>This work has been finished in March 2008.&lt;/p>
&lt;p>Model-Driven Engineering (MDE) gains momentum in academia as well as in practice. A wide variety of modeling tools is already available supporting different development tasks and advocating different modeling languages. In order to fully exploit the potential of MDE, modeling tools must work in combination, i.e., a seamless exchange of models between different modeling tools is crucial for MDE. Current best practices to achieve interoperability use model transformation languages to realize necessary mappings between the metamodels defining the modeling languages supported by different tools. However, the development of such mappings is still done in an ad-hoc and implementation-oriented manner which simply does not scale for large integration scenarios. The reason for this is twofold. First, various modeling languages are not based on metamodeling standards but instead define proprietary languages rather focused on notational aspects. And second, existing model transformation languages both do not support expressing mappings on a high-level of abstraction and lack appropriate reuse mechanisms for already existing integration knowledge.&lt;/p>
&lt;p>This thesis contributes to the above mentioned problems. It proposes a comprehensive approach for realizing model-based tool integration, which is inspired from techniques originating from the field of database integration, but employed in the context of MDE. For tackling the problem of missing metamodel descriptions, a semi-automatic approach for mining metamodels and models from textual language definitions is presented, being a prerequisite for the subsequent steps which are based on metamodels and models, only. For raising the level of abstraction and for ensuring the reuse of mappings between metamodels, a framework is proposed for building, applying, and executing reusable mapping operators. To demonstrate the applicability of the framework, it is applied to the definition of mapping operators which are intended to resolve typical structural heterogeneities occurring between the core concepts of metamodels. Finally, for ensuring roundtrip capabilities of transformations, two approaches are proposed evolving non-roundtripping transformations with roundtrip capabilities.&lt;/p>
&lt;p>Abstract and paper may be found in our &lt;a class="external" href="http://publik.tuwien.ac.at/showentry.php?ID=141768&amp;amp;lang=2">publication database&lt;/a>.&lt;/p></description></item><item><title>Conceptual Models and Model-Based Business Metadata to Bridge the Gap between Data Warehouses and Organizations</title><link>https://big.tuwien.ac.at/phd-thesis/archive/conceptual-models-and-model-based-business-metadata-to-bridge-the-gap-between-data-warehouses-and-organizations/</link><pubDate>Tue, 19 May 2020 12:38:29 +0000</pubDate><guid>https://big.tuwien.ac.at/phd-thesis/archive/conceptual-models-and-model-based-business-metadata-to-bridge-the-gap-between-data-warehouses-and-organizations/</guid><description>&lt;p>This work has been finished in November 2007.&lt;/p>
&lt;p>Data warehouse systems are used by decision makers for performance measurement and decision support. Measures such as the number of transactions per customer or the increase of sales during a promotion are used to recognize warning signs and to decide on future investments with regard to the strategic goals of the organization.&lt;/p>
&lt;p>Currently, the main focus of the data warehouse research field is on database issues. The data warehouse’s interaction with the organization and the way it supports the organization’s strategic goals have not yet been considered in depth. Conceptual models that describe the data warehouse from various viewpoints, including an outside view of the data warehouse system, its environment and expected usage, are missing. Moreover, even though the data in the data warehouse by its very nature has to be closely related to the concerns of the organization, current data warehouses also lack sufficient business meta-data that would inform users about the organizational context and implications of what they are analyzing.&lt;/p>
&lt;p>This thesis targets the relationship between the data warehouse and the structure, behavior, and goals of the organization.&lt;/p>
&lt;p>In order to describe this relationship, a conceptual modeling language was developed. It consists of models for describing the interdependencies between data warehouses and business processes, including so-called active data warehouse solutions; a model for identifying business objects such as customers and products in the data warehouse data model, and for constructing data models that comply to the state models of such business objects; as well as a model of data warehouse usage, which includes modeling the users, user groups, and user skill levels, the intensity with which they use the data warehouse infrastructure, temporal issues such as the required time and urgency of data access, and indicators of the relative importance of data warehouse usage.&lt;/p>
&lt;p>This thesis also introduces an approach to using models to enhance the way users access the data in the data warehouse. It presents model-based business metadata, which links enterprise models such as business process models or goal models to the data model of the data warehouse through the mechanism of model weaving. A prototype illustrating how models can be weaved and used for business metadata in a business intelligence tool has been developed as part of this thesis.&lt;/p>
&lt;p> &lt;/p>
&lt;p>Download the
&lt;a href="https://www.big.tuwien.ac.at/app/uploads/2016/10/Stefanov_pdf.pdf" target="_blank" rel="noopener">paper&lt;/a>&lt;/p></description></item><item><title>Model Transformation by Example</title><link>https://big.tuwien.ac.at/phd-thesis/archive/model-transformation-by-example/</link><pubDate>Tue, 19 May 2020 12:38:29 +0000</pubDate><guid>https://big.tuwien.ac.at/phd-thesis/archive/model-transformation-by-example/</guid><description>&lt;p>This work has been finished in May 2008.&lt;/p>
&lt;p>Model-Driven Engineering (MDE) is getting more and more attention as a viable alternative to the traditional code-centric software development paradigm. With its progress, several model transformation approaches and languages have been developed in the past years. Most of these approaches are metamodel-based and, therefore, require knowledge of the abstract syntax of the modeling languages, which in contrast is not necessary for defining domain models using the concrete syntax of the respective languages.&lt;/p>
&lt;p>Based on the by-example paradigm, we propose Model Transformation By-Example (MTBE), to cope with shortcomings of current model transformation approaches. Our approach allows the user to define semantic correspondences between concrete syntax elements with the help of special mapping operators. This is more user-friendly than directly specifying model transformation rules and mappings on the metamodel level. In general, the user’s knowledge about the notation of the modeling language and the meaning of mapping operators is sufficient for the definition of model transformations. The definition of mapping operators is subject to extension, which has been applied for the definition of mapping operators for the structural and the behavioral modeling domain. However, to keep things transparent and user-friendly, only a minimal set of mapping operators has been implemented. To compensate for the additional expressiveness inherent in common model transformation languages we apply reasoning algorithms on the models represented in concrete as well as in abstract syntax and on the metamodels generating adequate transformation code.&lt;/p>
&lt;p>In order to fulfill the requirements for a user-friendly application of MTBE, proper tool support and methods to guide the mapping and model transformation generation tasks are a must. Hence, a framework for MTBE was designed that builds on state-of-the-art MDE tools on the Eclipse platform, such as the Eclipse Modeling Framework (EMF), the Graphical Modeling Framework (GMF), the Atlas Transformation Language (ATL), and the Atlas Model Weaver (AMW). The decision to base our implementation on top of Eclipse and further Eclipse projects was driven by the fact, that there is a huge community we can address with our MTBE plug-in.&lt;/p>
&lt;p>Finally, we evaluate our approach by means of two case studies covering the structural as well as behavioral modeling language domain.&lt;/p>
&lt;p> &lt;/p>
&lt;p>Download the
&lt;a href="https://www.big.tuwien.ac.at/app/uploads/2016/10/Strommer_M.pdf" target="_blank" rel="noopener">paper&lt;/a>&lt;/p></description></item><item><title>Towards a Sustainable DWH Approach for Evidence-Based Healthcare</title><link>https://big.tuwien.ac.at/phd-thesis/archive/towards-a-sustainable-dwh-approach-for-evidence-based-healthcare/</link><pubDate>Tue, 19 May 2020 12:38:29 +0000</pubDate><guid>https://big.tuwien.ac.at/phd-thesis/archive/towards-a-sustainable-dwh-approach-for-evidence-based-healthcare/</guid><description>&lt;p>This work has been finished in September 2007.&lt;/p>
&lt;p>The healthcare industry is one of the world’s largest, fastest developing and most information-rich industries. Rapid growth of information technologies has brought immense opportunities for patient data sharing, development and dissemination of evidence-based medical knowledge and analysis across distributed, heterogeneous healthcare data sources.&lt;/p>
&lt;p>In contrast to other industries, where data warehouses have been successfully applied, healthcare is an area in which the information technology had only been able to permeate the administrative and logistic aspects of information processing. The growing need for integrated healthcare has led this industry to open towards adoption of extensive clinical decision support systems.&lt;/p>
&lt;p>Evidence-based medicine (EBM) offers a collection of proven best practise guidelines for recommending drugs and medical treatments. This thesis states that the way data warehouse (DWH) technology can facilitate EBM is twofold: (1) by supporting the rule development process, and (2) by providing the EBM-enriched knowledge base to support the decision-making process of the care givers.&lt;/p>
&lt;p>With respect to (1), we explain that data warehousing and data mining support the creation of the evidence-based rules by providing a platform and tools for knowledge discovery and pattern recognition. Large amounts of data can be analysed to confirm known or discover unknown trends and correlations in data.&lt;/p>
&lt;p>Regarding (2), we argue that the care giving process can benefit significantly from the application of DWH technology at the point of care. Given an integrated knowledge base, built upon broad variety of patient-related information sources and incorporating evidence-based rules, our approach offers a unique decision support for the practitioners in their every-day work.&lt;/p>
&lt;p>In order to guarantee the confidentiality of patient data in today´s increasingly information-based, multi-site health delivery environment, this thesis recommends a federated DWH approach instead of collecting data from remote sources into a centralized system. We endorse the application of de-personalisation, pseudonymization and role-based access mechanism for protection of sensitive healthcare data.&lt;/p>
&lt;p>This dissertation is intended to provide a roadmap for achieving sustainable healthcare decision support system based on federated data warehouses, facilitating evidence-based medicine that safeguards patient´s personal privacy. It postulates four rules to follow when building a modern medical decision support system and we hope that its advisory nature will prove to be helpful in designing future healthcare projects.&lt;/p>
&lt;p> &lt;/p>
&lt;p>Download the
&lt;a href="https://www.big.tuwien.ac.at/app/uploads/2016/10/Stolba_N.pdf" target="_blank" rel="noopener">paper&lt;/a>&lt;/p></description></item><item><title>Model Driven Product Line Engineering: Core Asset and Process Implications</title><link>https://big.tuwien.ac.at/phd-thesis/archive/model-driven-product-line-engineering-core-asset-and-process-implications/</link><pubDate>Tue, 19 May 2020 12:38:28 +0000</pubDate><guid>https://big.tuwien.ac.at/phd-thesis/archive/model-driven-product-line-engineering-core-asset-and-process-implications/</guid><description>&lt;p>This work has been finished in February 2011.&lt;/p>
&lt;p>Reuse is at the heart of major improvements in productivity and quality in Software Engineering. Both Model Driven Engineering (MDE) and Software Product Line Engineering (SPLE) are software development paradigm that promote reuse. Specifically, they promote systematic reuse and a departure from craftsmanship towards an industrialization of the software development process. MDE and SPLE have established their benefits separately. Their combination in Model Driven Product Line Engineering (MDPLE), gathers together the advantages of both.&lt;/p>
&lt;p> &lt;/p></description></item><item><title>Modelling Ubiquitous Web Applications - Requirements and Concepts</title><link>https://big.tuwien.ac.at/phd-thesis/archive/modelling-ubiquitous-web-applications-requirements-and-concepts/</link><pubDate>Tue, 19 May 2020 12:38:28 +0000</pubDate><guid>https://big.tuwien.ac.at/phd-thesis/archive/modelling-ubiquitous-web-applications-requirements-and-concepts/</guid><description>&lt;p>This work has been finished in November 2001.&lt;/p>
&lt;p>E-commerce and m-commerce have dramatically boosted the demand for services which enable ubiquitous access. Ubiquity offers new opportunities and challenges in terms of time-aware, location-aware, device-aware and personalized services. The fundamental objective of ubiquitous web applications is to provide services not only to people at any time, any where, with any media but specifically to communicate the right thing at the right time in the right way. The user should be enabled to interact efficiently with the application despite restrictions in the physical environment, thus preserving semantic equivalence of services and to take advantage from knowledge about the situation of use, leading to semantic enhancement of services. The prerequisite for this is that the application is aware of it`s context. For developing ubiquitous web applications, one must understand what context is to determine its relevancy and how it can be exploited for adapting the provided services towards this context, called customisation. Not least to customisation, the development of ubiquitous web applications is far from easy and calls for appropriate modelling techniques. There exists, however, only a few methods dedicated to the modelling of traditional web applications neglecting to a great extent ubiquity in terms of customisation.&lt;/p>
&lt;p>This thesis proposes a modelling method for ubiquitous web applications. Customisation is regarded as a new modelling dimension, influencing all other dimensions of ubiquitous web application modelling. As a prerequisite for supporting customisaiton, a set of generic models is introduced comprising a context model and arule model, togehter with several sub models. Generic means that the models provide, in the sense of an object-oriented framework, pre-defined classes and language constructs in order to model customisation. For separation of concerns the application is divided into a stable part, comprising the default, i.e., context-independent structure and behaviour and a variable, context-dependent part, thus being subject to adaptations. A set of generic adaptation operations is provided which can be complemented by application specific ones. These adaptation operations can be integrated into the ubiquitous web application on the basis of adaptation hooks. A customisation toolkit in terms of a customisation rule editor and browser supports an integrated modelling process and facilitates reusability on the basis of a repository of customisation rules, macros and patterns. Finally, a process is introduced, covering the whole task of customisation modelling, with a special focus on reusability, herewith providing a holistic view on the development process of ubiquitous web applications.&lt;/p>
&lt;p> &lt;/p></description></item><item><title>aspectUWA - Applying Aspect-Orientation to the Model-Driven Development of Ubiquitous Web Applications</title><link>https://big.tuwien.ac.at/phd-thesis/archive/aspectuwa-applying-aspect-orientation-to-the-model-driven-development-of-ubiquitous-web-applications/</link><pubDate>Tue, 19 May 2020 12:38:27 +0000</pubDate><guid>https://big.tuwien.ac.at/phd-thesis/archive/aspectuwa-applying-aspect-orientation-to-the-model-driven-development-of-ubiquitous-web-applications/</guid><description>&lt;p>This work has been finished in October 2007.&lt;/p>
&lt;p>Ubiquitous web applications (UWA) are a new type of web applications which are accessed in various contexts, i.e., through different devices, by users with various interests, at anytime from anyplace around the globe. In this respect, customization functionality exploits information on this context of use in order to adapt the application’s services accordingly. In web application development, customization is considered a new dimension which increases complexity by ”crosscutting” the content, hypertext, and presentation levels of a web application. Hence, from a software engineering point of view, a systematic development of UWAs on the basis of models is crucial. In model-driven engineering (MDE), models are employed ”as programs” to (semi-) automatically generate applications, which results in more efficient development processes as well as better maintainability and evolution of software. Customization functionality, however, is typically intermingled with the core functionality in a web application model, having a negative effect on understandability, reuse, maintenance and evolution. The aspect-orientation paradigm provides a new way of modularizing crosscutting concerns such as customization within so-called aspects, as well as the necessary means for composing the previously separated concerns in order to obtain the complete application model. There are already some web modeling approaches dealing with the ubiquitous nature of web applications, amongst them, first proposals to use aspect-orientation. Nevertheless, these approaches suffer from the following problems: First, they don’t consider the crosscutting nature of customization comprehensively, but for the hypertext level, only. Second, just very basic aspect-oriented modeling (AOM) concepts are used, resulting in less powerful mechanisms for separating customization. Third, composition of concerns is not regarded for the modeling level. And fourth, model-driven development of UWAs in the sense of MDE is still limited due to missing metamodel specifications and lack of tool support.&lt;/p>
&lt;p>The overall aim of this thesis is the exhaustive use of aspect-orientation as driving paradigm for comprehensively modeling customization aspect separately from all web application levels as well as providing means for composing the aspect with the web application model. Therefore, this thesis proposes the aspectUWA approach, which suggests a generic framework for extending existing web modeling languages with AOM concepts within the realms of MDE. In the context of this thesis, aspectUWA is applied to the web modeling anguageWebML, which doesn’t allow to separately model customization. The major contributions of this thesis are as follows: (i) A Conceptual Reference Model (CRM) for AOM has been developed to form the aforementioned general framework. (ii) A metamodel for WebML has been semi-automatically generated from an existing DTD-based language specification in order to allow for MDE. (iii) The aspectWebML language has been desiged on basis of the CRM and represents WebML’s port to AOM allowing for modeling customization separately as well as for composing the customization aspect with the rest of the web application model. (iv) An initial set of guidelines to be used for modeling customization within aspectWebML is proposed. And (v), the aspectWebML Modeling Environment provides the often missing tool support for modeling crosscutting concerns as well as their composition.&lt;/p>
&lt;p> &lt;/p>
&lt;p>Download the
&lt;a href="https://www.big.tuwien.ac.at/app/uploads/2016/10/Schauerhuber_A.pdf" target="_blank" rel="noopener">paper&lt;/a>&lt;/p></description></item><item><title>Testing and Debugging of Model Transformations</title><link>https://big.tuwien.ac.at/phd-thesis/archive/testing-and-debugging-of-model-transformations/</link><pubDate>Tue, 19 May 2020 12:38:27 +0000</pubDate><guid>https://big.tuwien.ac.at/phd-thesis/archive/testing-and-debugging-of-model-transformations/</guid><description>&lt;p>This work has been finished in December 2011.&lt;/p>
&lt;p>Model-Driven Engineering (MDE) proposes an active use of models to conduct the different phases of software development. The major vision is a shift from the idea of “everything is an object” in the object-oriented paradigm to the idea of “everything is a model” in MDE. Following this vision, it becomes obvious that transformations between models play a key role. Just like any other software, transformations should be engineered using sound and robust engineering techniques. However, current engineering techniques focus on the implementation phase of transformations, but fail to provide means for the analysis, design, testing and debugging phases.&lt;/p>
&lt;p>In particular, to support the analysis and design phase, means are needed that allow to formally describe the requirements of a certain transformation in order to allow for automatic validation in the testing phase. In case of a failure, additional means are needed to efficiently debug model transformations. However, current transformation languages provide only scarce support for debugging. This is mainly due to the fact that low-level information of an according execution engine is provided only, e.g., variable values. Finally, the operational semantics is hidden by these execution engines, which further aggravates finding failures and hampers understanding of transformation specifications.&lt;/p>
&lt;p>To tackle the aforementioned limitations, this thesis provides three main contributions. First, a declarative, visual language called PAMOMO is proposed, which allows to formally specify requirements on model transformations by means of contracts. To test if a model transformation fulfills the specified requirements, the contracts are compiled into check-only QVT Relations, providing dedicated error traces in case a contract fails. These traces may then be used as hints for debugging. To support debugging, Transformation Nets as a DSL on top of CPNs are proposed, which provide a dedicated runtime model for model transformations, making the hidden operational semantics explicit as a second major contribution. Finally, based on this runtime model various means of debugging are presented as a third contribution.&lt;/p>
&lt;p>To evaluate the contributions, relations to competing approaches are drawn in a first step. Second, case studies are used to show the applicability of the presented approaches. To evaluate the runtime model, the operational semantics of dedicated transformation languages is made explicit in terms of Transformation Nets. Finally, the debugging support is evaluated again by case studies and a first user study.&lt;/p>
&lt;p>Abstract and paper may be found in our &lt;a class="external" href="http://publik.tuwien.ac.at/showentry.php?ID=209018&amp;amp;lang=2">publication database&lt;/a>.&lt;/p></description></item><item><title>A Tour on TriGS - Development of an Active System and Application of Rule Patterns for Active Database Design</title><link>https://big.tuwien.ac.at/phd-thesis/archive/a-tour-on-trigs-development-of-an-active-system-and-application-of-rule-patterns-for-active-database-design/</link><pubDate>Tue, 19 May 2020 12:38:26 +0000</pubDate><guid>https://big.tuwien.ac.at/phd-thesis/archive/a-tour-on-trigs-development-of-an-active-system-and-application-of-rule-patterns-for-active-database-design/</guid><description>&lt;p>This work has been finished in September 1996.&lt;/p></description></item><item><title>BOOM: An Approach for an Object-Oriented Fourth Generation System</title><link>https://big.tuwien.ac.at/phd-thesis/archive/boom-an-approach-for-an-object-oriented-fourth-generation-system/</link><pubDate>Tue, 19 May 2020 12:38:26 +0000</pubDate><guid>https://big.tuwien.ac.at/phd-thesis/archive/boom-an-approach-for-an-object-oriented-fourth-generation-system/</guid><description>&lt;p>This work has been finished in March 1998.&lt;/p></description></item><item><title>Approximate Constraint Logic Programming</title><link>https://big.tuwien.ac.at/phd-thesis/archive/approximate-constraint-logic-programming/</link><pubDate>Tue, 19 May 2020 12:38:25 +0000</pubDate><guid>https://big.tuwien.ac.at/phd-thesis/archive/approximate-constraint-logic-programming/</guid><description>&lt;p>This work has been finished in June 1998.&lt;/p>
&lt;p>This thesis describes results that can be used to improve constraint logic programming (CLP) by increasing its expressivity and efficiency. This is done by introducing&lt;/p>
&lt;p>into constraint logic programming and providing a computer implementation of a CLP system using these inprovements. For reaching this goal, work has been done in the following main areas, corresponding to the three parts of the term „constraint logic programming“:&lt;/p>
&lt;p>Logic: An extension of the first-order predicate language, defining the notions of „approximate solution set“ and „approximate quantifier“ has been introduced.&lt;/p>
&lt;p>Programming (Language Design and Implementation): The syntax and semantics of a new constraint logic programming language allowing first-order constraints with approximate quantifiers and approximate answers has been defined and implemented.&lt;/p>
&lt;p>Constraint (Solving): A new algorithm for approximately solving first-order constraints with approximate quantifiers has been devised. The algorithm has been implemented over the domain of the real numbers.&lt;/p>
&lt;p> &lt;/p></description></item><item><title>De Modo Operandi: Towards the Interoperability of Workflow Information</title><link>https://big.tuwien.ac.at/phd-thesis/archive/de-modo-operandi-towards-the-interoperability-of-workflow-information/</link><pubDate>Tue, 19 May 2020 12:38:25 +0000</pubDate><guid>https://big.tuwien.ac.at/phd-thesis/archive/de-modo-operandi-towards-the-interoperability-of-workflow-information/</guid><description>&lt;p>This work has been finished in April 1995.&lt;/p>
&lt;p>The research reported in this dissertation deals with workflow management and electronic publishing. Recent developments like the evolvement of international standards, advanced communication services, as well as new delivery platforms, have resulted in a bewildering number of workflow systems, each of them being a proprietary solution. The consequences are non-interoperable systems where workflow information cannot be exchanged, a fact which does backfire with the ideas of recent developments.&lt;/p>
&lt;p>HyTime is an international standard for the exchange of time-dependent, structured information. So-called HyTime architectural forms were developed for representing workflow information. Through this as well as through additional layers in the architecture of our workflow system we enable the interoperability of workflow information between different systems.&lt;/p>
&lt;p>We investigate the publishing process and derive requirements for system support. Existing systems, both research prototypes as well as commercial systems are subject of the following investigation. Based on these investigations we have specified an architecture for workflow systems. Specification and Implementation of a prototypical system developed in Visualworks\Smalltalk demonstrate the usability of the concept by a running system. The role of workflow within CSCW (Computer Supported Cooperative Work) is investigated. Concluding remarks including the significance of our approach as well as future work finish the dissertation.&lt;/p>
&lt;p> &lt;/p></description></item><item><title>TriGSflow - Workflow Management Based on Active Object-Oriented Database Systems and Extended Transaction Mechanisms</title><link>https://big.tuwien.ac.at/phd-thesis/archive/trigsflow-workflow-management-based-on-active-object-oriented-database-systems-and-extended-transaction-mechanisms/</link><pubDate>Tue, 19 May 2020 12:38:25 +0000</pubDate><guid>https://big.tuwien.ac.at/phd-thesis/archive/trigsflow-workflow-management-based-on-active-object-oriented-database-systems-and-extended-transaction-mechanisms/</guid><description>&lt;p>This work has been finished in February 1997.&lt;/p>
&lt;p>Effective business process management is a key success factor of today’s organizations acting in global markets. Their business processes have to dynamically adapt to changing requirements while executing in a consistent and reliable manner, even at the presence of activities performing concurrently. This book addresses the very vivid area of workflow management which provides a promising technology to solve these problems. The first part of the book describes a prototype workflow management system that gains flexibility and adaptability by building on object-oriented database technologies, Event-Condition-Action rules, and the role concept. The second part proposes an extension to the well-known nested transaction model that addresses the specific consistency and reliability requirements of workflow management systems.&lt;/p>
&lt;p>The book is directed likewise at researchers and practitioners interested in the broad field of workflow technology. It gives a comprehensive survey of the various aspects of business process research. The overview of prominent representatives of commercial workflow management systems and the rich bibliography provide an invaluable guide for further reading&lt;/p>
&lt;p> &lt;/p></description></item><item><title>A Four Level Architecture for Hypermedia Database Management Systems</title><link>https://big.tuwien.ac.at/phd-thesis/archive/a-four-level-architecture-for-hypermedia-database-management-systems/</link><pubDate>Tue, 19 May 2020 12:38:24 +0000</pubDate><guid>https://big.tuwien.ac.at/phd-thesis/archive/a-four-level-architecture-for-hypermedia-database-management-systems/</guid><description>&lt;p>This work has been finished in March 1998.&lt;/p>
&lt;p>In this thesis the Hypermedia Database Management System (HyperD) Architecture for hypermedia database management systems and the classes needed to implement the architecture are described. The HyperD architecture allows to model the structure as well as the content of hypermedia data in a consistent, highly flexible, and object oriented manner. The HyperD architecture can be extended easily to accommodate new media types and is flexible enough to model domain specific information. This thesis also describes implementation issues regarding a prototypical implementation for images.&lt;/p>
&lt;p>One focus of the work is to show that the concept of physical and logical data independence can be applied beneficially to hypermedia database management systems. The approach to physical data independence presented here takes the characteristics of multimedia data into account and allows a controlled reuse of multimedia objects. The approach to logical data independence presented in this thesis is highly flexible and allows a clean separation of application specific and general knowledge.&lt;/p>
&lt;p>This thesis also shows how the HyperD architecture can be extended with the concept of Corresponding Information Content (CIC). CIC allows to model the amount and quality of the pieces of information in one media object in relationship to the pieces of information in another media object.&lt;/p>
&lt;p> &lt;/p></description></item><item><title>Definition of Behavior in Object-Oriented Databases by View Integration</title><link>https://big.tuwien.ac.at/phd-thesis/archive/definition-of-behavior-in-object-oriented-databases-by-view-integration/</link><pubDate>Tue, 19 May 2020 12:38:24 +0000</pubDate><guid>https://big.tuwien.ac.at/phd-thesis/archive/definition-of-behavior-in-object-oriented-databases-by-view-integration/</guid><description>&lt;p>This work has been finished in September 1998.&lt;/p>
&lt;p>Databases in large organizations are usually designed by a group of people including potential future users of the database who know the application domain from everyday business. The design of databases by view integration means that several users or groups of users define their views on the proposed database. These views are collected and integrated to one conceptual database schema.&lt;/p>
&lt;p>We treat view integration in the context of modeling business processes and workflows and use the object-oriented data model Object/Behavior Diagrams to define the structure and behavior of business objects. In this work, we will focus on the definition and integration of views of the behavior of objects. Behavior of business objects is defined based on a two-schema architecture: Business processes define the overall behavior of business objects according to external business rules, which mainly reflect long-term business rules due to natural facts or law; workflows represent the current processing of business objects in an organization according to internal business rules.&lt;/p>
&lt;p>Users define their views as they perceive processing of business objects in everyday business, thereby modeling workflows. Further, views of different users comprise different information: (1) Views model behavior of different entities of the real world; (2) views define processes at different levels of detail or omit parts of the processes; (3) views contain comparable information that is defined using different modeling concepts; (4) views define specifications of activities by providing an interface or refer to activities without defining an interface.&lt;/p>
&lt;p>The goal of view integration is to define the complete set of object types and business processes in the conceptual database schema. Thus, information relevant for the business processes is extracted from the workflows, the object types of the integrated schema are determined, and a business process as well as the activity specifications are defined for each object type. The goal of view integration is to define object types with business processes in a way that the processing of objects according to a business process in the conceptual schema can be observed as a correct processing in each view if information that is not defined in the view is ignored.&lt;/p>
&lt;p> &lt;/p></description></item><item><title>Active Object-Oriented Databases: From Conceptual Design to Logical Design</title><link>https://big.tuwien.ac.at/phd-thesis/archive/active-object-oriented-databases-from-conceptual-design-to-logical-design/</link><pubDate>Tue, 19 May 2020 12:38:23 +0000</pubDate><guid>https://big.tuwien.ac.at/phd-thesis/archive/active-object-oriented-databases-from-conceptual-design-to-logical-design/</guid><description>&lt;p>This work has been finished in February 1998.&lt;/p>
&lt;p>The design of active object-oriented databases includes modeling the structure of objects, their passive behavior in the form of operations that can be performed on them, and their active behavior in the form of business rules. Business rules are statements about business policies and can be formulated according to the event-condition-action structure of rules provided by active database systems, which allow to react to predefined situations by performing an operation if a certain condition is satisfied when the event occurs.&lt;/p>
&lt;p>An approach that has been followed successfully in conventional database design is to perform database design in two phases: In the first phase, the conceptual design, a high-level graphical representation of the database schema is developed. In the second phase, the logical design, the developed schema is mapped to the data model of the system used for the implementation. We adopt this approach for the design of active object-oriented databases.&lt;/p>
&lt;p>We introduce Active Object/Behavior Diagrams for the conceptual design of active object-oriented databases. Active Object/Behavior Diagrams seamlessly extend Object/Behavior Diagrams, an existing high-level graphical language for modeling the structure and the passive behavior of objects, with concepts for modeling business rules. Modeling business rules at the conceptual level requires different concepts than currently provided by active object-oriented database systems and by recent approaches to active object-oriented database design. Active Object/Behavior Diagrams introduce a graphical rule and event language the meets the identified requirements.&lt;/p>
&lt;p>During logical design, a schema developed with Active Object/Behavior Diagrams is mapped to a logical schema of an existing active object-oriented database system. We present such a mapping for TriGS, a prototype of an active object-oriented database system built on top of the commercial object-oriented database system GemStone (GemStone Systems, Inc.). The mapping decomposes the high-level constructs of Active Object/Behavior Diagrams into lower-level constructs of TriGS. The presented mapping covers all three dimensions of a schema specified with Active Object/Behavior Diagrams: object structure, passive object behavior, and active object behavior.&lt;/p>
&lt;p> &lt;/p></description></item><item><title>Handling Variants of Business Document Models</title><link>https://big.tuwien.ac.at/phd-thesis/archive/handling-variants-of-business-document-models/</link><pubDate>Tue, 19 May 2020 12:38:23 +0000</pubDate><guid>https://big.tuwien.ac.at/phd-thesis/archive/handling-variants-of-business-document-models/</guid><description>&lt;p>This work has been finished in December 2011.&lt;/p>
&lt;p>The United Nations Centre for Trade Facilitation and Electronic Business (UN/CEFACT) envisions seamless information exchange between business partners in electronic commerce. Therefore, UN/CEFACT provides the UML Profile for Core Components for the definition of document models based on UML class diagrams.&lt;/p>
&lt;p>Having used this approach for three years in practice, it became evident that managing document model versions is a prerequisite for successfully utilizing Core Components. While managing software versions in the area of Software Engineering is well understood and successfully applied in industrial projects, the direct application of the same techniques for versioning models is conditionally appropriate. The thesis presents a model registry based on combining techniques from traditional Software Configuration Management with the concepts of Reference Modeling, where similar problems are addressed based on a different background. The benefits of such a registry include a repository for storing models and their variants, proper concepts for preserving consistency across model variants, as well as detecting similar model variants in order to reduce model complexity and duplication.&lt;/p>
&lt;p> &lt;/p></description></item><item><title>Context Aware Core Components Modeling</title><link>https://big.tuwien.ac.at/phd-thesis/archive/context-aware-core-components-modeling/</link><pubDate>Tue, 19 May 2020 12:38:22 +0000</pubDate><guid>https://big.tuwien.ac.at/phd-thesis/archive/context-aware-core-components-modeling/</guid><description>&lt;p>This work has been finished in October 2012.&lt;/p>
&lt;p>Business document standards usually cover a hierarchical structure of thousands of elements that may be relevant in any business context (any industry, any geopolitical region, etc.). In order to use a business document standard in a specific context, user groups define so-called implementation guidelines based on a subset consisting usually of 3 – 5% of the overall elements. When one defines a new implementation guideline for a specific context, one has always to start from scratch, which is time-consuming and also leads to somewhat heterogeneous interpretations of the standard. It is our goal to speed up the development process and to create more homogeneous implementation guidelines by learning from existing models. If we could assign a formal context to existing implementation guidelines, one may guess the subset of a new implementation guideline for a given context. Accordingly, the Ph.D. thesis looks for an approach to model the context of business document standards and for an algorithm to calculate the content model (subset) of a message implementation guideline.&lt;/p>
&lt;p> &lt;/p>
&lt;p>Download the
&lt;a href="https://www.big.tuwien.ac.at/app/uploads/2016/10/Novakovic_D.pdf" target="_blank" rel="noopener">paper&lt;/a>&lt;/p></description></item><item><title>The Model Morphing Approach - Horizontal Transformation of Business Process Models</title><link>https://big.tuwien.ac.at/phd-thesis/archive/the-model-morphing-approach-horizontal-transformation-of-business-process-models/</link><pubDate>Tue, 19 May 2020 12:38:22 +0000</pubDate><guid>https://big.tuwien.ac.at/phd-thesis/archive/the-model-morphing-approach-horizontal-transformation-of-business-process-models/</guid><description>&lt;p>This work has been finished in February 2008.&lt;/p>
&lt;p>Owing to company mergers and business to business interoperability, there is a need for model transformation in the area of business process modeling to facilitate model integration and model synchronisation. This need arises, on one hand, from the fact that there are many different business process modeling formalisms, for example the ADONIS R Standard Modeling Method , UML 2.1 Activity Diagram, the Event-driven Process Chain Method, and, the Business Process Modeling Notation. These formalisms provide different ways to express and represent the same aspects of business process modeling. On the other hand, existing model transformation approaches, like ATL, QVT, and Fujaba, use very general concepts for transforming models for different purposes. However, recurring structures have been observed when transforming models in the area of business process modeling. This leads to the assumption, that there are similar transformation problems in a distinct area. These recurring structures, however, are only inadequately supported by existing transformation approaches.&lt;/p>
&lt;p>This thesis analyzes the different ways of how business process modeling aspects are represented in various business process modeling formalisms. Furthermore, existing transformation approaches are evaluated concerning their suitability for transforming models in the area of business process modeling. Based on this evaluation, special requirements and solutions for model transformations in the area of business process modeling are derived. These solutions lead to the construction of the Model Morphing approach, which consists of an integrated metamodel and morphing methods which operate based on this metamodel. The Model Morphing approach makes it possible to concentrate on the specific transformation problems within a distinct domain. Furthermore, it reuses existing model transformation approaches and reduces the need for excellent programming skills when defining model transformations.&lt;/p>
&lt;p> &lt;/p>
&lt;p>Download the
&lt;a href="https://www.big.tuwien.ac.at/app/uploads/2016/10/Murzek_M.pdf" target="_blank" rel="noopener">paper&lt;/a>&lt;/p></description></item><item><title>Ant Algorithms for Self-Organization in Social Networks</title><link>https://big.tuwien.ac.at/phd-thesis/archive/ant-algorithms-for-self-organization-in-social-networks/</link><pubDate>Tue, 19 May 2020 12:38:21 +0000</pubDate><guid>https://big.tuwien.ac.at/phd-thesis/archive/ant-algorithms-for-self-organization-in-social-networks/</guid><description>&lt;p>This work has been finished in May 2007.&lt;/p>
&lt;p>Peer-to-peer networks and folksonomies are like living organisms, ever growing and changing as time goes on. This thesis addresses the applicability of algorithms derived from the self-organizing and emergent behavior observed from ant colonies to these complex networks for two specific purposes, namely (1) content-based search in unstructured peer-to- peer networks, and (2) the extraction of adaptive user profiles from folksonomies.&lt;/p>
&lt;p>For search in unstructured peer-to-peer networks, the main goal is to find the shortest path from every querying peer to one or more answering peers that possess resources which are appropriate answers for the given query. The S EM A NT algorithm, which is designed for this task, is based on reputation learning. In reputation learning, the information about the remote peers’ resources is gained passively by observing the user queries and their answers that are forwarded through the local peer. Every successful query evokes small updates in the routing tables of those peers that are included in the path between the querying and the answering peer. The routing tables are used for subsequent queries to decide which link to follow in order to find appropriate resources. The S EM A NT algorithm is compliant with the Ant Colony Optimization meta-heuristic, and it employs a probabilistic procedure to select outgoing links for query forwarding. This procedure combines an exploiting strategy, which selects those links currently known as the most appropriate ones, with an exploring strategy, which also follows links not currently known as the best ones with the aim of finding better paths not yet explored. A weight defines the ratio between the strategies.&lt;/p>
&lt;p>Since the S EM A NT algorithm is a content-based approach to peer-to-peer search, its performance depends on how the content is distributed in the network. The evaluation of the algorithm includes an investigation to which extent this is the case. Based on these results, we develop strategies for improvement. Under the assumption that the resources in the network are annotated according to a taxonomy, and that the query vocabulary is restricted to the leaf topics from the same taxonomy, it is possible to consider also the upper-level topics in the query routing procedure of the algorithm in order to increase its performance.&lt;/p>
&lt;p>Ant algorithms include an evaporation feature for integrating a time factor when incrementally creating solutions. This feature is beneficial for the task of learning adaptive user profiles from tagging data. For this purpose we design the Add-A-Tag algorithm, which is based on a combination of an evaporation feature for adapting the user profile to trends over time, and the co-occurrence technique for determining the relationships between tags. The user profiles created with the Add-A-Tag algorithm are semantic networks derived from the structure of the tagging data, and they are adaptive in the sense that they change according to changes in a user’s tagging behavior. In addition to the long-term interests of a user, also his or her short-term interests are included in the profile at any given point of time. We present a tool for visualizing the changes in the profile over time, and we show how to exploit the profile for personalized browsing of annotated data sources.&lt;/p>
&lt;p> &lt;/p>
&lt;p>Download the
&lt;a href="https://www.big.tuwien.ac.at/app/uploads/2016/10/Michlmayr_E.pdf" target="_blank" rel="noopener">paper&lt;/a>&lt;/p></description></item><item><title>High Performance Computing in Finance - On the Parallel Implementation of Pricing and Optimization Models</title><link>https://big.tuwien.ac.at/phd-thesis/archive/high-performance-computing-in-finance-on-the-parallel-implementation-of-pricing-and-optimization-models/</link><pubDate>Tue, 19 May 2020 12:38:21 +0000</pubDate><guid>https://big.tuwien.ac.at/phd-thesis/archive/high-performance-computing-in-finance-on-the-parallel-implementation-of-pricing-and-optimization-models/</guid><description>&lt;p>This work has been finished in May 2006.&lt;/p>
&lt;p>High Performance Computing is useful in the field of finance for solving problems which are defined on models of financial variables in the form of sequences of scenarios along with their realization probabilities. Both the evolution of stock prices and interest rates is frequently described in this manner. Starting from a known state, and covering a future time horizon of multiple periods, these models take the form of scenario trees. As a special case, the structure collapses into a lattice, if the tree is “recombining”. This work deals with the two problem classes of determining prices of financial instruments, and of determining optimal portfolios of assets, with respect to some objective function and constraints. Dynamic optimization techniques allow for multiple planning periods, whereas stochastic dynamic optimization problems take into account also probabilities and exhibit (exponentially growing) tree structures, which can become very large. As an example, a model of ten years of three assets, each of which is described by the extents and probabilities of rising or falling of their respective prices within a year, results in a scenario tree with more than one billion (23 )10 = 1 073 741 824 terminal nodes. Computation times for solving these problems can extend to hours and days, hence high performance computing techniques of achieving speed up are desirable.&lt;/p>
&lt;p>The major approach for performance improvement in this work is parallel computing. It includes the parallel implementation of Monte Carlo simulation techniques as well as of backward induction methods for pricing path dependent interest rate derivatives, in particular constant maturity floaters with embedded options. In the optimization part, the nested Benders decomposition method of multistage stochastic optimization has been parallelized in a synchronous as well as in an asynchronous version. The parallel implementations obtain speedups ranging from reasonable to excellent and demonstrate the potential of high performance computing for financial applications. In addition, they served as case studies in the development of software tools for high performance computing within the framework of the Special Research Program No. F011 Aurora “Advanced Models, Applications and Software Systems for High Performance Computing” of the Austrian Science Fund (FWF).&lt;/p>
&lt;p>The data parallel programming language HPF+, with extensions for clusters of SMPs, has been successfully employed in the implementation of pricing algorithms. A path notation has been specified as an extension to Fortran 95, allowing for the high level formulation of parallel algorithms operating on lattice structures. The parallel programming model of a distributed active tree has been designed and implemented on top of Java’s threads and RMI. Parallel implementations of the nested Benders decomposition algorithm in Java demonstrate that this is a suitable language for high performance computing. The OpusJava component framework, as well as the JavaSymphony class library, and the distributed active tree model proved their usefulness as programming support environments in the implementation of parallel tree structured algorithms.&lt;/p>
&lt;p>In addition to the parallelization of sequential existing algorithms, the improvement of known parallelization approaches, and the use of specialized parallel programming languages and programming models, an increase in performance has been achieved by algorithmic developments. The generalization of the classical backward induction method allows for the faster calculation, i.e., in linear instead of exponential time, of prices of a class of instruments exhibiting “limited” path dependence, demonstrating that highly effective approaches of performance improvement combine the levels of algorithms and parallel implementation.&lt;/p>
&lt;p> &lt;/p>
&lt;p>Download the
&lt;a href="https://www.big.tuwien.ac.at/app/uploads/2016/10/Moritsch_H.pdf" target="_blank" rel="noopener">paper&lt;/a>&lt;/p></description></item><item><title>Testing of UML Activity Diagrams</title><link>https://big.tuwien.ac.at/phd-thesis/archive/testing-of-uml-activity-diagrams/</link><pubDate>Tue, 19 May 2020 12:38:21 +0000</pubDate><guid>https://big.tuwien.ac.at/phd-thesis/archive/testing-of-uml-activity-diagrams/</guid><description>&lt;p>In model-driven development, modeling languages provide the means for software development on a higher level of abstraction than traditional general purpose languages. However, compared to general purpose languages, these modeling languages often lack the proper tool support, such as tools for debugging and testing. Especially testing is essential to achieve a high quality of the final software product. In this work, we propose an approach for testing UML models at the model level to ensure the validation of their quality before the executable code is produced out of these models. In particular, we propose a dedicated testing language for specifying and executing test scenarios of UML activity diagrams based on OMG’s fUML standard.&lt;/p></description></item><item><title>REA-DSL: Business Model Driven Data Engineering</title><link>https://big.tuwien.ac.at/phd-thesis/archive/rea-dsl-business-model-driven-data-engineering/</link><pubDate>Tue, 19 May 2020 12:38:20 +0000</pubDate><guid>https://big.tuwien.ac.at/phd-thesis/archive/rea-dsl-business-model-driven-data-engineering/</guid><description>&lt;p>This work has been finished in June 2012.&lt;/p>
&lt;p>Accounting Information Systems (AIS) are essential for companies not only to record and track what events are happening or what events have happened in the past, they are also one of the most important tools for management to predict the financial future of a firm and take according actions. To enable an AIS to precisely record economic data and apply reasoning on them, it is crucial that the data structure of an AIS is built upon the economic phenomenas of a company’s business. Accordingly, it is already important to have a detailed understanding of the company’s economic actions at the design time of an AIS.&lt;/p>
&lt;p>Like in most software development projects, the dilemma during design time of an IT product is the language barrier between the domain expert, providing vital input for defining the requirements, and the IT professional, designing and developing the IT product. In most cases the domain expert is not capable of understanding IT specific terms, and the IT professional is not capable of completely understanding the specific area of the domain expert. Nevertheless, to successfully complete an IT product, these two groups still need to unambiguously communicate with each other by using a common language.&lt;/p>
&lt;p>When designing an AIS, the domain at hand is the accounting/business domain. Thus, a business modeling language describing economic phenomenas of a company can be used as such a common language to define requirements. One powerful business modeling language today is the Resource-Event-Agent ontology (REA). It not only allows describing events of the present and the past, it also allows specification of commitments made for future events. Consequently, it perfectly fits our requirement to capture the economic phenomenas of an AIS. However, REA is somewhat vague in the definition of its concepts and the current representation is merely IT related, which makes it hard to be understood by business experts. Accordingly, REA still cannot be used as a common communication language for the AIS design phase.&lt;/p>
&lt;p>Given these limitations, in this thesis we have taken upon the challenge to develop an unambiguous and intuitive graphical domain-specific representation for the REA ontology called the REA-DSL. First, we formalize the REA ontology by providing a REA-DSL meta-model incorporating the REA concepts resources, events, agents, commitments, and types as well as concepts known from database modeling. Subsequently, we create a graphical notation for the REA-DSL using different shapes for different REA concepts. Additionally, to reduce the complexity of the models, we split the REA-DSL into five interlinked views. A serialization format for the REA-DSL is provided by the REA-XML language. Furthermore, we specify a mapping between the conceptual REA-DSL and a database description language. This enables the semi-automatic generation of database structures for an AIS.&lt;/p>
&lt;p>The presented REA-DSL serves as an unambiguous and powerful business modeling language which can be used by IT and business experts for faster designing a robust AIS.&lt;/p>
&lt;p>Abstract and paper may be found in our &lt;a class="external" href="http://publik.tuwien.ac.at/showentry.php?ID=223117&amp;amp;lang=2">publication database&lt;/a>.&lt;/p></description></item><item><title>Self-Organization of Software Libraries: An Artificial Neural Network Approach</title><link>https://big.tuwien.ac.at/phd-thesis/archive/self-organization-of-software-libraries-an-artificial-neural-network-approach/</link><pubDate>Tue, 19 May 2020 12:38:20 +0000</pubDate><guid>https://big.tuwien.ac.at/phd-thesis/archive/self-organization-of-software-libraries-an-artificial-neural-network-approach/</guid><description>&lt;p>This work has been finished in November 1994.&lt;/p></description></item><item><title>Adaptable Model Versioning based on Model Transformation By Demonstration</title><link>https://big.tuwien.ac.at/phd-thesis/archive/adaptable-model-versioning-based-on-model-transformation-by-demonstration/</link><pubDate>Tue, 19 May 2020 12:38:19 +0000</pubDate><guid>https://big.tuwien.ac.at/phd-thesis/archive/adaptable-model-versioning-based-on-model-transformation-by-demonstration/</guid><description>&lt;p>This work has been finished in December 2011.&lt;/p>
&lt;p>&lt;em>Model-driven engineering&lt;/em> (MDE) is evermore adopted in academia and industry for being a new paradigm helping software developers to cope with the ever increasing complexity of software systems being developed. In MDE, software models constitute the central artifacts in the software engineering process, going beyond their traditional use as blueprints, and act as the single source of information for automatically generating executable software.&lt;/p>
&lt;p>Although MDE is a promising approach to master the &lt;em>complexity&lt;/em> of software systems, so far it lacks proper concepts to deal with the ever growing &lt;em>size&lt;/em> of software systems in practice. Developing a large software system entails the need for a large number of collaborating developers. Unfortunately, &lt;em>collaborative development of models&lt;/em> is currently not sufficiently supported. Traditional versioning systems for code fail for models, because they treat models just as plain text files and, as a consequence, neglect the graph-based nature of models.&lt;/p>
&lt;p>A few dedicated &lt;em>model versioning approaches&lt;/em> have been proposed, which directly operate on the models and not on the models‘ textual representation. However, these approaches suffer from four major deficiencies. First, they either support only one modeling language or, if they are &lt;em>generic&lt;/em>, they do not consider important specifics of a modeling language. Second, they do not allow the specification of &lt;em>composite operations&lt;/em> such as refactorings and thus, third, they &lt;em>neglect&lt;/em> the importance of respecting the original intention behind composite operations for detecting conflicts and constructing a merged model. Fourth, the types of &lt;em>detectable conflicts&lt;/em> among concurrently applied operations is &lt;em>insufficient&lt;/em> and &lt;em>not extensible by users&lt;/em>.&lt;/p>
&lt;p>To tackle these deficiencies, we present four major contributions in this thesis. First, we introduce an &lt;em>adaptable model versioning framework&lt;/em>, which aims at combining the advantages of two worlds; the proposed framework is generic and offers out-of-the-box support for &lt;em>all modeling languages&lt;/em> conforming to a common meta-metamodel, but also allows to be &lt;em>adapted&lt;/em> for enhancing the versioning support for &lt;em>specific modeling languages&lt;/em>. Second, we propose a novel technique, called &lt;em>model transformation by demonstration&lt;/em>, for easily specifying composite operations. Besides being executable, these composite operation specifications also constitute the &lt;em>adaptation artifacts&lt;/em> for enhancing the proposed versioning system. More precisely, with our third contribution, we present a novel approach for &lt;em>detecting applications of specified composite operations&lt;/em> without imposing any dependencies on the employed modeling environment. Fourth, we present a novel approach for detecting &lt;em>additional types of conflicts&lt;/em> caused by &lt;em>concurrently applied composite operations&lt;/em>. Furthermore, we contribute additional techniques for revealing potentially obfuscated or unfavorable merge results. Besides introducing the contributions from a conceptual point of view, we provide an open source implementation of these concepts and present empirical case studies and experiments for evaluating their usefulness and ease of use.&lt;/p>
&lt;p>Download the
&lt;a href="http://www.slideshare.net/PhilipLanger/adaptable-model-versioning-using" title="Slides on Slideshare" target="_blank" rel="noopener">slides&lt;/a>&lt;/p>
&lt;p>Abstract and paper may be found in our &lt;a class="external" href="http://publik.tuwien.ac.at/showentry.php?ID=203931&amp;amp;lang=2">publication database&lt;/a>.&lt;/p>
&lt;p>Download the
&lt;a href="https://www.big.tuwien.ac.at/app/uploads/2016/10/Langer_P.pdf" target="_blank" rel="noopener">paper&lt;/a>&lt;/p></description></item><item><title>Business Documents for Inter-Organisational Business Processes</title><link>https://big.tuwien.ac.at/phd-thesis/archive/business-documents-for-inter-organisational-business-processes/</link><pubDate>Tue, 19 May 2020 12:38:19 +0000</pubDate><guid>https://big.tuwien.ac.at/phd-thesis/archive/business-documents-for-inter-organisational-business-processes/</guid><description>&lt;p>This work has been finished in December 2009.&lt;/p>
&lt;p>Automated business-to-business (B2B) interactions between companies are constantly superseding old paper-based processes. This automation of inter-organizational processes requires a two-fold agreement between the participating business partners. First of all, business partners must agree on a common process choreography, unambiguously defining the exact exchange order of business documents in an inter-organizational business process. Consequently, business partners must agree on the structure of the exchanged business information as well. The two main business document paradigms, which are we elaborate on in this thesis, are top-down business document standards and bottom-up business document standards. The research question, this thesis aims to solve, is how to provide appropriate methods for the definition of business documents for inter-organizational business processes. Due to their special characteristics, such as the involvement of various stakeholders from different companies, the definition of business documents for inter-organizational business processes is not as straightforward as the definition of business documents for intra-organizational business processes. For the definition of inter-organizational business documents we employ two different approaches – a top-down approach and a bottom-up approach. For both approaches we provide appropriate methods for the definition of business documents, the mapping between different business document definitions, and the derivation of XML-based deployment artifacts from business document definitions. We thoroughly cover state-of-the art in the domain of inter-organizational business documents and inter-organizational business processes. This thesis starts by giving an introduction to the domain of Electronic Data Interchange (EDI) and shows the transition of data-centric EDI solutions to modern B2B systems in Chapter 1. Thereby, the specific requirements for B2B interactions are elaborated – in particular in regard to the definition of the exchanged business information. We motivate the findings of this thesis using an accompanying example from the domain of pan-European waste transport, which is introduced in Chapter 2. In Chapter 3 we provide a survey of current state-of-the-art in business documents standards. Chapter 4 provides an introduction to UN/CEFACT’s Core Components, a top-down business document standard which is key to this thesis. In a nutshell, core components are implementation neutral building blocks for assembling business documents. Although this implementation neutrality is one of the strengths of core components, it hinders a broad diffusion of the standard, since no common representation format for core components is available. To address this issue, this thesis provides three reference representation formats for core components: (i) a UML Profile for Core Components (Chapter 5), (ii) a Domain Specific Language for Core Components (Chapter 6), (iii) and a Web Ontology Language representation for Core Components (Chapter 7). The derivation of XML Schema artifacts from core components, which may be deployed to IT systems, is covered in Chapter 8. A successful diffusion of core Components may only be achieved if a broad user community has access to the necessary core component definitions. Consequently, we provide a registry meta-model for core components in Chapter 9. Bottom-up business document standards are subject to discussion in the second part of this thesis. Thereby, domain specific extensions to bottom-up document standards are introduced in Chapter 10. Consequently, we examine how to map bottom-up standard definitions to core component based top-down standard definitions in Chapter 11. Finally, we show how to combine business choreography models and business document models in Chapter 12. Related work is discussed in Chapter 13 and Chapter 14 concludes the contributions of this thesis. In summary this thesis provides the following seven contributions: (1) An overview of business document standards, based on standard clusters; (2) three reference representation formats for core components using the Unified Modeling Language, Domain Specific Languages, and Web Ontology Language for Core Components; (3) an unambiguous derivation of XML Schema artifacts from UML based core component models; (4) a registry meta-model for a core component registry; (5) domain specific extensions for an XML based bottom-up business document standard; (6) a mapping of bottom-up business document standards to top-down business documents standards; (7) an integration of UML based core component models in UML based business choreography models. In short the overall approach facilitates the definition of business documents in an inter-organizational context and fosters reuse of existing business document definitions.&lt;/p>
&lt;p>Abstract and paper may be found in our &lt;a class="external" href="http://publik.tuwien.ac.at/showentry.php?ID=183994&amp;amp;lang=2">publication database&lt;/a>.&lt;/p></description></item><item><title>Defining Executable Modeling Languages with fUML</title><link>https://big.tuwien.ac.at/phd-thesis/archive/defining-executable-modeling-languages-with-fuml/</link><pubDate>Tue, 19 May 2020 12:38:19 +0000</pubDate><guid>https://big.tuwien.ac.at/phd-thesis/archive/defining-executable-modeling-languages-with-fuml/</guid><description>&lt;p>This work has been finished in December 2014.&lt;/p>
&lt;p>Model-driven engineering (MDE) is a software development paradigm aiming to cope with the growing complexity of software systems by raising the level of abstraction. In this paradigm, a system is defined by means of models using modeling languages that enable developers to abstract away from implementation and platform details. From the models, complete implementations may be (semi-)automatically generated by utilizing model transformation techniques. As MDE puts models into the center of software development, adequate methods for creating, analyzing, and utilizing models are crucial. Due to the large body of used modeling languages, means for efficiently developing adequate tool support for modeling languages are needed. To address this need, the automation techniques provided by MDE may also be applied to automate the development of such tool support. This is current practice for developing syntax-based tools. However, the automated development of semantics-based tools has not reached the same level of maturity yet. The goal of this thesis is to fill this gap and provide a solution for automating the development of semantics-based tools for executable modeling languages. Therefore, a language and methodology for developing behavioral semantics specifications based on the standardized language fUML are proposed. To provide the basis for developing semantics-based tools, the execution environment of fUML was extended with means for execution control, runtime observation, and runtime analysis. Based on these extensions, a generic model execution environment for modeling languages whose behavioral semantics is defined with fUML was developed. This environment provides the foundation for developing semantics-based tools for executable modeling languages, which has been shown by the implementation of a semantic model differencing tool and other semantics-based tools.&lt;/p>
&lt;p>Abstract and paper may be found in our &lt;a class="external" href="http://publik.tuwien.ac.at/showentry.php?ID=233990&amp;amp;lang=2">publication database&lt;/a>.&lt;/p>
&lt;p>Download the
&lt;a href="https://www.big.tuwien.ac.at/app/uploads/2016/10/Mayerhofer_T.pdf" target="_blank" rel="noopener">paper&lt;/a>&lt;/p></description></item><item><title>Conceptual Design of Active Object-Oriented Databases</title><link>https://big.tuwien.ac.at/phd-thesis/archive/conceptual-design-of-active-object-oriented-databases/</link><pubDate>Tue, 19 May 2020 12:38:18 +0000</pubDate><guid>https://big.tuwien.ac.at/phd-thesis/archive/conceptual-design-of-active-object-oriented-databases/</guid><description>&lt;p>This work has been finished in September 1997.&lt;/p>
&lt;p>Business rules are statements about business policies and can be formulated according to the event-condition-action structure of rules provided by active database systems, which allow to react to predefined situations by performing an operation if a certain condition is satisfied when the event occurs.&lt;/p>
&lt;p>The conceptual design of active object-oriented databases includes modeling the structure of objects, their passive behavior (the operations that can be peformed on objects), and their active behavior (rules that allow objects to react autonomously to predefined situations by performing an operation). Modeling business rules at the conceptual level by means of the active behavior of objects requires different concepts than currently provided by active object-oriented database systems and by recent approaches to active object-oriented database design.&lt;/p>
&lt;p>This thesis presents a high-level graphical language called Active Object/Behavior Diagrams, which meets the requirements identified for modeling business rules at the conceptual level. Active Object/Behavior Diagrams extend the already introduced Object/Behavior Diagrams with Situation/Activation Diagrams, a graphical rule and event language.&lt;/p>
&lt;p>In order to cope with the complex domain of business applications, concepts for specializing the object structure and the passive behavior have been elaborated and presented in the diverse literature. Specializing active behavior (business rules) has received little attention so far. This thesis extends the specialization concepts already defined for Object/Behavior Diagrams with the concepts for specializing Situation/Activation Diagrams.&lt;/p>
&lt;p>The usage of modeling concepts is constrained by a set of consistency rules. They have the designer stick to a correct usage of the modeling concepts in order to achieve a consistent database schema. Even if all consistency rules are obeyed, different designers may yield different consistent database schemata, which may differ in their quality. This thesis presents guidelines for the conceptual design of active behavior in active object-oriented databases. These design guidelines should help the designer to achieve a consistent as well as a high-quality database schema, i.e., a comprehensible and maintainable database schema.&lt;/p>
&lt;p> &lt;/p></description></item><item><title>Monitoring von verteilten Systemen</title><link>https://big.tuwien.ac.at/phd-thesis/archive/monitoring-von-verteilten-systemen/</link><pubDate>Tue, 19 May 2020 12:38:18 +0000</pubDate><guid>https://big.tuwien.ac.at/phd-thesis/archive/monitoring-von-verteilten-systemen/</guid><description>&lt;p>This work has been finished in June 2000.&lt;/p>
&lt;p>Enhancements to computer systems and networking technologies have lead to an increasing decentralization of services and data which implies the usage of common resources (e.g. networks) and more parallelization of processes in application systems to a greater extent. One of the advantages of these systems is that they can be better adapted to physical, organizational and software-technological requirements.&lt;/p>
&lt;p>Developers of distributed systems are confronted in the construction process with problems which do not appear or only appear in a restricted form in the development of non-distributed systems. Examples of such problems are: mapping distributed resources and/or processes onto a set of computers; paralleling process steps; identification and handling of faults, etc. Monitoring and dynamic program analysis should support software development of distributed systems. The support should occur in such a way that system requirements can be met, the above mentioned problems can be solved, and distributed systems can be observed.&lt;/p>
&lt;p>The work is divided into seven chapters. Besides the chapters introduction and conclusion, there are five chapters with the following topics: terms of distributed systems; distributed systems requirements and problems during the development of such systems; monitoring concepts; existing monitoring systems; and the monitoring system Orwell.&lt;/p>
&lt;p>The second chapter describes important terms of distributed systems. Starting with the term »system« , a characterization of distributed system will be made, to discuss important properties of these systems. Based on the properties and terms, we discuss important concepts and mechanisms, which play an important role in the construction of distributed systems.&lt;/p>
&lt;p>The third chapter describes on the basis of the above mentioned concepts and mechanisms, important aspects of distributed systems from the view of software engineering. Such aspects are reliability, fault tolerance, efficiency, scalability and security. After that, we discuss problems of the development process of distributed systems. Additionally, object-oriented systems will be discussed. Furthermore, we will discuss aspects like time and causality, which are important for monitoring distributed systems.&lt;/p>
&lt;p>The fourth chapter consists of a discussion of basic monitoring-system requirements. The main part of the chapter is about the general monitoring model of Mansouri-Samani[95] and its concepts, activities, and strategies for the observation and analysis of distributed systems.&lt;/p>
&lt;p>The fifth chapter consists of a presentation of selected monitoring research approaches and tools.&lt;/p>
&lt;p>The sixth chapter describes the monitoring system Orwell. The architecture of the distributed and object-oriented analysis environment and its functionality will be discussed. Finally it contains a comparison and evaluation with other approaches.&lt;/p>
&lt;p>This work concludes with a summary of results as well as a discussion of future developments and possible research directions.&lt;/p>
&lt;p> &lt;/p></description></item><item><title>Business Process Modelling - Languages, Goals, and Variabilities</title><link>https://big.tuwien.ac.at/phd-thesis/archive/business-process-modelling-languages-goals-and-variabilities/</link><pubDate>Tue, 19 May 2020 12:38:17 +0000</pubDate><guid>https://big.tuwien.ac.at/phd-thesis/archive/business-process-modelling-languages-goals-and-variabilities/</guid><description>&lt;p>This work has been finished in January 2008.&lt;/p>
&lt;p>Over the last decade more and more companies started to optimize their business processes in a way to meet its business goals. They develop business process models defining which activities have to be executed in which order under which conditions by whom and by using which resources. For this purpose a lot of different approaches to business process modelling have been developed, which resulted in many different Business Process Modelling Languages (BPMLs).&lt;/p>
&lt;p>The definition of a business process has to cover many different aspects (e.g. control flow, organizational view, data view, etc.). A perfect business process modelling approach would address all the different aspects. Unfortunately, none of the existing approaches provides concepts for addressing all of these aspects. Each of them concentrates on some aspects. The focus on certain aspects is mainly due to the different applications areas, e.g. business engineering or software engineering etc.&lt;/p>
&lt;p>Although BPMLs are well established in industry and science, a comprehensive evaluation or a framework for an evaluation to compare the different BPMLs is still missing. Thus, it is the goal of this thesis to provide an evaluation framework for the comparison of BPMLs and to apply this framework in the evaluation of the currently most popular BPMLs. The resulting framework is based on a generic metamodel that captures all of the concepts appearing in any of the state-of-the-art BPMLs. On a high level this framework addresses the following views: Business Process Context Perspective, Behavioural Perspective, Functional Perspective, Informational Perspective, and Organisational Perspective. An evaluation based on this framework checks whether the certain aspects in each of these perspectives is supported by the concepts of each of the considered BPMLs. In the evaluation of this thesis, we used the following languages: UML 2 Activity Diagram, Business Process Modelling Notation, Event Driven Process Chain, IDEF3, Petri Net, Role Activity Diagram.&lt;/p>
&lt;p>According to the evaluation we were able to identify three main problems in current BPMLs. The first problem is that the definition of the dependency between business processes and their supporting software systems is inadequately supported. In our approach we support the elicitation of requirements from business process models for the software systems to be developed by extending current BPMLs with software requirements and components to ensure a business-goal oriented software development.&lt;/p>
&lt;p>The second problem concerns the variability of similar, but well-distinguished software products within a software product line. These software products not only differ in its structural definition, but also in the process to create them. Today, variability modelling is a domain specific modelling technique that is limited to the structural definition of similar software products. In our approach we extend the concepts of variability modeling to integrate the dynamical aspects into the UML. The resulting approach is based on a well defined dependency between UML class diagrams and UML activity diagrams.&lt;/p>
&lt;p>The third problem is that current conceptual BPMLs do not provide explicit modelling means for process goals and their measures. The modelling of goals and its monitoring is a critical step in business process modeling. Hence, we extend the metamodels of UML 2 AD, EPC and BPMN with business process goals and performance measures. These concepts become explicitly visible in the corresponding models. Furthermore, a mapping of the performance measures onto the Business Process Execution Language (BPEL) enables their monitoring in an execution environment.&lt;/p>
&lt;p> &lt;/p>
&lt;p>Download the
&lt;a href="https://www.big.tuwien.ac.at/app/uploads/2016/10/Korherr_B.pdf" target="_blank" rel="noopener">paper&lt;/a>&lt;/p></description></item><item><title>Model Driven Development of Inter-organizational Workflows</title><link>https://big.tuwien.ac.at/phd-thesis/archive/model-driven-development-of-inter-organizational-workflows/</link><pubDate>Tue, 19 May 2020 12:38:17 +0000</pubDate><guid>https://big.tuwien.ac.at/phd-thesis/archive/model-driven-development-of-inter-organizational-workflows/</guid><description>&lt;p>This work has been finished in May 2004.&lt;/p>
&lt;p>The rise of the web has spurred automation of cooperation among organizations. Interorganizational workflows support such cooperations in a way similar to traditional intraorganizational workflows that support business processes within an organization. The distinct characteristics of inter-organizational workflows, such as heterogeneity and autonomy of the participating software systems, has lead to the development of several new XML-based technologies supporting inter-organizational cooperation. These technologies, however, introduce additional complexity into the development of inter-organizational workflows. Model driven development is an approach to master these complexities by using higher-level models as main development artifacts. In the model driven architecture (MDA), UML can be employed as common modelling language for models at various levels of abstraction and various technologies.&lt;/p>
&lt;p>The goal of this thesis is to exploit the application of MDA for model driven development of inter-organizational workflows. In this respect, several contributions are made. First, a survey of current XML-based technologies is given, discussing the commonalities and differences of the various languages and identifying requirements on any modelling language supporting them as target technologies. Second, an extension of UML for platform-specific modelling of XML documents is defined, specifically addressing the problem of round-trip engineering. Third, different ways of extending schema specifications for XML documents are investigated, addressing the lack of expressiveness of XML schemas as compared to UML models.&lt;/p>
&lt;p> &lt;/p>
&lt;p>Download the
&lt;a href="https://www.big.tuwien.ac.at/app/uploads/2016/10/Kramler_G.pdf" target="_blank" rel="noopener">paper&lt;/a>&lt;/p></description></item><item><title>Oberon-D - On Adding Database Funktionality to an Object-Oriented Development Environment</title><link>https://big.tuwien.ac.at/phd-thesis/archive/oberon-d-on-adding-database-funktionality-to-an-object-oriented-development-environment/</link><pubDate>Tue, 19 May 2020 12:38:17 +0000</pubDate><guid>https://big.tuwien.ac.at/phd-thesis/archive/oberon-d-on-adding-database-funktionality-to-an-object-oriented-development-environment/</guid><description>&lt;p>This work has been finished in October 1997.&lt;/p></description></item><item><title>Metadata-Based Middleware for Integrating Information Systems</title><link>https://big.tuwien.ac.at/phd-thesis/archive/metadata-based-middleware-for-integrating-information-systems/</link><pubDate>Tue, 19 May 2020 12:38:16 +0000</pubDate><guid>https://big.tuwien.ac.at/phd-thesis/archive/metadata-based-middleware-for-integrating-information-systems/</guid><description>&lt;p>This work has been finished in April 1999.&lt;/p>
&lt;p>Today, information systems are widely employed for administrating large amounts of data of various application areas. Due to historical, organizational, and technical reasons, their infrastructure is usually characterized by the keywords distribution and heterogeneity, in the sense that an organization comprises several physically distributed and heterogeneous information system components. In fact, particulary within an organization, such system components are frequently interrelated. To enable their cooperation and to ensure one common access, it is required to achieve interoperability and to further integrate them logically. However, distribution and heterogeneity represent the most relevant barriers against the development of interoperable, logically integrated information systems.&lt;/p>
&lt;p>This thesis presents three systems realizing middleware to overcome these barriers, called COMan, IRO-DB, and OASIS. COMan integrates an object-oriented application and a relational database, providing persistence for complex objects and object-oriented manipulation of relational data. IRO-DB focuses on the integration of arbitrary relational as well as object-oriented database systems and constitutes a database federation. OASIS deals with the integration of arbitrary security concepts at an abstract description level, enabling their central monitoring and administration despite heterogeneity.&lt;/p>
&lt;p>All these systems achieve logical integration. They provide transparency with respect to distribution and heterogeneity while preserving the autonomy of the system components being integrated as far a possible. To allow for a flexible and generic integration all systems realize a metadata-based approach. This metadata-based approach prevents the hard-coding and distribution of the transformation knowledge, required due to distribution and heterogeneity aspects, over various system components. Rather, it is centralized in a reified way within a repository, thus, resulting in a system able to perform the essential transformations automatically and open to adapt to changing requirements.&lt;/p>
&lt;p>Based on the experience gained by developing these three systems, a criteria catalogue is developed allowing to categorize and evaluate different kinds of metadata-based middleware. The applicability of this catalogue is demonstrated by comparing the three introduced approaches by means of the proposed criteria.&lt;/p>
&lt;p> &lt;/p></description></item><item><title>Smart Matching – An Approach for the Automatic Generation of Executable Schema Mappings</title><link>https://big.tuwien.ac.at/phd-thesis/archive/smart-matching-an-approach-for-the-automatic-generation-of-executable-schema-mappings/</link><pubDate>Tue, 19 May 2020 12:38:16 +0000</pubDate><guid>https://big.tuwien.ac.at/phd-thesis/archive/smart-matching-an-approach-for-the-automatic-generation-of-executable-schema-mappings/</guid><description>&lt;p>This work has been finished in September 2008.&lt;/p>
&lt;p>Information integration has a long history in computer science [1]. It has started with theintegration of database schemas in the early eighties. With the rise of the Semantic Web andthe emerging abundance of ontologies, the need for an automatic information integration increased further.&lt;/p>
&lt;p>Information integration in general and automatic information integration in particular is a huge and challenging research area. One of the main problems is handling semantic heterogeneity and schema heterogeneity. Manually finding the semantically overlapping parts of schemas is a tedious problem. Furthermore, writing integration code is a labor intensive, error-prone, and cumbersome task. A lot of approaches have already been developed to automate this work. Nevertheless, not all integration problems have been solved so far.&lt;/p>
&lt;p>Matching tools are used to automatically find similarities between schemas. The results of these tools are simple correspondences. Based on these correspondences, one is able to write integration code. However, the simple correspondences are just suggestions and must be verified manually. Hence, the completeness and correctness of the resulting correspondences may not be assured. Furthermore, it is not possible to automatically derive transformation code for all found simple correspondences.&lt;/p>
&lt;p>In order to write transformation code, different kinds of transformation languages have been developed. The produced code is too customized for a specific type of schema to be easily reused for other integration problems. Hence, to the best of our knowledge, there exists no transformation language to develop reusable transformation patterns for different kinds of heterogeneity problems.&lt;/p>
&lt;p>This thesis addresses the heterogeneity problems, as well as the lack of reusable transformation code, and the need for establishing correct and complete correspondences between schemas. The first two problems are tackled by developing an executable declarative mapping language, which is able to cope with the core of schema heterogeneity problems. In contrast to simple correspondences, this mapping language is able to express more constraints. Based on these more expressive mappings, the execution code is automatically derived. The third problem is tackled by a self-tuning, iterative matching approach. This approach is based on the developed mapping language. Mapping strategies are responsible for the application of mapping operators. Based on the executable mapping suggestion, completeness and correctness are achieved for a provided set of instance models by a test-driven approach. These instance models are used to evaluate the produced mapping model. The prototype of this self-tuning approach is called SmartMatcher.&lt;/p>
&lt;p>[1] Laura Haas. Beauty and the Beast: The Theory and Practice of Information Integration. In 11th International Conference on Database Theory, Springer LNCS 4353, 2007, pp. 28-43.&lt;/p>
&lt;p> &lt;/p>
&lt;p>Download the
&lt;a href="https://www.big.tuwien.ac.at/app/uploads/2016/10/Kargl_H.pdf" target="_blank" rel="noopener">paper&lt;/a>&lt;/p></description></item><item><title>A Univied Peer-to-Peer Database Framework for XQueries over Dynamic Distributed Content and its Application for Scalable Service Discovery</title><link>https://big.tuwien.ac.at/phd-thesis/archive/a-univied-peer-to-peer-database-framework-for-xqueries-over-dynamic-distributed-content-and-its-application-for-scalable-service-discovery/</link><pubDate>Tue, 19 May 2020 12:38:15 +0000</pubDate><guid>https://big.tuwien.ac.at/phd-thesis/archive/a-univied-peer-to-peer-database-framework-for-xqueries-over-dynamic-distributed-content-and-its-application-for-scalable-service-discovery/</guid><description>&lt;p>This work has been finished in March 2002.&lt;/p>
&lt;p>In a large distributed system spanning administrative domains such as a Grid, it is desirable to maintain and query dynamic and timely information about active participants such as services, resources and user communities. The web services vision promises that programs are made more flexible and powerful by querying Internet databases (registries) at runtime in order to discover information and network attached third-party building blocks. Services can advertise themselves and related metadata via such databases, enabling the assembly of distributed higher-level components. In support of this vision, this thesis shows how to support expressive general-purpose queries over a view that integrates autonomous dynamic database nodes from a wide range of distributed system topologies.&lt;/p>
&lt;p>We motivate and justify the assertion that realistic ubiquitous service and resource discovery requires a rich general-purpose query language such as XQuery or SQL. Next, we introduce the Web Service Discovery Architecture (WSDA), which subsumes an array of dis- parate concepts, interfaces and protocols under a single semi-transparent umbrella. WSDA specifies a small set of orthogonal multi-purpose communication primitives (building blocks) for discovery. These primitives cover service identification, service description retrieval, data publication as well as minimal and powerful query support. The individual primitives can be combined and plugged together by specific clients and services to yield a wide range of be- haviors and emerging synergies. Based on WSDA, we introduce the hyper registry, which is a centralized database node for discovery of dynamic distributed content, supporting XQueries over a tuple set from an XML data model. We address the problem of maintaining dynamic and timely information populated from a large variety of unreliable, frequently changing, autonomous and heterogeneous remote data sources.&lt;/p>
&lt;p>However, in a large cross-organizational system, the set of information tuples is partitioned over many such distributed nodes, for reasons including autonomy, scalability, availability, performance and security. This suggests the use of Peer-to-Peer (P2P) query technology. Consequently, we take the first steps towards unifying the fields of database management systems and P2P computing. As a result, we propose the WSDA based Unified Peer-to-Peer Database Framework (UPDF) and its associated Peer Database Protocol (PDP), which are unified in the sense that they allow to express specific applications for a wide range of data types (typed or untyped XML, any MIME type), node topologies (e.g. ring, tree, graph), query languages (e.g. XQuery, SQL), query response modes (e.g. Routed, Direct and Referral Response), neighbor selection policies, pipelining, timeout and other scope characteristics.&lt;/p>
&lt;p>The uniformity and wide applicability of our approach is distinguished from related work, which (1) addresses some but not all problems, and (2) does not propose a unified framework.&lt;/p>
&lt;p> &lt;/p>
&lt;p>Download the
&lt;a href="https://www.big.tuwien.ac.at/app/uploads/2016/10/Hoschek_W.pdf" target="_blank" rel="noopener">paper&lt;/a>&lt;/p></description></item><item><title>Adaptivity in Learning Management Systems focussing on Learning Styles</title><link>https://big.tuwien.ac.at/phd-thesis/archive/adaptivity-in-learning-management-systems-focussing-on-learning-styles/</link><pubDate>Tue, 19 May 2020 12:38:15 +0000</pubDate><guid>https://big.tuwien.ac.at/phd-thesis/archive/adaptivity-in-learning-management-systems-focussing-on-learning-styles/</guid><description>&lt;p>his work has been finished in December 2007.&lt;/p>
&lt;p>Learning management systems (LMSs) such as WebCT, Blackboard, and Moodle are commonly and successfully used in e-education. While they focus on supporting teachers in creating and holding online courses, they typically do not consider the individual differences of learners. However, learners have different needs and characteristics such as prior knowledge, motivation, cognitive traits, and learning styles. Recently, increasing attention is paid to characteristics such as learning styles, their impact on learning, and how these individual characteristics can be supported by learning systems. These investigations are motivated by educational theories, which argue that providing courses which fit the individual characteristics of students makes learning easier for them and thus, increases their learning progress.&lt;/p>
&lt;p>This thesis focuses on extending LMSs to provide adaptivity by incorporating learning styles according to the Felder-Silverman learning style model. An automated approach for identifying learning styles from the behaviour and actions of learners has been designed, implemented, and evaluated, demonstrating that the proposed approach is suitable for identifying learning styles. Based on this approach, a standalone tool for automatic detection of learning styles in LMSs has been implemented.&lt;/p>
&lt;p>Furthermore, investigations have been conducted on improving the automatic detection of learning styles by using additional information from cognitive traits. The potential of working memory capacity is investigated. Results of a comprehensive literature review and two comprehensive evaluation studies show that relationships between working memory capacity and learning styles exist and that these relationships can provide additional information for the detection process of learning styles.&lt;/p>
&lt;p>Moreover, a concept for extending LMSs by enabling them to automatically generate and present courses that fit the students’ learning styles has been developed, implemented, and evaluated, using Moodle as a prototype. Results show that the proposed concept for providing adaptive courses is successful in supporting students in learning.&lt;/p>
&lt;p>By extending LMSs with adaptivity, a learning environment is built that supports teachers as well as learners. In such an adaptive LMS, teachers can continue using the advantages of LMSs and learners can additionally benefit from adaptive courses. This research opens ways for advanced learning systems, which are able to learn the needs and characteristics of learners, respond to them immediately, and provide learners with courses where adaptation is frequently improved and updated to the learners’ needs.&lt;/p>
&lt;p> &lt;/p>
&lt;p>Download the
&lt;a href="https://www.big.tuwien.ac.at/app/uploads/2016/10/Graf_S.pdf" target="_blank" rel="noopener">paper&lt;/a>&lt;/p></description></item><item><title>Formal Verification Techniques in Model Evolution</title><link>https://big.tuwien.ac.at/phd-thesis/archive/formal-verification-techniques-in-model-evolution/</link><pubDate>Tue, 19 May 2020 12:38:14 +0000</pubDate><guid>https://big.tuwien.ac.at/phd-thesis/archive/formal-verification-techniques-in-model-evolution/</guid><description>&lt;p>This work has been finished in July 2015.&lt;/p>
&lt;p>Correctness with respect to its specification is, with varying degree, crucial for all software developed today. Software that is developed following the model based development (MBD) approach is no exception to this observation. Consider a typical MBD workflow: a model is successively altered and refined up to the point when the model is transformed into executable code. Suppose an error has been introduced in the course of the various refinements. Without proper verification techniques this error can propagate through all subsequent refinements and into the executable code. Clearly, this circumstance is undesirable. In this thesis I will thus develop a model checking-based framework for the verification of MBD artifacts that (a) offers a high-degree of automation as compared to existing approaches and (b) allows the user to model the software and write the specification in the same familiy of languages, e.g., the system is modeled using UML and the specification is written in OCL.&lt;/p>
&lt;p> &lt;/p></description></item><item><title>Search-Based Model Transformations</title><link>https://big.tuwien.ac.at/phd-thesis/archive/search-based-model-transformations/</link><pubDate>Tue, 19 May 2020 12:38:14 +0000</pubDate><guid>https://big.tuwien.ac.at/phd-thesis/archive/search-based-model-transformations/</guid><description>&lt;p>This work has been finished in April 2016.&lt;/p>
&lt;p>Model-Driven Engineering (MDE) is a paradigm that promotes the use of models as the central artifacts for solving problems. In MDE, problem domains are specified using domain-specific modeling languages and models are concrete problem instances that abstract from reality to reduce complexity. At the heart of MDE, model transformations are used to systematically manipulate these problem models to find good solutions to the problem at hand. However, reasoning about how the transformation needs to be orchestrated to find good solutions is a non-trivial task due to the large or even infinite transformation space. As a result, this task is either performed automatically, e.g., by following an apply-as-long-as-possible approach, which does not necessarily produce satisfactory results, or it is carried out manually by the respective engineer. This, in turn, hampers the application of MDE techniques on complex problems which usually cannot be solved manually or by enumerating all possible solutions.&lt;/p>
&lt;p>Therefore, we present in this thesis an approach that facilitates to solve these problems by stating clear objectives operationalized through model-based analysis techniques and elevating search-based optimization methods to the model level to find optimal transformation orchestrations. As first contribution, we introduce a model-based analysis approach that measures dynamic, timed properties that consider the contention of resources directly on the model level using the fUML standard. As second contribution, we provide a generic encoding of the transformation orchestration problem on which many different optimization methods can be applied. Using this encoding, we propose an approach that enables to solve problems by providing a model, a set of transformation rules, a set of objectives that are optimized during the process and a set of constraints that mark invalid solutions. The optimization process is configured through a dedicated language which provides information on the optimization concepts and immediate feedback for the concrete configuration. The results consist of the respective orchestrated transformations, the solution models, the objective and constraint values as well as analysis details about the optimization process. Our approach is based on graph transformations and has been implemented as an open-source framework called MOMoT. Based on this implementation, we provide an extensive evaluation of our approach using several case studies from the area of model-driven software engineering as well as two novel problem formulations that tackle the modularization of model transformations and the generic modularization of modeling languages. The obtained evaluation results validate the effectiveness of our approach and give rise to interesting lines of research.&lt;/p>
&lt;p>Abstract and paper may be found in our &lt;a class="external" href="http://publik.tuwien.ac.at/showentry.php?ID=249363&amp;amp;lang=2">publication database&lt;/a>.&lt;/p></description></item><item><title>Conceptual Design of Secure Workflow Systems: An Object-Oriented Approach to the Uniform Modeling of Workflows, Organizations, and Security</title><link>https://big.tuwien.ac.at/phd-thesis/archive/conceptual-design-of-secure-workflow-systems-an-object-oriented-approach-to-the-uniform-modeling-of-workflows-organizations-and-security/</link><pubDate>Tue, 19 May 2020 12:38:13 +0000</pubDate><guid>https://big.tuwien.ac.at/phd-thesis/archive/conceptual-design-of-secure-workflow-systems-an-object-oriented-approach-to-the-uniform-modeling-of-workflows-organizations-and-security/</guid><description>&lt;p>This work has been finished in May 1998.&lt;/p>
&lt;p>The conceptual design of workflow systems comprises the modeling of organizational processes, organization structures, and security requirements. We present a comprehensive, conceptual workflow model that is to be used in early phases of the design of workflow systems that have high demands on security. The workflow model follows a uniform object-oriented approach.&lt;/p>
&lt;p>The processes of organizations need often be adapted to changed requirements in the business environments of organizations. We propose a novel schema architecture for the modeling of organizational processes. The so-called „two-schema architecture“ separates, according to its origin, knowledge on organizational processes into external knowledge, e.g., natural facts and law, and internal knowledge, i.e., organizational commitments. Since organizations have no influence on external knowledge – at least no direct influence -, most adaptions of organizational processes cause only changes to internal knowledge. The „two-schema architecture“ supports to a high degree the reuse of knowledge on organizational processes and eases the adaption of organizational processes to changed requirements in the business environments of organizations.&lt;/p>
&lt;p>The structure of organizations is typically organized around business functions of organizations. The structure of modern organizations is organized around the processes of organizations. As a result, the vertical hierarchy of organizations is flattened. Typically, actors work in network-like groups, which may be easily adapted to changed requirements. We support the modeling of both forms of organization structures, i.e., hierarchies and networks.&lt;/p>
&lt;p>The security requirements of organizational processes say to which actors authorizations can be issued, in which form particular authorizations must be represented (e.g., key cards), and how authorizations that have been issued to actors must be maintained. Basic security requirements for workflow systems are: (1) Accesses of actors that do not possess appropriate authorizations must be denied. (2) Authorizations that are in conflict with the security requirements of organizational processes must not be issued. We specify the security requirements of a workflow system in an authorization schema. A workflow management system can use such an authorization schema as a filter to exclude authorizations that are illegal wrt. the protection requirements of organizational processes from its authorization base.&lt;/p>
&lt;p> &lt;/p></description></item><item><title>Conflict Resolution in Model Versioning</title><link>https://big.tuwien.ac.at/phd-thesis/archive/conflict-resolution-in-model-versioning/</link><pubDate>Tue, 19 May 2020 12:38:13 +0000</pubDate><guid>https://big.tuwien.ac.at/phd-thesis/archive/conflict-resolution-in-model-versioning/</guid><description>&lt;p>This work has been finished in July 2012.&lt;/p>
&lt;p>In most engineering disciplines, models are built as pragmatic, yet precise abstractions of huge systems. The model building process requires multiple people jointly elaborating on artifacts, which are analyzed, used to communicate among stakeholders, and act finally as construction plan for realizing the modeled system. In the field of software engineering, modeling languages such as the &lt;em>Unified Modeling Language&lt;/em> (UML) provide multiple diagrams to describe various viewpoints of a system in a concrete graphical notation. While the code-centric software engineering discipline adopted those models as visual language for describing the system under study, the increasing complexity of modern software systems accompanied by ever shorter time to market constraints has asked for new techniques. The upcoming &lt;em>Model-Driven Engineering&lt;/em> (MDE) approach aims at additionally exploiting models to automatically generate executable code. This paradigm shift lifts models to first-class citizens within the whole engineering process, effectively shaping the primary artifact of change undergoing the collaborative refinement from informal sketches to blueprints. This upgrowth intrinsically demands tool support for managing the models‘ history including merging of parallel evolved models. Optimistic versioning systems, which are already successfully applied for the management of source code, handle both issues. However, applying those systems to models fails due to the models‘ graph-based structure. Consequently, first dedicated model versioning systems emerged. Although current model versioning systems provide decent conflict detection facilities, they (1) ignore the graphical representation of the models, and (2) neglect conflict resolution by totally shifting the responsibility to the user. Yet, the central role of models unifying the human-centric, collaborative abstraction and design process with the computation-centric process of generating executable systems, demands proper mechanisms to foster validity and quality of the merged model.&lt;/p>
&lt;p>In this thesis, we first analyze specifics of model versioning and elaborate on the notion of conflict to improve conflict resolution respecting the central role of models. To cope with the human-centric aspect, we present a conflict aware merge strategy to calculate a tentatively merged &lt;em>conflict diagram&lt;/em> as accelerator for conflict resolution retaining the graphical representation of the model. The conflict diagram unifies non-conflicting changes and materializes merge conflicts in form of annotations, rendering a coherent picture of the model’s evolution. To further support the conflict resolution process, we elaborate on a &lt;em>conflict resolution recommender system&lt;/em> on top of the conflict diagram, which recommends automatically executable conflict resolution patterns. Finally, to satisfy validity conditions of the computation-centric aspect, we establish a &lt;em>formal framework&lt;/em> based on graph transformation theory, to showcase the feasibility of our approach.&lt;/p>
&lt;p>Abstract and paper may be found in our &lt;a class="external" href="http://publik.tuwien.ac.at/showentry.php?ID=208975&amp;amp;lang=2">publication database&lt;/a>.&lt;/p></description></item><item><title>Model integration by virtualization</title><link>https://big.tuwien.ac.at/phd-thesis/archive/model-integration-by-virtualization/</link><pubDate>Tue, 19 May 2020 12:38:13 +0000</pubDate><guid>https://big.tuwien.ac.at/phd-thesis/archive/model-integration-by-virtualization/</guid><description>&lt;p>Model integration has been a recurring problem for several years now and gets even more impact due to the large amount of big, heterogenous model used in today’s industries. Virtualization has been successfully applied to data integration for a long time now and already received some attention in the modeling community, but is typically limited to providing read–only integrated information. Thus, it is proposed to go one step further and use virtualization for more aspects of model integration like synchronization and transformation. Models to be synchronized are de- fined as virtual models over their common and custom parts which might reduce the need of explicit synchronization. This new approach will need a theoretical foundation of virtual models, a new virtualization language, and implementation of this language in a framework and various strategies concerning the handling of virtual models&lt;/p></description></item><item><title>An Architecture Style for Cloud Application Modeling</title><link>https://big.tuwien.ac.at/phd-thesis/archive/an-architecture-style-for-cloud-application-modeling/</link><pubDate>Tue, 19 May 2020 12:38:12 +0000</pubDate><guid>https://big.tuwien.ac.at/phd-thesis/archive/an-architecture-style-for-cloud-application-modeling/</guid><description>&lt;p>UML is a widely adopted open standard to create architectural models from multiple viewpoints for various domains. Its language-inherent extension mechanism is being applied to systematically integrate domain-specific concepts via libraries and profiles because they are indispensable for model-based engineering (MBE). Cloud computing is an appealing target domain for MBE. Modern cloud environments support a relatively high degree of automation in service provisioning, which allows cloud users to dynamically acquire services required for deploying cloud applications. On the other hand, MBE aims at increasing the automation of application development by a systematic tool-supported refinement of high-level models towards a target platform and the environment underneath. The selected platform and environment designate the technical target domain whose concepts have to be captured on the model level in order to enable the refinement of architectural models. Modeling concepts and tools along with a set of constraints on how they can be used denote an architecture style. Providing an architecture style for cloud application modeling based on UML including tools that exploit automated processes of both cloud computing and MBE is thus highly desirable. Due to the generic nature of UML, it does however not provide cloud modeling concepts by default and existing UML tools do not yet adequately support cloud-specific model refinement.&lt;br>
To address these deficiencies, the goal of this thesis is to realize cloud-specific extensions to UML and a toolset that together form an architecture style for developing cloud applications. In particular, we place emphasis on the automation of development processes and their effectiveness in producing truly useful models. Four main contributions are presented to achieve this goal. First we systematically review current cloud modeling languages (CMLs) and investigate major cloud environments to derive a core set of features inherent to the cloud computing domain. They serve as the basis for developing the UML- based cloud application modeling language (CAML), which is the second contribution. CAML supports semi-automatic model refinement towards the Java platform and three major cloud environments via dedicated libraries and profiles. The third contribution addresses the automatic translation of UML architecture models refined by CAML into TOSCA, a recently adopted standard that aims at automating application provisioning and management. Combining UML and TOSCA closes the gap between architecture modeling and application provisioning. As model transformations are key to automate the refinement and translation of model-based artifacts, maintaining those transformations and their produced artifacts is addressed by the fourth contribution. We exploit incremental transformation to co- evolve existing models with changes to transformations. In addition to the conceptual contributions, we provide proof-of-concept implementations as open-source projects and present case studies for evaluating not only their practical relevance but also aspects such as quality and performance.&lt;/p>
&lt;p>Download the
&lt;a href="https://www.big.tuwien.ac.at/app/uploads/2016/09/Diss_Bergmayr.pdf" target="_blank" rel="noopener">paper&lt;/a>&lt;/p></description></item><item><title>Maintaining Consistency of Data on the Web</title><link>https://big.tuwien.ac.at/phd-thesis/archive/maintaining-consistency-of-data-on-the-web/</link><pubDate>Tue, 19 May 2020 12:38:12 +0000</pubDate><guid>https://big.tuwien.ac.at/phd-thesis/archive/maintaining-consistency-of-data-on-the-web/</guid><description>&lt;p>This work has been finished in December 2004.&lt;/p>
&lt;p>Increasingly more data is becoming available on the Web, estimates speaking of 1 billion documents in 2002. Most of the documents are Web pages whose data is considered to be in XML format, expecting it to eventually replace HTML, the current lingua franca of the Web, e.g., by XHTML.&lt;/p>
&lt;p>A common problem in designing and maintaining a Web site is that data on a Web page often replicates or derives from other data, the so-called base data, that is usually not contained in the deriving or replicating page. Two properties of Web sites account for this situation. First, the hypertext structure of a Web site not necessarily coincides with the structure of its underlying conceptual domain model, thus it may be necessary to present a single data item on several pages. Second, the content of pre-generated Web pages is often drawn from legacy systems, usually relational databases. In this case Web pages replicate data items from databases.&lt;/p>
&lt;p>Consequently, replicas and derivations become inconsistent upon modifying base data in a Web page or a relational database. For example, after modifying a product’s price in the database, already pre-generated Web pages offer the product at an out-dated price. Or, after assigning a thesis to a student and modifying the Web page that describes it in detail, the thesis is still incorrectly contained in the list of offered thesis, missing in the list of ongoing thesis, and missing in the advisor’s teaching record.&lt;/p>
&lt;p>The thesis presents a solution by proposing a combined approach that provides for maintaining consistency of data in Web pages that (i) replicate data in relational databases, or (ii) replicate or derive from data in Web pages. Upon modifying base data, the modification is immediately pushed to affected Web pages. There, maintenance is performed incrementally by only modifying the affected part of the page instead of re-generating the whole page from scratch.&lt;/p>
&lt;p>The proposed approach provides for consistent, up-to-date Web pages any time. It is efficient by providing incremental page maintenance techniques, generic by maintaining consistency of XML data in general, flexible by reacting to modifications in Web pages of other businesses, transparent by maintaining a business’ autonomy in managing its data, open by allowing future extensions to be built on top of it, and extensible by enabling the integration of arbitrary legacy systems.&lt;/p>
&lt;p> &lt;/p>
&lt;p>Download the
&lt;a href="https://www.big.tuwien.ac.at/app/uploads/2016/10/Bernauer_M.pdf" target="_blank" rel="noopener">paper&lt;/a>&lt;/p></description></item><item><title>Formal Specification of Distributed Systems - A Discrete Space-Time Logic</title><link>https://big.tuwien.ac.at/phd-thesis/archive/formal-specification-of-distributed-systems-a-discrete-space-time-logic/</link><pubDate>Tue, 19 May 2020 12:38:11 +0000</pubDate><guid>https://big.tuwien.ac.at/phd-thesis/archive/formal-specification-of-distributed-systems-a-discrete-space-time-logic/</guid><description>&lt;p>This work has been finished in April 1995.&lt;/p></description></item><item><title>Graphical Debugging of QVT Relations using Transformation Nets</title><link>https://big.tuwien.ac.at/master-thesis/archive/graphical-debugging-of-qvt-relations-using-transformation-nets/</link><pubDate>Tue, 19 May 2020 12:38:07 +0000</pubDate><guid>https://big.tuwien.ac.at/master-thesis/archive/graphical-debugging-of-qvt-relations-using-transformation-nets/</guid><description>&lt;p>This work has been finished in December 2009.&lt;/p>
&lt;p>Model transformations (MT) play a key role in the Model Driven Engineering (MDE) paradigm, leading to the standardization of the Query/View/Transformation (QVT) model transformation language by the Object Management Group (OMG). Until now, however, this language did not attract the same interest as the Unified Modeling Language (UML), because of the lack of adequate debugging facilities which are necessary regarding the following three problem areas: First, declarative languages like QVT Relations (QVT-R) hides the operational semantics of transformations. Only the information provided by the interpreter, as well as the tendered inputs and returned outputs are available for tracking the progress of transformations. Furthermore, the ordering of transformation application is hidden by the MT engines providing only a black-boxes view to the users. This can lead to the problem of impedance mismatches between design and runtime. These characteristics of QVT-R are assets for developing, but are handicaps for debugging. Second, QVT-R code is specified on higher abstraction level than its execution and state-of-the-art debugging. This deteriorates the ability to deduce causes from produced results. Third, the information content responsible for operating MTs is spread over several artifacts including the input model, a resulting target model and the QVT-R code. As a consequence, the reasons for a particular outcome are hard to be derived from the involved artifacts. This severely harms the ease of debugging. Therefore, this master thesis tackles the mentioned problems by visualizing QVT-R as Transformations Nets, using the MT framework „Transformations On Petri Nets In Color“ (TROPIC) based on Colored Petri Nets (CPN). This can be seen as explicit definition of operational semantics on a high abstraction level providing a white-box view for debugging QVT-R. This thesis proposes a procedure model formulated in a conceptual approach and in a prototypic implementation striving for bridging the existing gap between these two different paradigms by mapping the concepts of QVT Relations to such nets. In this thesis three particular contributions are provided: (i) a solution approach for unidirectional mappings producing target models from an existing source model, (ii) the support for model inheritance, (iii) and synchronization approaches for timely and version-based incremental changes.&lt;/p>
&lt;p> &lt;/p>
&lt;p>Download the
&lt;a href="https://www.big.tuwien.ac.at/app/uploads/2016/10/Zwickl_paper1.pdf" target="_blank" rel="noopener">paper&lt;/a> and
&lt;a href="https://www.big.tuwien.ac.at/app/uploads/2016/10/Zwickl_poster1.pdf" target="_blank" rel="noopener">poster&lt;/a>&lt;/p></description></item><item><title>Visual Design and Analysis Support for Answer Set Programming</title><link>https://big.tuwien.ac.at/master-thesis/archive/visual-design-and-analysis-support-for-answer-set-programming/</link><pubDate>Tue, 19 May 2020 12:38:07 +0000</pubDate><guid>https://big.tuwien.ac.at/master-thesis/archive/visual-design-and-analysis-support-for-answer-set-programming/</guid><description>&lt;p>This work has been finished in February 2011.&lt;/p>
&lt;p>Abstract and paper may be found in our &lt;a class="external" href="http://publik.tuwien.ac.at/showentry.php?ID=195848&amp;amp;lang=2">publication database&lt;/a>.&lt;/p>
&lt;p>Download the
&lt;a href="https://www.big.tuwien.ac.at/app/uploads/2016/10/Zwickl_poster2.pdf" target="_blank" rel="noopener">poster&lt;/a>&lt;/p></description></item><item><title>Adaptivität in e-Learning Plattformen - Evaluation von Open Source Produkten und Implementierung einer Adaptierungskomponente im Rahmen einer Fallstudien</title><link>https://big.tuwien.ac.at/master-thesis/archive/adaptivitt-in-e-learning-plattformen-evaluation-von-open-source-produkten-und-implementierung-einer-adaptierungskomponente-im-rahmen-einer-fallstudien/</link><pubDate>Tue, 19 May 2020 12:38:06 +0000</pubDate><guid>https://big.tuwien.ac.at/master-thesis/archive/adaptivitt-in-e-learning-plattformen-evaluation-von-open-source-produkten-und-implementierung-einer-adaptierungskomponente-im-rahmen-einer-fallstudien/</guid><description>&lt;p>This work has been finished in July 2005.&lt;/p>
&lt;p>Diese Arbeit beschäftigt sich mit e-Learning und e-Learning Plattformen. Das Ziel ist die geeignetste Plattform zu eruieren, um diese anschließend zu erweitern. Im Laufe der Arbeit werden neun e-Learning Systeme vorgestellt und evaluiert. Diese sind (in alphabethischer Reihenfolge): .LRN, ATutor, Dokeos, ILIAS, LON-CAPA, Moodle, OpenUSS mit Freestyle Learning, Sakai und Spaghetti Learning. Die Auswahl der Systeme war vorgegeben. Bei allen diesen Plattformen handelt es sich um Open Source Produkte, welche auf einem Server installiert und getestet wurden. Anschließend wird die Evaluierung der Plattformen beschrieben, wobei einerseits großer Wert auf die allgemeine Funktionalität und Qualität der Plattformen gelegt wurde, andererseits auch Adaptionsaspekte berücksichtigt wurden. Da Moodle die Evaluierung für sich entscheiden konnte, wurde Moodle in einem nächsten Schritt um eine adaptive Komponente erweitert.&lt;/p>
&lt;p> &lt;/p>
&lt;p>Download the
&lt;a href="https://www.big.tuwien.ac.at/app/uploads/2016/10/Z%c3%b6chmeister_paper.pdf" target="_blank" rel="noopener">paper&lt;/a>&lt;/p></description></item><item><title>Visualization of Evolving Graphical Models and Diagrams in the Context of Model Review</title><link>https://big.tuwien.ac.at/master-thesis/archive/visualization-of-evolving-graphical-models-and-diagrams-in-the-context-of-model-review/</link><pubDate>Tue, 19 May 2020 12:38:06 +0000</pubDate><guid>https://big.tuwien.ac.at/master-thesis/archive/visualization-of-evolving-graphical-models-and-diagrams-in-the-context-of-model-review/</guid><description>&lt;p>Source code review tools are part of many large scale software development processes. An example for such a code review tool is Gerrit which is used in popular open source projects such as the Android Open Source Project, Eclipse, LibreOffice and many others. Code reviews aim at finding and preventing mistakes introduced by changed artifacts before they are merged into the actual software project. The actual form of such a review varies and ranges from pair programming to formal inspections. However, the basic review process supported by most of the review tools is as follows: The review process is started by a contributor who provides one or more new or modified artifacts to the project. One or more reviewers provide feedback, leave comments on the contribution and decide whether the contribution will be accepted to be merged into the project or not. If not, the contributor may provide new versions of these artifacts based on the feedback of the reviewers and the process starts over again.&lt;/p>
&lt;p>This process requires to keep track of the changes introduced to the artifacts and previous feedback, which together form a review history. To support this, most of the source code review tools provide visualization of differences among the changed artifacts and additional annotations, such as comments tied to a specific scope of the text data. However, to the best of our knowledge, these visualizations only support textual artifacts, such as source code. Apart from binary artifacts, this way of visualization is also a problem for artifacts that encode data with text, but are hard to read for humans, such as models and diagrams.&lt;/p>
&lt;p>In Model-Driven Engineering, models are the most important artifacts of a software project. Such models are represented by a textual syntax or a graphical syntax. The previously mentioned visualizations are dedicated to show differences between textual artifacts and are hence suitable for models with a textual syntax. However, they do not support models using a graphical syntax, unless they can be encoded in text. Although the latter is technically possible, it is desirable to visualize the changes and annotations using the graphical representation, as this overcomes the burden of learning another representation and keeping them in sync.&lt;/p>
&lt;p>The aim of this thesis is to develop a set of visualization techniques to visualize graphical models in the context of review processes. Prototype implementations of the resulting techniques and case studies will be used to verify the results. These prototypes will be built on top of popular open source frameworks and tools used in Model-Driven Engineering, such as Eclipse, and the Eclipse Modeling Framework.&lt;/p>
&lt;p> &lt;/p></description></item><item><title>An Adaptable OCL Engine for validating Models in different Tool Environments</title><link>https://big.tuwien.ac.at/master-thesis/archive/an-adaptable-ocl-engine-for-validating-models-in-different-tool-environments/</link><pubDate>Tue, 19 May 2020 12:38:05 +0000</pubDate><guid>https://big.tuwien.ac.at/master-thesis/archive/an-adaptable-ocl-engine-for-validating-models-in-different-tool-environments/</guid><description>&lt;p>This work has been finished in September 2013.&lt;/p>
&lt;p>Abstract and paper may be found in our &lt;a class="external" href="http://publik.tuwien.ac.at/showentry.php?ID=223111&amp;amp;lang=2">publication database&lt;/a>.&lt;/p></description></item><item><title>The Diversity and Penetration of EDI in Austria: An Empirical Analysis</title><link>https://big.tuwien.ac.at/master-thesis/archive/the-diversity-and-penetration-of-edi-in-austria-an-empirical-analysis/</link><pubDate>Tue, 19 May 2020 12:38:05 +0000</pubDate><guid>https://big.tuwien.ac.at/master-thesis/archive/the-diversity-and-penetration-of-edi-in-austria-an-empirical-analysis/</guid><description>&lt;p>This work has been finished in February 2011.&lt;/p>
&lt;p>Electronic Data Interchange (EDI) is still one of the key challenges of today’s businesses. Currently, there exist several ways of handling EDI between companies. The prevalent technology in use is still EDIFACT. However, with the inception of XML, new standards are on the rise. Either way, numerous standards and message format implementations lead to services that fail to communicate with each other. Hence, interoperability is bound to fail.&lt;/p>
&lt;p>Before we can actually try to solve such interoperability issues, we need to have in-depth knowledge about the penetration and the diversity of electronic business document formats and standards. Therefore, an empirical study shall be conducted for the Austrian market, in which data on the usage of EDI is gathered and statistically analyzed to serve as valuable input for further research in this area.&lt;/p>
&lt;p>Tasks in the master’s thesis include:&lt;/p>
&lt;p> &lt;/p></description></item><item><title>Metamodell-basierte Integration von Web Modellierungssprachen</title><link>https://big.tuwien.ac.at/master-thesis/archive/metamodell-basierte-integration-von-web-modellierungssprachen/</link><pubDate>Tue, 19 May 2020 12:38:04 +0000</pubDate><guid>https://big.tuwien.ac.at/master-thesis/archive/metamodell-basierte-integration-von-web-modellierungssprachen/</guid><description>&lt;p>This work has been finished in October 2008.&lt;/p>
&lt;p>Web-Anwendungen haben sich über die letzten Jahrzehnte stark verändert. Die erste Generation zielte auf die einfache Bereitstellung von Informationen mittels statischer Websites. Durch die zweite Generation wurde eine neue Dimension eröffnet, wobei Web-Anwendungen nicht mehr nur als Mittel zur Informationsdarstellung gesehen werden, sondern auch vielfältige Dienste zur Verfügung stellen. Durch die daraus folgende Erhöhung des Entwicklungsaufwands von Web-Anwendungen entsteht die Notwendigkeit, die Entwicklung durch die Verwendung von modellbasierten Entwicklungsmethoden und spezifischen Web-Modellierungssprachen zu unterstützen.&lt;/p>
&lt;p>Die modellgetriebene Softwareentwicklung hat durch die Model Driven Architecture Initiative (MDA) stark an Bedeutung gewonnen. MDA zielt im Allgemeinen darauf ab, Modellierungssprachen aus verschiedenen Bereichen zu standardisieren, um Interoperabilität zwischen den verschiedenen Modellierungswerkzeugen zu schaffen. Jedoch wird MDA zurzeit nur als eine Vision gesehen, da die notwendige Basis für die Realisierung fehlt. Betroffen davon ist auch der Web Engineering Bereich, da bestehende Web-Modellierungsmethoden im Sinne der MDA nicht vollständig modellgetrieben sind. Es fehlen die entsprechenden Metamodelle zu den Web-Modellierungssprachen und die Modelltransformationen, um Modellaustausch zwischen den Web-Modellierungswerkzeugen zu gewährleisten.&lt;/p>
&lt;p>Diese Arbeit versucht eine erste Lösung für das Interoperabilitätsproblem zwischen den verschiedenen Web-Modellierungswerkzeugen umzusetzen. Ob eine verlustfreie Abbildung zwischen eingesetzten Web-Modellierungssprachen entwickelt werden kann, bildet die zentrale Forschungsfrage, die im Zuge dieser Arbeit beantwortet wird. Um diese Forschungsfrage zu beantworten, wird folgende Methode eingesetzt. Im ersten Teil der Arbeit werden die wesentlichen Eigenschaften von Web- Modellierungssprachen erklärt und anhand der entsprechenden Tools untersucht. Im zweiten Teil der Arbeit werden die Metamodelle für die einzelnen Modellierungssprachen erstellt und anhand eines Fallbeispiels detailliert untersucht. Im dritten Teil der Arbeit werden anhand des modellierten Fallbeispiels Unterschiede und Gemeinsamkeiten der Modellierungssprachen bestimmt. Der vierte Teil der Arbeit beschäftigt sich mit der Erstellung der Modelltransformationen für die Realisierung des Modellaustausches. Zusätzlich werden die zu realisierenden Modelltransformationen nach vordefinierten Kriterien wie Informationsverlust und Realisierbarkeit bewertet.&lt;/p>
&lt;p> &lt;/p>
&lt;p>Download the
&lt;a href="https://www.big.tuwien.ac.at/app/uploads/2016/10/Y%c3%bccel_paper.pdf" target="_blank" rel="noopener">paper&lt;/a> and
&lt;a href="https://www.big.tuwien.ac.at/app/uploads/2016/10/Y%c3%bccel_poster.pdf" target="_blank" rel="noopener">poster&lt;/a>&lt;/p></description></item><item><title>Model Driven Architecture in der Praxis - Evaluierung von aktuellen Werkzeugen und Fallstudie</title><link>https://big.tuwien.ac.at/master-thesis/archive/model-driven-architecture-in-der-praxis-evaluierung-von-aktuellen-werkzeugen-und-fallstudie/</link><pubDate>Tue, 19 May 2020 12:38:04 +0000</pubDate><guid>https://big.tuwien.ac.at/master-thesis/archive/model-driven-architecture-in-der-praxis-evaluierung-von-aktuellen-werkzeugen-und-fallstudie/</guid><description>&lt;p>This work has been finished in March 2005.&lt;/p>
&lt;p>Model Driven Architecture (MDA) wird von der Object Management Group (OMG) stark vorangetrieben und hält Einzug in die Softwareentwicklung. MDA wird als nächster Schritt des Formalisierungs- und Abstraktionsprozesses von Software gesehen, etwa wie die Ablöse von Assembler durch Hochsprachen. Schenkt man den vielen Versprechungen der OMG Glauben, so lassen sich aus technologieunabhängigen Modellen problemlos Anwendungen für verschiedenste Plattformen wie J2EE, CORBA oder .NET automatisch generieren. Dabei gibt die OMG nur eine theoretische Architektur und Spezifikation von MDA vor, die Implementierungen von Werkzeugen bzw. Transformationsregeln wird an die Softwareindustrie abgegeben. Diese soll in nächster Zeit für Automatisierungstools sorgen, die die Modelltransformationen und weitere Hilfsmittel für den erfolgreichen Einsatz von MDA unterstützen.&lt;/p>
&lt;p>In der Praxis wurden schon mehrere Projekte mittels MDA auf Basis der bereits vorhandenen Werkzeuge verwirklicht. Die Vision dabei ist, dass Softwareanwendungen automatisch generiert werden. Hier ist aber zu klären, ob die Tools wirklich Anspruch auf MDA haben oder ob es sich „nur“ um UML Tools handelt, die Codeseg- mente automatisch aus grafischen Modellen ableiten können.&lt;/p>
&lt;p>Die Diplomarbeit beschreibt ausführlich die theoretischen Konzepte von MDA sowie die praktische Umsetzung von MDA anhand eines Ausschnitts des CALENDARIUM-Projektes. Die theoretischen Konzepte wie plattformunabhängiges Modell, plattformabhängiges Modell, Modelltransformationen und Metamodellierung werden ausführlich erklärt und diskutiert. Dabei werden einerseits Probleme der Transformation der verschiedenen Modelle (vom Business Modell bis hin zum Code) aufgezeigt, sowie die Auswirkungen auf den Softwareentwicklungsprozess untersucht. Weiters wird auf die manuelle Erstellung von Transformationsregeln eingegangen. Anhand eines Kriterienkatalogs werden die Anforderungen an MDA-Werkzeuge diskutiert und existierende Werkzeuge untersucht. Weiters wird anhand des CALENDARIUMS ein Beispiel MDA-Projekt auf Basis einer relationalen Datenbank, Servlets, JSPs und EJBs durchgeführt. Dabei wird mit Hilfe von Tools die Erstellung eines lauffähigen Programms aus einem plattformunabhängigen Modell durchgeführt.&lt;/p>
&lt;p>Inwieweit die MDA-Werkzeuge diese Aufgabe automatisch erledigen können, oder an welchen Stellen die ProgrammiererIn selber noch Hand anlegen muss, wird durch dieses Beispielprojekt dargestellt. Weiters wird durch die Tool-Evaluierung der aktuelle Stand der Technik von MDA-Werkzeugen aufgezeigt. Dabei werden einerseits Bereiche von MDA identifiziert, die durch aktuelle Werkzeuge bereits umgesetzt wurden, und andererseits aufgezeigt, welche Bereiche unzureichend abgedeckt werden und noch weitere Forschungsaktivitäten benötigen.&lt;/p>
&lt;p> &lt;/p>
&lt;p>Download the
&lt;a href="https://www.big.tuwien.ac.at/app/uploads/2016/10/Wimmer_paper.pdf" target="_blank" rel="noopener">paper&lt;/a>&lt;/p></description></item><item><title>Moderne Softwareentwicklungsumgebungen – Evaluierung Java-basierter Ansätze</title><link>https://big.tuwien.ac.at/master-thesis/archive/moderne-softwareentwicklungsumgebungen-evaluierung-java-basierter-anstze/</link><pubDate>Tue, 19 May 2020 12:38:04 +0000</pubDate><guid>https://big.tuwien.ac.at/master-thesis/archive/moderne-softwareentwicklungsumgebungen-evaluierung-java-basierter-anstze/</guid><description>&lt;p>This work has been finished in March 2007.&lt;/p>
&lt;p>In den letzten Jahrzehnten durchlief die Softwareentwicklung eine eindrucksvolle Evolution. Anfang der 1960er Jahre begann die kommerzielle Softwareentwicklung mit primitiven Assemblerinstruktionen, kurz darauf folgten bereits die ersten Hochsprachen. In den 1990er Jahren setzte sich schließlich die objektorientierte Softwareentwicklung durch. Nun scheint diese Evolution ihre Fortsetzung durch modellgetriebene Ansätze zu finden. Diese Ansätze versuchen die objektorientierte Program mierung durch grafische Modelle zu ergänzen, und so auch die Software allgemeiner zu gestalten, um gegebenenfalls auch die eigentliche Programmiersprache ersetzen zu können. Durch die Arbeit mit diesen neuen Techniken müssen die entsprechenden Entwicklungsumgebungen zwangsläufig komplexer werden. Reichten zur Entwicklung mit Assembler bzw. frühen Hochsprachen noch ein einfacher Texteditor in Kombination mit einem Compiler oder Linker, so wurden bei objektorientierten Sprachen großteils bereits umfangreiche integrierte Entwicklungsumgebungen eingesetzt.&lt;/p>
&lt;p>In dieser Arbeit sollen die Möglichkeiten gängiger integrierter Entwicklungsumgebungen anhand eines erstellten Kriterienkatalogs bewertet werden. Die Produkte werden hinsichtlich ihrer Möglichkeiten in den Bereichen Programmierung, Modellierung, Softwarequalitätssicherung, Erweiterbarkeit und Bedienung evaluiert. Es wurden bei den Produkten sowohl Vertreter aus dem kommerziellen, als auch dem freien (Open Source) Umfeld für die Entwicklung mit der Programmiersprache Java gewählt. Diese Arbeit konzentriert sich bei den Untersuchungen auf die Entwicklungsumgebungen Eclipse 3.2, Netbeans 5.5, JBuilder 2006 und IntelliJ IDEA 6.0. Eine Partnerarbeit, die zeitgleich am Institut von Florian Skopik [Sko07] durchgeführt wurde, beschäftigt sich mit C++/C# Entwicklungsumgebungen. Da der Kriterienkatalog unabhängig von den untersuchten Entwicklungsumgebungen ist, wurde dieser Teil gemeinsam erstellt und ist in beiden Arbeiten vorhanden.&lt;/p>
&lt;p> &lt;/p>
&lt;p>Download the
&lt;a href="https://www.big.tuwien.ac.at/app/uploads/2016/10/Wihsb%c3%b6ck_paper.pdf" target="_blank" rel="noopener">paper&lt;/a> and
&lt;a href="https://www.big.tuwien.ac.at/app/uploads/2016/10/Wihsb%c3%b6ck_poster.pdf" target="_blank" rel="noopener">poster&lt;/a>&lt;/p></description></item><item><title>Constraints and Models@Runtime for EMF Profiles</title><link>https://big.tuwien.ac.at/master-thesis/archive/constraints-and-modelsruntime-for-emf-profiles/</link><pubDate>Tue, 19 May 2020 12:38:03 +0000</pubDate><guid>https://big.tuwien.ac.at/master-thesis/archive/constraints-and-modelsruntime-for-emf-profiles/</guid><description>&lt;p>Modeling languages play an essential part in the software engineering process. While UML is currently the primarily used language for this purpose, others such as Domain-Specific Modeling Languages (DSMLs) are catching up. EMF Profiles is a project developed by the Business Informatics Group to ease the creation of such DSMLs. Since EMF Profiles is a prototype it still has some limitations, which prevent the creation of certain modeling languages. This Master Thesis aims to develop and evaluate a framework based on the EMF Profiles prototype, which provides support for Models with strong constraints and runtime behavior.&lt;/p></description></item><item><title>Ubiquitäre Web-Anwendungen – Modellierung und Implementierung von Kontext Information</title><link>https://big.tuwien.ac.at/master-thesis/archive/ubiquitre-web-anwendungen-modellierung-und-implementierung-von-kontext-information/</link><pubDate>Tue, 19 May 2020 12:38:03 +0000</pubDate><guid>https://big.tuwien.ac.at/master-thesis/archive/ubiquitre-web-anwendungen-modellierung-und-implementierung-von-kontext-information/</guid><description>&lt;p>This work has been finished in November 2007.&lt;/p>
&lt;p>Ubiquitäre Web-Anwendungen sollen, entsprechend dem anytime/anywhere/anymedia Paradigma, dem Anwender, egal wann, wo und mit welchem Gerät er die Anwendung nutzt, einen individuell abgestimmten und auf die Rahmenbedingungen des Benutzers angepassten Inhalt liefern.&lt;/p>
&lt;p>Im Rahmen einer Kooperation von drei Magisterarbeiten [Brosch, Mayer, Weissensteiner] wurde ein ubiquitäres Tourismusinformationssystem entwickelt. Das Ziel dieses umfangreichen Projekts war die Konzeption, Modellierung und Implementierung einer Web-Anwendung mit Customizationunterstützung, dh. einer Web-Anwendungen, die aufgrund verschiedener Kontextfaktoren wie Benutzer, Zeit, Ort, Gerät, etc., mit der Adaptierung ihrer Dienste reagiert.&lt;/p>
&lt;p>Hierbei ist eine entsprechende Kontextbehandlung insbesondere betreffend die Repräsentation, die Erfassung und die Auswertung von Kontextinformation von entscheidender Bedeutung. Darüber hinaus ergibt sich einerseits das Problem, dass sich die Kontexterfassung und die Auswertung des aktuellen Kontexts über die gesamte Web-Anwendung erstreckt. Andererseits sind diese Funktionalitäten meist auch fix im Sourcecode verankert, wodurch die Wartung und Flexibilität des Systems erheblich eingeschränkt wird. Daher sollen diese Komponenten möglichst gekapselt und separiert von der restlichen Anwendung implementiert werden, was in dieser Arbeit mit Hilfe von aspektorientierter Programmierung gelöst wird.&lt;/p>
&lt;p>Für ubiquitäre Web-Anwendungen und die Customization ihrer Dienste ist der Kontext das Basiselement, ohne welchem keine Adaptierung möglich ist. Die Rolle des Kontext in ubiquitärenWeb-Anwendungen ist das Thema dieser Arbeit. Hierbei wird auf die Erfassung, Repräsentation und Auswertung von Kontextinformationen eingegangen, wobei Grundlagen verschiedener Kontextmodelle für die Repräsentation dargestellt werden und ein Einblick in Regelsysteme für die Auswertung von Kontextinformationen gegeben wird. Darüber hinaus werden bestehende Ansätze für Kontext verarbeitende Frameworks vorgestellt. Im Anschluss wird auf die praktische Umsetzung der Kontextbehandlung und das entwickelte Regelsystem für die erforderlichen Adaptierungen im entwickelten Forschungsprototyp eingegangen.&lt;/p>
&lt;p> &lt;/p>
&lt;p>Download the
&lt;a href="https://www.big.tuwien.ac.at/app/uploads/2016/10/Weissensteiner_paper.pdf" target="_blank" rel="noopener">paper&lt;/a> and
&lt;a href="https://www.big.tuwien.ac.at/app/uploads/2016/10/Weissensteiner_poster.pdf" target="_blank" rel="noopener">poster&lt;/a>&lt;/p></description></item><item><title>Architekturzentrierte Modellgetriebene Softwareentwicklung - Fallbeispiel und Evaluierung</title><link>https://big.tuwien.ac.at/master-thesis/archive/architekturzentrierte-modellgetriebene-softwareentwicklung-fallbeispiel-und-evaluierung/</link><pubDate>Tue, 19 May 2020 12:38:02 +0000</pubDate><guid>https://big.tuwien.ac.at/master-thesis/archive/architekturzentrierte-modellgetriebene-softwareentwicklung-fallbeispiel-und-evaluierung/</guid><description>&lt;p>This work has been finished in September 2006.&lt;/p>
&lt;p>In den vergangenen zwei Jahrzehnten hat Software eine immer stärkere Bedeutung in zahlreichen Geschäftsprozessen und alltäglichen Informationsflüssen erlangt. Sie stellt gewissermaßen das Fundament dieser Abläufe dar. Software ist zu einem kritischen Bestandteil vieler Unternehmen und Lebensbereiche geworden. Analog zu dieser Bedeutunksteigerung stehen die Entwicklungsmethoden mehr und mehr im Spannungsfeld von hoher Qualität des Endprodukts und niedrigen Entwicklungskosten bzw. kurzen -zyklen. In der Realität können viele Projekte diesen Ansprüchen nicht gerecht werden. Um den Softwareschaffenden neue Werkzeuge zu bieten, die es ermöglichen diese gegensätzlichen Ziele zu vereinbaren, gibt es seit geraumer Zeit, die Bestrebung Code automatisch aus einem Modell der zu entwickelnden Applikation zu generieren.&lt;/p>
&lt;p>Einer dieser Ansätze ist die Modellgetriebene Software Entwicklung (eng: Model Driven Software Development, kurz MDSD). Bei MDSD wird basierend auf einem in den meisten Fällen graphischen Modell durch Transformationen lauffähiger Sourcecode erzeugt. Stahl und Völter beschreiben in ihrem Buch „Modellgetriebene Software Entwicklung“ [1] einen pragmatischen Ansatz um mit Hilfe von MDSD und bereits heute verfügbaren Techniken den Infrastrukturcode einer Applikation bzw. einer ganzen Software-Systemfamilie zu generieren. Diesen Ansatz bezeichnen sie als architekturzentrierte-MDSD (AC-MDSD). Es wird dabei versucht den Infrastrukturcode einer definierten Softwaresystemfamilie möglichst vollständig zu generieren. Eine Softwaresystemfamilie ist die Summe aller Applikationen die auf derselben Architektur und technologischen Plattform beruhen.&lt;/p>
&lt;p>Die Codegenerierung bei AC-MDSD stützt sich auf zwei Säulen. Zum einen werden die verwendeten Modelle mittels einer so genannten Domain Specific Language (DSL) formalisiert. Die DSL spiegelt mit ihren Ausdrucksmitteln den Problemraum der jeweiligen Domäne wieder. Die Konzepte der DSL werden durch ein Metamodell der Domäne abgebildet. Zum anderen erleichtert der Einsatz eines Frameworks und wieder verwendbarer Komponenten die Erzeugung des Sourcecodes, da der „Weg“ zwischen Generat und Modell verkürzt wird.&lt;/p>
&lt;p>Im Rahmen dieser Diplomarbeit wird ausgehend von den in [1] beschriebenen theoretischen Konzepten und dem von den Autoren des Buches mitentwickelten Codegenerator Toolkit openArchitectureWare (oAW) [2], die konkrete Vorgehensweise bei der Softwareerstellung mittels AC-MDSD an Hand eines praktischen Beispiels aus dem Bereich „Softwareinfrastruktur für E-Business-Anwendungen“ veranschaulicht. Die Umsetzung erfolgt mit Hilfe von Technologien aus dem J2EE Bereich wie JSPs, Servlets, Enterprise JavaBeans und dem Webframework Struts. Fachlich handelt es sich dabei um eine Online-Buchhandlung. Im Rahmen der Durchführung soll auch die Erstellung eines GEF-Editors für die DSL mit Hilfe von oAW veranschaulicht werden. Neben diesen praktischen Aspekten der Arbeit werden die für das Verständnis nötigen theoretischen Konzepte dargelegt, und eine Abgrenzung zu verwandten Methoden wie MDA durchgeführt. Abschließend wird eine kritische Evaluierung hinsichtlich der Praxistauglichkeit des vorgestellten Ansatzes vorgenommen. Dabei werden sowohl dessen Stärken als auch Schwächen gegenübergestellt.&lt;/p>
&lt;p>Quellenverzeichnis&lt;/p>
&lt;p>[1] Markus Völter, Thomas Stahl; Modellgetriebene Softwareentwicklung. dpunkt.verlag, 1. Auflage 2005 [2] &lt;a href="http://www.openarchitectureware.org">www.openarchitectureware.org&lt;/a>&lt;/p>
&lt;p> &lt;/p>
&lt;p>Download the
&lt;a href="https://www.big.tuwien.ac.at/app/uploads/2016/10/Weismann_paper.pdf" target="_blank" rel="noopener">paper&lt;/a> and
&lt;a href="https://www.big.tuwien.ac.at/app/uploads/2016/10/Weismann_poster.pdf" target="_blank" rel="noopener">poster&lt;/a>&lt;/p></description></item><item><title>Evaluation of UML Model Transformation Tools</title><link>https://big.tuwien.ac.at/master-thesis/archive/evaluation-of-uml-model-transformation-tools/</link><pubDate>Tue, 19 May 2020 12:38:02 +0000</pubDate><guid>https://big.tuwien.ac.at/master-thesis/archive/evaluation-of-uml-model-transformation-tools/</guid><description>&lt;p>This work has been finished in June 2005.&lt;/p>
&lt;p>MDA(Model Driven Architecture) defines a software development process. Three models build the core of the MDA: PIM (Platform Independent Model), PSM (Platform Specific Model) and Code. The developers of software are only required to concentrate on developing models in PIM format. The transformation to PSM and Code, which is the traditional understanding for UML model transformation can be automatically achieved by using general transformation tools.&lt;/p>
&lt;p>The traditional way of developing UML transformations is usually to develop a specific one to one transformation using a fixed set of rules and profiles. The development of the transformation is usually complicated and time consuming. Due to the many different forms of UML, the transformation between these UMLs has been proved to be a very tough and inefficient.&lt;/p>
&lt;p>Since the introduction of MDA, MOF(Meta Object Facility) and QVT (Query, View and Transformation) concepts from the Object Management Group(OMG), UML transformations come to a new era. Many working groups have presented their concepts and made their implementation using these definitions.&lt;/p>
&lt;p>This diploma thesis gives an introduction to the principle of UML transformation according to MDA, MOF and QVT. It also gives an evaluation of the up to date model transformation tools based on these concepts to show their strength and weaknesses. These state of the art transformation tools are built according to OMG MOF 2.0 Query / View / Transformation. The evaluated tools are UMT, MTL, ATL, GMT, BOTL and OptimalJ.&lt;/p>
&lt;p>In this diploma thesis the analysis methods described in a review of OMG MOF 2.0 QVT [Gardner03]are used. The evaluation of the transformation tools has been done in a set of aspects, such as scalability, simplicity and bi-directionality of mappings.&lt;/p>
&lt;p> &lt;/p>
&lt;p>Download the
&lt;a href="https://www.big.tuwien.ac.at/app/uploads/2016/10/Wang_paper.pdf" target="_blank" rel="noopener">paper&lt;/a>&lt;/p></description></item><item><title>Moola - A Groovy-based Model Operation Orchestration Language</title><link>https://big.tuwien.ac.at/master-thesis/archive/moola-a-groovy-based-model-operation-orchestration-language/</link><pubDate>Tue, 19 May 2020 12:38:02 +0000</pubDate><guid>https://big.tuwien.ac.at/master-thesis/archive/moola-a-groovy-based-model-operation-orchestration-language/</guid><description>&lt;p>A core concept of Model-Driven Software Engineering (MDSE) is the use of models and transformations. Models represent information of the system, while transformations allow converting one or more input models to specific output models. In the last years, more and more transformation languages were introduced to allow MDSE to be applied to a wide spectrum of use cases. Today, many advanced scenarios can be expressed by MDSE and the use of new transformation languages. However, in every non-trivial project, multiple transformations have to be executed in particular order to yield the final result. Most transformation languages do not allow to be integrated in such an orchestration. They either lack interfaces to the outside and hence violate the black box principal or need a specific execution context, such as a running development environment. In this thesis, I analyze several existing tools for Transformation Orchestration, which try to overcome these problems to allow for the orchestration of various transformation languages to one transformation chain. I then take inspiration from these tools and other domains, such as Build Management and Workflow Management, to create a new tool for Transformation Orchestration called Moola. Especially concepts from build tools such as Gradle can be applied to Transformation Orchestration. If we see the models of the last transformation as overall outcome, the whole orchestration can be seen as build process. Like Gradle, Moola will be implemented as domain-specific language in Groovy. This allows for powerful, yet easy to read orchestration mark-up. Moola will then be evaluated against use cases taken from the ARTIST project.&lt;/p></description></item><item><title>Ein Ansatz zur Auflösung von Konflikten bei der Versionierung von Modellen</title><link>https://big.tuwien.ac.at/master-thesis/archive/ein-ansatz-zur-auflsung-von-konflikten-bei-der-versionierung-von-modellen/</link><pubDate>Tue, 19 May 2020 12:38:01 +0000</pubDate><guid>https://big.tuwien.ac.at/master-thesis/archive/ein-ansatz-zur-auflsung-von-konflikten-bei-der-versionierung-von-modellen/</guid><description>&lt;p>This work has been finished in February 2009.&lt;/p>
&lt;p>In der modernen Softwareentwicklung werden Modelle nicht nur zur Dokumentation eingesetzt sondern auch zur Generierung von Quellcode. Syntaxfehler und Inkonsistenzen im Modell wirken sich daher direkt auf den Quellcode aus. Bearbeitet nur ein Entwickler ein Modell, so kann ein zumindest in sich konsistentes Modell durch die von der Entwicklungsumgebung zur Verfügung gestellten Werkzeuge gewährleistet werden. Arbeiten jedoch mehrere Entwickler kollaborativ an einem Modell, was der realistischere Fall ist, muss dieses unter Versionskontrolle (version control system, VCS) gestellt werden. Herkömmliche textbasierte Ansätze zur Versionierung sind für graphische Modelle jedoch nicht ausreichend.&lt;/p>
&lt;p>Die Verwendung von konventionellen VCS zur Versionierung von Modellen bringt zwei grundlegende Probleme mit sich. Das erste Problem bezieht sich auf die auftretenden Konflikte zwischen zwei Modellversionen, z.B. wenn mehrere Entwickler gleichzeitig dasselbe Modellelement ändern. Diese Konflikte müssen durch die Entwickler manuell aufgelöst werden, da für eine Zusammenführung der Änderungen keine Werkzeugunterstützung existiert. Treten bei der manuellen Zusammenführung der Änderungen Fehler auf, hat dies dierekten Einfluss auf den generierten Quellcode. Das zweite Problem bezieht sich auf Information, die während der Konfliktauflösung entsteht, aber für zukünftige ähnliche Konfliktsituationen nicht gespeichert wird und daher nicht wiederverwendet werden kann. Diese Information könnte jedoch dem Entwickler bei späteren Konfliktauflösungen hilfreich sein. Außerdem könnten auf Basis dieser Information über mögliche Konfliktsituationen Entwurfsrichtlinien für die Erstellung eines Modells vorgegeben werden.&lt;/p>
&lt;p>Der in dieser Arbeit vorgestellte Ansatz zur Konfliktauflösung ermöglicht eine Beschreibung von Auflösungsstrategien für syntaktische und statisch semantische Konflikte. Zur Beschreibung der syntaktischen Konflikte und deren Auflösung wird eine modellbasierte, deskriptive Sprache vorgestellt. Zur Auflösung der statisch semantischen Konflikte werden Graph-Produktionsregeln bzw. Muster mittels OCL genutzt.&lt;/p>
&lt;p>Durch den modellbasierten Ansatz der Sprachdefinition für die Beschreibung der Auflösungsstrategien ist eine einfache und flexible Erweiterung bzw. Änderung der Strategien möglich. Die gemeinsame Struktur bildet die Grundlage für eine Protokollierung der Benutzerentscheidungen. Aus diesen können zusätzliche Informationen zur Unterstützung des Benutzers bei der Entscheidungsfindung der passenden Auflösungsstrategie gewonnen werden. Die Prüfung auf Einhaltung von Entwurfsrichtlinien ist ebenfalls möglich. Durch die erhöhte Qualität der zusammengeführten Modellversionen werden beim generierten Code Fehler zur Compile- und Laufzeit reduziert.&lt;/p>
&lt;p> &lt;/p>
&lt;p>Download the
&lt;a href="https://www.big.tuwien.ac.at/app/uploads/2016/10/Tragatschnig_paper.pdf" target="_blank" rel="noopener">paper&lt;/a> and
&lt;a href="https://www.big.tuwien.ac.at/app/uploads/2016/10/Tragatschnig_poster.pdf" target="_blank" rel="noopener">poster&lt;/a>&lt;/p></description></item><item><title>Enterprise Mashups - A Teaching Case</title><link>https://big.tuwien.ac.at/master-thesis/archive/enterprise-mashups-a-teaching-case/</link><pubDate>Tue, 19 May 2020 12:38:01 +0000</pubDate><guid>https://big.tuwien.ac.at/master-thesis/archive/enterprise-mashups-a-teaching-case/</guid><description>&lt;p>This work has been finished in March 2012.&lt;/p>
&lt;p>Der Einsatz von Enterprise Mashups erlaubt Anwendern ohne technische Kenntnisse aus vorhandenen Daten in unterschiedlichen Systemen ad hoc eine neue Anwendung zu erstellen. Die Integration heterogener Daten in eine neue Anwendung durch den Endanwender, stellt gerade im Einsatz von Unternehmen ein großes noch ungenutztes Potential dar.&lt;/p>
&lt;p>So arbeiten viele Unternehmen mit hoch integrierten ERP Systemen, die einen Großteil der Daten zur Steuerung der Prozesse enthalten. Allerdings sind nicht alle Informationen vollständig im ERP System enthalten bzw. können nicht alle Operationen über das ERP System ausgeführt werden. Es entsteht die Situation bei der Daten aus unterschiedlichen Systemen zusammengeführt und daraus Entscheidungen getroffen werden müssen. Der Einsatz einer Mashup Applikation, welche bei Bedarf entsprechend der Anforderung erstellt wird, bringt einen entscheidenden Mehrwert für die Fachabteilungen.&lt;/p>
&lt;p>Im Rahmen der vorliegenden Arbeit werden die speziellen Anforderungen wie Datenqualität, die erhöhte Sicherheit bei unternehmerisch sensiblen Daten und die Einbindung von integrierten ERP Systemen als auch von Legacy Applikationen in Enterprise Mashups untersucht. Unter Legacy Applikationen werden alle Arten von unternehmerischen Anwendungen verstanden, die unter Umständen technisch nicht mehr auf dem neuesten Stand sind, allerdings aus verschiedenen Gründen weiterhin im Unternehmen eingesetzt werden. Des Weiteren wird ein Prototyp für ein Enterprise Mashup entwickelt, welcher die Verwendung von Informationen aus dem ERP System Microsoft Dynamics AX in Verbindung mit anderen Mashup Daten erlaubt. Für die Realisierung des Prototyps wird innerhalb Dynamics AX eine Möglichkeit zur Anbindung von Mashups entwickelt. Für das Mashup selbst werden vorhandene Frameworks evaluiert und ein Framework für die Umsetzung des Prototyps gewählt, welches die entsprechenden Dienste zum Erstellen des Mashups und Bereitstellen der Daten für die Clients bietet.&lt;/p>
&lt;p>Mit dem exemplarisch umgesetzten Mashup wird die schnelle und unkomplizierte Kombination der Daten unterschiedlicher Anwendungen in den Vordergrund gestellt. Der Prototyp stellt einen Leitfaden für Anwender und Unternehmen dar, um die oft komplizierte technische und organisatorische Umsetzung neuer Applikationen zu vereinfachen. Mit Mashups wird Mitarbeiten ein Werkzeug bereit gestellt, um bei Bedarf selbst ohne Programmierkenntnisse und ohne die Unterstützung der IT Abteilung die notwendige Anwendung oder Auswertung erstellen zu können.&lt;/p>
&lt;p>Abstract and paper may be found in our &lt;a class="external" href="http://publik.tuwien.ac.at/showentry.php?ID=216156&amp;amp;lang=2">publication database&lt;/a>.&lt;/p>
&lt;p>Download the
&lt;a href="https://www.big.tuwien.ac.at/app/uploads/2016/10/Ungerb%c3%b6ck_poster.pdf" target="_blank" rel="noopener">poster&lt;/a>&lt;/p></description></item><item><title>From BSopt-DSL to Windows Workflow</title><link>https://big.tuwien.ac.at/master-thesis/archive/from-bsopt-dsl-to-windows-workflow/</link><pubDate>Tue, 19 May 2020 12:38:00 +0000</pubDate><guid>https://big.tuwien.ac.at/master-thesis/archive/from-bsopt-dsl-to-windows-workflow/</guid><description>&lt;p>This work has been finished in September 2010.&lt;/p>
&lt;p>Abstract and paper may be found in our &lt;a class="external" href="http://publik.tuwien.ac.at/showentry.php?ID=189404&amp;amp;lang=2">publication database&lt;/a>.&lt;/p>
&lt;p>Download the
&lt;a href="https://www.big.tuwien.ac.at/app/uploads/2016/10/Topf_paper.pdf" target="_blank" rel="noopener">paper&lt;/a> and
&lt;a href="https://www.big.tuwien.ac.at/app/uploads/2016/10/Topf_poster.pdf" target="_blank" rel="noopener">poster&lt;/a>&lt;/p></description></item><item><title>Integration von Crosscutting Concerns in aspectWebML</title><link>https://big.tuwien.ac.at/master-thesis/archive/integration-von-crosscutting-concerns-in-aspectwebml/</link><pubDate>Tue, 19 May 2020 12:38:00 +0000</pubDate><guid>https://big.tuwien.ac.at/master-thesis/archive/integration-von-crosscutting-concerns-in-aspectwebml/</guid><description>&lt;p>This work has been finished in January 2008.&lt;/p>
&lt;p>Ubiquitäre Web-Anwendungen werden nach dem anytime/anywhere/anymedia Paradigma individuell auf den Benutzungskontext, wie zum Beispiel Zeit, Ort oder Endgerät angepasst. Die Durchführung solcher Customizations ist oft komplex, da sich eine Änderung meist nicht nur auf einen bestimmten Teil der Web-Anwendung bezieht, sondern eine Vielzahl von Stellen betrifft, die in den verschiedenen Ebenen der Web-Anwendung, Content, Hypertext und Präsentation liegen. Im Bereich des Model Driven Engineering ziehen die meisten Web-Modellierungssprachen diese Eigenschaft von Customizations nicht gesondert in Betracht. Änderungen werden, so wie herkömmliche Anpassungen des Models, an mehreren Stellen direkt im Kern-Model vorgenommen. Diese Vorgehensweise führt allerdings bezüglich Wartbarkeit und Erweiterbarkeit zu einer erhöhten Komplexität und damit zu einem ineffizienten Entwicklungsprozess. In aspectWebML, einer Erweiterung der Web-Modellierungssprache WebML, werden Customizations dagegen als so genannte Crosscutting Concerns im Sinne der Aspektorientierung betrachtet und mit Hilfe spezieller aspektorientierter Konzepte behandelt. Diese ermöglichen eine klare Trennung bei der Modellierung von Kernfunktionalität und Crosscutting Concerns, wodurch eine Reduzierung der Komplexität der Modelle, eine Verbesserung der Wartbarkeit sowie der Wiederverwendbarkeit einzelner Customizations erreicht wird. Als Teil des Modellierungsprozesses muss dieser klaren Trennung von Kernfunktionalität und Crosscutting Concerns aber auch ein geeigneter Mechanismus gegenübergestellt werden, der die einzelnen Teile wieder zu einem Gesamtmodel, dem Ergebnis der Modellierung, integriert.&lt;/p>
&lt;p>Das Ziel dieser Arbeit ist daher die Implementierung eines Algorithmus zur Integration von Crosscutting Concerns in aspectWebML auf Basis der bestehenden aspektorientierten Konzepte. Dabei sollen die Anforderungen an solch eine Integration analysiert werden und eine geeignete Technologie gewählt werden, um die 13 verschiedenen Möglichkeiten zur Modellierung von Customization-Szenarien in aspectWebML umsetzen zu können. Der Algorithmus soll in ein vorhandenes Modellierungswerkzeug integriert werden, das mittels EMF (Eclipse Modeling Framework) erzeugt und um verschiedene Funktionalitäten zur Unterstützung des Modellierers erweitert wurde, sowie anhand verschiedener Customization Szenarien überprüft werden.&lt;/p>
&lt;p> &lt;/p>
&lt;p>Download the
&lt;a href="https://www.big.tuwien.ac.at/app/uploads/2016/10/Tomasek_paper.pdf" target="_blank" rel="noopener">paper&lt;/a> and
&lt;a href="https://www.big.tuwien.ac.at/app/uploads/2016/10/Tomasek_poster.pdf" target="_blank" rel="noopener">poster&lt;/a>&lt;/p></description></item><item><title>Entwurf und Realisierung einer Internetplattform für den Verlag von fotounterstützten Dokumentationen alpiner Touren</title><link>https://big.tuwien.ac.at/master-thesis/archive/entwurf-und-realisierung-einer-internetplattform-fr-den-verlag-von-fotountersttzten-dokumentationen-alpiner-touren/</link><pubDate>Tue, 19 May 2020 12:37:59 +0000</pubDate><guid>https://big.tuwien.ac.at/master-thesis/archive/entwurf-und-realisierung-einer-internetplattform-fr-den-verlag-von-fotountersttzten-dokumentationen-alpiner-touren/</guid><description>&lt;p>This work has been finished in August 2006.&lt;/p>
&lt;p>Immer mehr Wanderer und Bergsteiger werden durch die Faszination der Gebirgswelt sowie deren Erlebnis­ und Erholungswert in das Gebirge gezogen. Voraussetzung zum erfolgreichen und sicheren Durchführen von Touren im Gebirge ist eine sehr genaue Tourenplanung. Diese erhöht die Sicherheit und somit den Erlebniswert.&lt;/p>
&lt;p>Von besonderem Interesse bei der Tourenplanung sind genaue Informationen über den Tourenverlauf sowie über mögliche Gefahren­ und Schlüsselstellen. Die meisten Informationen werden in Textform angeboten. Sowohl Fachliteratur als auch Informationen im Internet beschreiben Touren überwiegend in Worten, es fehlt in der Regel gutes Fotomaterial. Doch gerade dieses verbessert die Vorstellung über eine alpine Tour ganz wesentlich. Sowohl die Orientierung vor Ort als auch die Einschätzung von Schlüsselstellen in der Tour werden durch vorher bekanntes Fotomaterial wesentlich erleichtert.&lt;/p>
&lt;p>Aus diesem Grund beschäftigt sich die vorliegende Arbeit mit der Entwicklung einer Internetplattform für den Verlag von fotounterstützten Dokumentationen alpiner Touren. Jede Dokumentation soll dabei genügend Fotomaterial enthalten können, um den gesamten Verlauf einer Tour sowie alle Schlüsselstellen auf der Tour sichtbar zu machen. Die Internetplattform unterstützt also Wanderer und Bergsteiger dabei, ausreichend Bildinformation über bevorstehende Touren für eine ausführliche Tourenplanung zu erhalten. Umgekehrt haben Tourengeher auch die Möglichkeit, als Alpinautoren fotounterstützte Dokumentationen alpiner Touren zu publizieren.&lt;/p>
&lt;p>Da das Durchführen und Erstellen derartiger Dokumentationen stets mit viel Zeit und Kosten verbunden ist, sollen die Kosten durch Verkauf der Dokumentationen nach Möglichkeit gedeckt werden. Die Internetplattform stellt dafür ein geeignetes Verkaufssystem zur Verfügung.&lt;/p>
&lt;p>Die Plattform wurde mit Sommerbeginn 2006 eröffnet1) und stellt als Basisinhalt einen Osttirol Wander­ und Hochtourenführer sowie einen kleinen Zentralpyrenäen Wanderführer zur Verfügung. Da es Berge weltweit gibt und Alpinisten unterschiedlichste Sprachen sprechen, wurde die Internetplattform mehrsprachig ausgeführt, zur Zeit in den Sprachen Deutsch, Englisch und Französisch. So haben Autoren die Möglichkeit, Dokumentationen in mehreren Sprachen zu publizieren und Tourengeher können Dokumentationen in mehreren Sprachen beziehen.&lt;/p>
&lt;p>Die vorliegende Arbeit beschäftigt sich mit der Entwicklung dieser Plattform. Zuerst wird eine Anforderungsanalyse erstellt, welche die Anforderungen einer solchen Plattform aufzeigt. Basierend auf diesen Anforderungen wird die Plattform anschließend modelliert. Der Schwerpunkt der vorliegenden Arbeit liegt in der Modellierung. In dieser werden sämtliche Modelle aufgezeigt, die für eine Realisierung einer derartigen Plattform notwendig sind. Aufbauend auf der Modellierung werden die wichtigsten Teile einer möglichen Implementierung genauer besprochen. Auch rechtliche Grundlagen zum Betrieb der Plattform werden abschließend erörtert.&lt;/p>
&lt;p>Gezeigt wird, dass für die Umsetzung eines derartigen Verlages neben umfangreichen technischen und sprachlichen Kenntnissen sowie neben Erfahrungen in der Alpinistik auch grundlegende Kenntnisse in den Gebieten der Buchhaltung und im Daten­ und Informatikrecht notwendig sind.&lt;/p>
&lt;p>Die Realisierung der Plattform stellt sich diesbezüglich als ein multidisziplinäres Projekt in dem spannenden Gebiet des Bergsports heraus.&lt;/p>
&lt;p> &lt;/p>
&lt;p>Download the
&lt;a href="https://www.big.tuwien.ac.at/app/uploads/2016/10/Skunk_paper.pdf" target="_blank" rel="noopener">paper&lt;/a> and
&lt;a href="https://www.big.tuwien.ac.at/app/uploads/2016/10/Skunk_poster.pdf" target="_blank" rel="noopener">poster&lt;/a>&lt;/p></description></item><item><title>TeCa-4-DaMi – Entwicklung eines Frameworks für die testgetriebene Datenmigration</title><link>https://big.tuwien.ac.at/master-thesis/archive/teca-4-dami-entwicklung-eines-frameworks-fr-die-testgetriebene-datenmigration/</link><pubDate>Tue, 19 May 2020 12:37:59 +0000</pubDate><guid>https://big.tuwien.ac.at/master-thesis/archive/teca-4-dami-entwicklung-eines-frameworks-fr-die-testgetriebene-datenmigration/</guid><description>&lt;p>This work has been finished in November 2008.&lt;/p>
&lt;p>Aufgrund der schon weit fortgeschrittenen und immer weiter fortschreitenden Ver-netzung von verschiedenen Systemen und Datenquellen mussten und müssen auch weiterhin Wege gefunden werden, diese Vernetzungen möglichst effektiv durchzu-führen, um möglichst viel Nutzen daraus zu ziehen.&lt;/p>
&lt;p>Ein in diese Thematik fallender Bereich befasst sich mit der Integration bzw. Migration von Daten, die mittlerweile in allen Bereichen der Wirtschaft Anwendung findet. So zum Beispiel in Unternehmen, die Kooperationen eingehen oder fusionieren, Unternehmen, die andere Unternehmen übernehmen oder bei Plattformen, die es sich zur Aufgabe machen, Informationen aus unterschiedlichen Quellen in unterschiedlichen Formaten mit unterschiedlichen Strukturen zur Verfügung zu stellen. Bei all diesen Ereignissen spielt Informationsintegration eine große und entscheidende Rolle.&lt;/p>
&lt;p>Ein Ziel dieser Arbeit ist es, die Thematik der Informationsintegration und insbesondere der Datenmigration näher zu beleuchten. Problembereiche sollen aufgedeckt und der momentane Stand an Werkzeugen und Sprachen dargestellt werden. Eine in der Theorie beschriebene Vorgehensweise wird anhand eines praktischen Beispieles umgesetzt, um einerseits praktische Erfahrung zu sammeln, und andererseits einzelne Abläufe besser darstellen zu können.&lt;/p>
&lt;p>Ein wichtiger Punkt bei der Datenmigration ist die Verlässlichkeit und die Korrektheit einer solchen Migrationslösung, weshalb der TeCa-4-DaMi Prozess (Test Cases for Data Migration) entwickelt wird, der die Methode der testgetriebenen Datenmigration einführt, um erfolgreiche Migrationslösungen zu erstellen. Einen Kernpunkt dieses Prozesses stellen die Testfälle dar, die ausschlaggebend für den Erfolg des Prozesses sind. Daher bietet TeCa-4-DaMi ein Framework, das speziell die systematische Erstellung von Testfällen unterstützt, um die Korrektheit und Vollständigkeit von Migrationslösungen zu gewährleisten.&lt;/p>
&lt;p> &lt;/p>
&lt;p>Download the
&lt;a href="https://www.big.tuwien.ac.at/app/uploads/2016/10/Swoboda_paper.pdf" target="_blank" rel="noopener">paper&lt;/a> and
&lt;a href="https://www.big.tuwien.ac.at/app/uploads/2016/10/Swoboda_poster.pdf" target="_blank" rel="noopener">poster&lt;/a>&lt;/p></description></item><item><title>Measuring Software Development Productivity - Specification, Design and Prototypical Implementation of a Performance Measurement System</title><link>https://big.tuwien.ac.at/master-thesis/archive/measuring-software-development-productivity-specification-design-and-prototypical-implementation-of-a-performance-measurement-system/</link><pubDate>Tue, 19 May 2020 12:37:58 +0000</pubDate><guid>https://big.tuwien.ac.at/master-thesis/archive/measuring-software-development-productivity-specification-design-and-prototypical-implementation-of-a-performance-measurement-system/</guid><description>&lt;p>This work has been finished in October 2004.&lt;/p>
&lt;p>Companies require software process performance measurement systems in order to reach higher levels of the Capability Maturity Model and gain long term competitive advantages. Current measurement programs suffer from missing, invalid or delayed data, and a lack of metrics standards and analysis functionality. In order to avoid these limitations, the approach utilized in this thesis employs balanced, goal-oriented metrics based on a stakeholder-driven methodology to analyse the software development process. Decision support technology enables the integration and visualization of data gathered from various sources in the organization. This approach was designed and implemented as a generic prototype on the Lotus Notes platform, extending the product range of a Vienna software company by adding a component to a software quality and test suite. The software process of a major customer in the insurance industry was analysed as a sample process.&lt;/p>
&lt;p> &lt;/p>
&lt;p>Download the
&lt;a href="https://www.big.tuwien.ac.at/app/uploads/2016/10/Stefanov_paper.pdf" target="_blank" rel="noopener">paper&lt;/a>&lt;/p></description></item><item><title>Content Wiederverwendung in verteilten Content Management Systemen</title><link>https://big.tuwien.ac.at/master-thesis/archive/content-wiederverwendung-in-verteilten-content-management-systemen/</link><pubDate>Tue, 19 May 2020 12:37:57 +0000</pubDate><guid>https://big.tuwien.ac.at/master-thesis/archive/content-wiederverwendung-in-verteilten-content-management-systemen/</guid><description>&lt;p>This work has been finished in May 2006.&lt;/p>
&lt;p>Content Management Systeme sind in Unternehmen feste Bestandteile beim Contenterstellungsprozess. Sie unterstützen Autoren beim Erstellen und Bearbeiten von Content durch grafische Benutzeroberflächen, einfache Bedienung und unzähligen Hilfestellungen. Da oft gleicher Content auf verschiedenen Webseiten angezeigt und nur einmal erstellt werden soll, setzen immer mehr Unternehmen Content Wiederverwendung ein. Die meisten Content Management Systeme beinhalten – oft recht einfache – Funktionen, um Content wieder zu verwenden. Doch wie kann Content in Unternehmen, wo mehrere Abteilungen Content erfassen und verschiedene Content Management Systeme im Einsatz sind, wieder verwendet werden?&lt;/p>
&lt;p>Diese Arbeit befasst sich mit allgemeinen Aspekten von Content Management Systemen und Content Wiederverwendung, wie Content Wiederverwendung in verteilten Content Management Systemen realisiert werden kann und wie Content Wiederverwendung von derzeit am Markt erhältlichen Content Management Systemen unterstützt wird.&lt;/p>
&lt;p> &lt;/p>
&lt;p>Download the
&lt;a href="https://www.big.tuwien.ac.at/app/uploads/2016/10/Staribacher_paper.pdf" target="_blank" rel="noopener">paper&lt;/a> and
&lt;a href="https://www.big.tuwien.ac.at/app/uploads/2016/10/staribacher_poster.pdf" target="_blank" rel="noopener">poster&lt;/a>&lt;/p></description></item><item><title>Peer-to-Peer Realisierung nachvollziehbarer Dokumentflüsse</title><link>https://big.tuwien.ac.at/master-thesis/archive/peer-to-peer-realisierung-nachvollziehbarer-dokumentflsse/</link><pubDate>Tue, 19 May 2020 12:37:57 +0000</pubDate><guid>https://big.tuwien.ac.at/master-thesis/archive/peer-to-peer-realisierung-nachvollziehbarer-dokumentflsse/</guid><description>&lt;p>This work has been finished in April 2005.&lt;/p>
&lt;p>Traceable Document Flows [Bern04] ist ein auf dem BIG-Institut entwickeltes Konzept, das es – wie der Name schon sagt – ermöglicht, zu verfolgen, wohin sich Dokumente im Laufe der Zeit bewegt haben. Von Anwenderseite erhält man so eine Art Dokument-Historie, obwohl die Dokumente und deren Versionen völlig dezentral verwaltet werden.&lt;/p>
&lt;p>Im Zuge der Diplomarbeit wird dieses Konzept unter Verwendung der Middleware JXTA [Jxta04] als Prototyp [Tdfs04] realisiert. Jeder Rechner wird als Peer mit einem Namen, einer Beschreibung und einer eindeutigen Peer ID ausgestattet und kann von anderen Peers im Netzwerk gesucht und, wenn gefunden, angesprochen werden. Die Kommunikation erfolgt bei einfachen Mitteilungen über Broadcasting und bei Mitteilungen, deren Empfang unbedingt gewährleistet sein muss, über eine Pipe, die eine direkte Verbindung zwischen zwei Peers darstellt.&lt;/p>
&lt;p>Der Prototyp bietet die Möglichkeit Dokumente und Versionen zu erzeugen und diese mittels der Interaktion Checkin entweder lokal oder remote auf anderen Peers zu platzieren. Weiters ist es möglich, Versionen in andere Versionen hineinzuführen (Merge), sie auf andere Peers zu verschieben (Reallocate) oder sie zu löschen (Delete).&lt;/p>
&lt;p>Dokumente können andere Dokumente abonnieren, um das Ereignis zu empfangen, das beim Durchführen einer der oben genannten Interaktionen auf dieses Dokument ausgelöst wird. Das Ereignis wird dabei von Version zu Version weitergeleitet, bis alle Versionen des abonnierenden Dokuments erreicht wurden. JXTA bietet aber auch die Möglichkeit, solche Mitteilungen über das JXTA-Discovery-Service zu verbreiten. Der Vergleich dieser beiden Mechanismen stellt den zweiten Teil der Diplomarbeit dar. Hauptaugenmerk liegt dabei auf der Zuverlässigkeit und Dauer des Ereignisflusses in unterschiedlichen Netzwerken. Möchte man sicherstellen, dass ein Ereignis alle Versionen des abonnierenden Dokuments erreicht, ist erstere Variante zu wählen. Ist einem hingegen wichtig, dass die Verteilung so schnell als möglich unter Inkaufnahme des Nichterreichens mancher Versionen durchgeführt wird, ist dem JXTA-Discovery-Service der Vorzug zu geben.&lt;/p>
&lt;p> &lt;/p>
&lt;p>Download the
&lt;a href="https://www.big.tuwien.ac.at/app/uploads/2016/10/Sonntag_poster.pdf" target="_blank" rel="noopener">paper&lt;/a>&lt;/p></description></item><item><title>Model Weaver 2.0 - eine AJAX-basierte Web-Anwendung für Model Weaving</title><link>https://big.tuwien.ac.at/master-thesis/archive/model-weaver-2-0-eine-ajax-basierte-web-anwendung-fr-model-weaving/</link><pubDate>Tue, 19 May 2020 12:37:56 +0000</pubDate><guid>https://big.tuwien.ac.at/master-thesis/archive/model-weaver-2-0-eine-ajax-basierte-web-anwendung-fr-model-weaving/</guid><description>&lt;p>This work has been finished in January 2008.&lt;/p>
&lt;p>Modellgetriebene Softwareentwicklung (MDSD) soll dabei helfen, Softwaresysteme hinsichtlich ihrer Komplexität zu vereinfachen und ihre Qualität zu steigern. Dazu werden Werkzeuge benötigt, welche den Benutzer dabei unterstützen. Ein Bestandteil von MDSD ist Model Weaving, welches für eine Vielzahl von Anwendungen eine Voraussetzung darstellt. Unter anderem liefert Model Weaving die nötigen Informationen, um daraus Modelltransformationen abzuleiten. Es ist möglich, mehrere Modelle durch diese Modelltransformation in ein Modell zusammen zu führen, Modelle in ihrem Informationsumfang zu erweitern und dergleichen. Herkömmliche Ansätze, wie der ATLAS Model Weaver (AMW) der ATLAS Group, sind als Rich-Client-Anwendung implementiert, was nicht immer von Vorteil ist. Zusätzliche Ressourcen auf der Client-Seite und eine Installation beim Benutzer zählen dazu. Da der AMW Bestandteil des Eclipse Modelling Frameworks ist und nicht jede Version miteinander kompatibel ist, kann es hier zu unerwarteten Schwierigkeiten kommen. Auch in der modellgetriebenen Softwareentwicklung haben sich Plattformen entwickelt, welche den Austausch von Modellen erleichtern sollen. Diese als „Model Repositories“ bezeichneten Plattformen sollen Grundgerüste für die Modellentwicklung bereitstellen. Hier wäre es hilfreich, Verbindungen zwischen den einzelnen „Repositories“ zu schaffen. Ziel dieser Arbeit ist es, basierend auf dem MetaModelbrowser von Jürgen Flandorfer, eine Anwendung zu entwickeln, welche das Thema Model Weaving aufgreift und versucht, dieses mit dem Web zu verbinden. Dies hat den Vorteil, dass dem Benutzer der Umgang mit dem Web vertraut ist, somit kein zusätzlicher Lernaufwand entsteht. Probleme bezüglich Performanz auf der Clientseite werden vermieden und ein leichtgewichtiger, ressourcensparender Client wird geschaffen, welcher keine Installation mehr benötigt. Da eine weitgehend eigenständige Weaving Umgebung geschaffen wird, kommt es nicht zu einem Zusammenspiel mehrerer Softwarekomponenten, wie es beim AMW der Fall ist. Modelle können zentral am Server abgelegt werden. Dies ermöglicht ein gemeinsames Arbeiten an Modellen. Mit einer Funktion des MetaModelbrowsers können Modelle anhand einer URL eingebunden werden. Somit ist es möglich, Model Repositories in den Weaving Prozess mit einzubeziehen. Als Alternative zu den Eclipse basierten Model Weaving Ansätzen soll also eine webbasierte Anwendung geschaffen werden, mit deren Hilfe die Probleme der herkömmlichen Ansätze vermieden werden können.&lt;/p>
&lt;p> &lt;/p>
&lt;p>Download the
&lt;a href="https://www.big.tuwien.ac.at/app/uploads/2016/10/Solarz_paper.pdf" target="_blank" rel="noopener">paper&lt;/a> and
&lt;a href="https://www.big.tuwien.ac.at/app/uploads/2016/10/Solarz_poster.pdf" target="_blank" rel="noopener">poster&lt;/a>&lt;/p></description></item><item><title>Softwareentwicklung mit UML und Eclipse</title><link>https://big.tuwien.ac.at/master-thesis/archive/softwareentwicklung-mit-uml-und-eclipse/</link><pubDate>Tue, 19 May 2020 12:37:56 +0000</pubDate><guid>https://big.tuwien.ac.at/master-thesis/archive/softwareentwicklung-mit-uml-und-eclipse/</guid><description>&lt;p>This work has been finished in October 2008.&lt;/p>
&lt;p>In der heutigen Zeit ändern sich Anforderungen an Anwendungen laufend. Neben den Anforderungen haben sich natürlich auch die Hilfsmitteln und Technologien weiterentwickelt. Moderne objektorientierte Sprachen, wie z.B. UML und Java, werden den heutigen Ansprüchen gerecht.&lt;/p>
&lt;p>Zu einem großen Teilgebiet der Softwareentwicklung zählen verteilte Systeme bzw. Web-Anwendungen. Die objektorientierte Programmiersprache Java, oder besser gesagt die Java Enterprise Edition, in Zusammenhang mit UML eignet sich hervorragend solche Systeme zu entwickeln. Dieses Thema wurde ausführlich in [Soko07] behandelt.&lt;/p>
&lt;p>Als weiteres Hilfsmittel wird heutzutage in jedem Projekt eine Entwicklungsumgebung verwendet. Eine sehr verbreitete und frei zugängliche Entwicklungsumgebung im Bereich der Java Softwareentwicklung ist das Projekt „eclipse“ [Ecli08]. Der Vorteil dieser Entwicklungsumgebung ist, dass sie durch ein ausgeprägtes Pluginmanagement leicht erweiterbar ist.&lt;/p>
&lt;p>Diese Arbeit evaluiert Projekte bzw. Plugins für die Entwicklungsumgebung „eclipse“, die UML 2.0 unterstützen und dadurch bei der Entwicklung behilflich sind. Weiters soll diese Arbeit evaluieren, inwieweit die getesteten Plugins eine automatisierte Codegenerierung erlauben. Dies soll anhand einer kleinen Beispielanwendung demonstriert werden.&lt;/p>
&lt;p>Ein weiteres Ziel dieser Arbeit ist es kostengünstige Alternativen zu den Entwicklungsumgebungen von IBM (IBM Rational Application Developer [IBM08]) und Omondo (Eclipse Uml [Omon08]) zu finden.&lt;/p>
&lt;p> &lt;/p>
&lt;p>Download the
&lt;a href="https://www.big.tuwien.ac.at/app/uploads/2016/10/Sokop_paper1.pdf" target="_blank" rel="noopener">paper&lt;/a> and
&lt;a href="https://www.big.tuwien.ac.at/app/uploads/2016/10/Sokop_poster_1.pdf" target="_blank" rel="noopener">poster&lt;/a>&lt;/p></description></item><item><title>Ein Vergleich zwischen Visual Studio 2005 und Eclipse Graphical Modeling Framework zur Unterstützung von MDSD</title><link>https://big.tuwien.ac.at/master-thesis/archive/ein-vergleich-zwischen-visual-studio-2005-und-eclipse-graphical-modeling-framework-zur-untersttzung-von-mdsd/</link><pubDate>Tue, 19 May 2020 12:37:55 +0000</pubDate><guid>https://big.tuwien.ac.at/master-thesis/archive/ein-vergleich-zwischen-visual-studio-2005-und-eclipse-graphical-modeling-framework-zur-untersttzung-von-mdsd/</guid><description>&lt;p>This work has been finished in March 2006.&lt;/p>
&lt;p>Die Veränderungen in der Softwareentwicklung verlangen nach höherer Produktivität in der Erstellung der Software auf höherem Qualitätsniveau sowie nach neuen Ansätzen, um diesen Herausforderungen zu begegnen. Ein viel versprechender Ansatz, der in diese Richtung geht, ist modellgetriebene Softwareentwicklung, bei der Modellierung die zentrale Tätigkeit im Entwicklungsprozess einnimmt.&lt;/p>
&lt;p>Ein wichtiger Aspekt dieses neuen Paradigmas ist die Erstellung von domänenspezifi- schen Modellierungswerkzeugen. Zurzeit befinden sich zwei große Projekte in Durchführung, die sich diesem Thema widmen: das Eclipse Graphical Modeling Framework sowie die Microsoft DSL-Tools für Visual Studio 2005.&lt;/p>
&lt;p>Diese Arbeit möchte zuerst einen umfassenden Einblick in die Thematik der modellgetriebenen Softwareentwicklung geben. Danach soll in einer Evaluierung der beiden zuvor erwähnten Technologien erörtert werden, inwieweit diese die definierten Anforderungen erfüllen. Abschließend werden die Ansätze anhand der gewonnenen Erkenntnisse gegenübergestellt.&lt;/p>
&lt;p> &lt;/p>
&lt;p>Download the
&lt;a href="https://www.big.tuwien.ac.at/app/uploads/2016/10/Slapeta_paper.pdf" target="_blank" rel="noopener">paper&lt;/a>&lt;/p></description></item><item><title>Java Enterprise Anwendungen und UML 2.0 - ein starkes Team?</title><link>https://big.tuwien.ac.at/master-thesis/archive/java-enterprise-anwendungen-und-uml-2-0-ein-starkes-team/</link><pubDate>Tue, 19 May 2020 12:37:55 +0000</pubDate><guid>https://big.tuwien.ac.at/master-thesis/archive/java-enterprise-anwendungen-und-uml-2-0-ein-starkes-team/</guid><description>&lt;p>This work has been finished in October 2007.&lt;/p>
&lt;p>In der heutigen Zeit ändern sich Anforderungen an Anwendungen laufend. Neben den Anforderungen haben sich natürlich auch die Hilfsmitteln und Technologien weiterentwickelt. Moderne objektorientierte Sprachen wie z.B. UML und Java werden den heutigen Ansprüchen gerecht.&lt;/p>
&lt;p>Die objektorientierte Programmiersprache Java, oder besser gesagt die Java Enterprise Edition, eignet sich hervorragend um verteilte Systeme, zu denen auch Webanwendungen zählen, zu entwickeln. UML 2.0 ist mit ihren aktuellen Diagrammarten ebenfalls sehr gut für die Modellierung von verteilten Anwendungen geeignet. Diese Arbeit evaluiert das Zusammenspiel zwischen UML 2.0 und Java Enterprise Anwendungen.&lt;/p>
&lt;p>In UML 2.0 gibt es insgesamt 13 verschiedene Diagrammarten. Jedes einzelne Diagramm hat Stärken und Schwächen in Bezug auf Enterprise Anwendungen. Diese Arbeit zeigt, welche Teile einer Enterprise Anwendung sich mit welchem Diagramm in UML 2.0 modellieren lassen bzw. welche nicht.&lt;/p>
&lt;p>Zusätzlich geht diese Arbeit auch auf die Möglichkeiten ein, allgemeine Aspekte einer Enterprise Anwendung zu modellieren, wie z.B. Design Patterns und Systemarchitekturen. Dabei werden für ein bestehendes Beispiel die einzelnen Diagramme, die UML 2.0 zur Verfügung stellt, modelliert.&lt;/p>
&lt;p>Ein weiteres Ziel der Arbeit ist, einen generellen Überblick von UML 2.0 Diagrammarten im Rational Unified Process zu geben. Dabei wird evaluiert, welches Diagramm in welcher Phase des Unified Process in Bezug auf Enterprise Anwendungen hilfreich sein kann.&lt;/p>
&lt;p> &lt;/p>
&lt;p>Download the
&lt;a href="https://www.big.tuwien.ac.at/app/uploads/2016/10/Sokop_paper2.pdf" target="_blank" rel="noopener">paper&lt;/a> and
&lt;a href="https://www.big.tuwien.ac.at/app/uploads/2016/10/Sokop_poster2.pdf" target="_blank" rel="noopener">poster&lt;/a>&lt;/p></description></item><item><title>Moderne Softwareentwicklungsumgebungen – Evaluierung C++/C#-basierter Ansätze</title><link>https://big.tuwien.ac.at/master-thesis/archive/moderne-softwareentwicklungsumgebungen-evaluierung-c-c-basierter-anstze/</link><pubDate>Tue, 19 May 2020 12:37:54 +0000</pubDate><guid>https://big.tuwien.ac.at/master-thesis/archive/moderne-softwareentwicklungsumgebungen-evaluierung-c-c-basierter-anstze/</guid><description>&lt;p>This work has been finished in March 2007.&lt;/p>
&lt;p>Die kurze Geschichte der Softwareentwicklung ist geprägt von Innovationen. Als relativ junge Ingenieursdisziplin, verglichen mit Maschinenbau, Elektrontechnik oder dem Bauingenieurswesen, spielt sie erst seit einigen Jahrzehnten eine tragende Rolle in der technischen Entwicklung. Ihre Bedeutung nimmt seither jedoch kontinuierlich zu. Angefangen, in den 1960ern mit Assemblerprogrammierung, etablierten sich in den 70ern die ersten Hochsprachen am Markt, gefolgt von objektorientierter Programmierung in den 90er-Jahren. Heute steht die nächste Revolution bevor, die Einführung der modellgetriebenen Softwareentwicklung, welche durch ihre noch größere Abstrahierung eine effizientere Arbeitsweise und eine schnellere Projektumsetzung, als mit bisher üblichen Mitteln, erlauben soll. Die Arbeitsschritte, die dabei von einer Entwicklungsumgebung unterstützt werden sollen, werden daher immer komplexer. Schon längst reicht ein einfacher Texteditor mit einem Kommandozeilencompiler nicht mehr aus. Für professionelle Entwicklung wird auch eine professionelle Herangehensweise erforderlich, welche erst durch ausgereifte Werkzeuge ermöglicht wird.&lt;/p>
&lt;p>Die vorliegende Arbeit untersucht, welche Softwareentwicklungsmethoden sich als Standards am Markt etabliert haben und welche Rolle der vielerorts propagierte modellgetriebene Ansatz dabei spielt. Weiters werden die heute größten und bekanntesten integrierten Entwicklungsumgebungen (IDEs) für die Hochsprachen C++ und C# auf deren Fähigkeiten in den Bereichen Modellierung, Programmierung, Softwarequalitätssicherung, Bedienbarkeit, Erweiterbarkeit und Support untersucht. Zu diesem Zweck wird ein Kriterienkatalog vorgestellt, welcher die üblichen Features einer IDE aufzählt und als Bewertungsgrundlage dient.&lt;/p>
&lt;p>Die beiden größten kommerziellen Anbieter für Softwareentwicklungswerkzeuge am PC für die genannten Sprachen sind Borland und Microsoft, daher wird sowohl das derzeit aktuelle Borland Developer Studio (2006), als auch das neueste Microsoft Visual Studio (2005) einer Evaluierung unterzogen. Darüber hinaus wurden zwei Vertreter der Open Source Software ausgewählt. Es sind dies das aus dem Java-Umfeld bekannte Eclipse mit einem C++-Plugin und Sharp Develop für C#. Aufgrund der gewählten IDEs können die beiden größten kommerziellen Produkte ebenso miteinander verglichen, wie auch die Fragestellung behandelt werden, ob Open Source Software in diesem Bereich eine ernstzunehmende Alternative darstellt.&lt;/p>
&lt;p>Eine weitere Arbeit, welche IDEs mit Java-basierten Ansätzen untersucht, wurde ebenfalls zeitgleich an der TU Wien / Business Informatics Group durchgeführt. Da Softwareentwicklungsprozesse und Kriterienkatalog unabhängig von der gewählten Programmiersprache sind, wurden jene Teile der Arbeit, welche diese Themen behandeln, gemeinsam erarbeitet. Die Partnerarbeit wurde von Michael Wihsböck durchgeführt.&lt;/p>
&lt;p> &lt;/p>
&lt;p>Download the
&lt;a href="https://www.big.tuwien.ac.at/app/uploads/2016/10/Skopik_paper.pdf" target="_blank" rel="noopener">paper&lt;/a> and
&lt;a href="https://www.big.tuwien.ac.at/app/uploads/2016/10/Skopik_poster.pdf" target="_blank" rel="noopener">poster&lt;/a>&lt;/p></description></item><item><title>Web-based Business Document Mapping using Smooks</title><link>https://big.tuwien.ac.at/master-thesis/archive/web-based-business-document-mapping-using-smooks/</link><pubDate>Tue, 19 May 2020 12:37:54 +0000</pubDate><guid>https://big.tuwien.ac.at/master-thesis/archive/web-based-business-document-mapping-using-smooks/</guid><description>&lt;p>This work has been finished in September 2013.&lt;/p>
&lt;p>Electronic commerce (e-commerce) and especially business-to-business (B2B) exchange of data, information or documents, continues to grow in recent years. One of the major challenges in e-commerce is how to align different standards that have emerged over those years [1,2]. Enterprises have to invest substantial financial resources to integrate various heterogeneous systems, in order to communicate within organization systems or among trading partners [3,4,5]. Rapid developments in Information and Communication Technologies (ICT) brought new cost-effective opportunities for small and medium-sized enterprises (SMEs) to exchange electronic business documents via the Internet using a wide range of integration tools. The current increasing attention into cloud computing as a way of how to minimize costs and introduce pay-per-use models, proves to be of high relevance for the creation of a cloud-ready tool with future potential [6].&lt;/p>
&lt;p>The objective of this work is to enable SMEs and non-profit organisations to exchange business documents within B2B e-commerce using free of charge, modern information technologies and systems. In order to minimize investments for infrastructure and application licenses, Web-based solutions accessible as cloud services are proposed. This innovative approach opens new possibilities for addressing common issues with mappings and transformations of business documents. Enabling such a solution should motivate SMEs to start using automated B2B electronic communication.&lt;/p>
&lt;p>The SmooKs Data Integration (DI) framework, an engine for processing XML and non XML data, currently does not support direct transformation. Therefore an innovative Web-based visual tool, capable of specifying relationships between two XML documents is designed and implemented. The crucial IT artifact of this work, will be the user interface which enables drag and drop mapping of documents and consecutive transformation using the SmooKs DI framework. Furthermore, the whole solution will be deployed as cloud service using Google App Engine and will be accessible from any standard Web browser. The result of this work is the outline of related work on B2B business document standards, mapping and transformation tools.&lt;/p>
&lt;p>This thesis follows the guidelines of the design science research methodology [7]. The main parts consist of related work relevant to B2B electronic exchange of structured business documents, their mapping and subsequent transformation. When transforming XML documents it is important to understand the model, and schema, as well as query languages [8,9]. Furthermore, an analysis of open source data integration frameworks is conducted, followed by a selection of the SmooKs framework. In order to enable direct transformation using SmooKs for XML and other business document standards, an architectural change of the SmooKs DI framework is proposed.&lt;/p>
&lt;p>In the technical part, a user interface (UI) will be created. This is elaborated from an analysis of existing integration tools. The relationship between XML structure and tree structure are described in more detail in [10]. And is taken into account for the design of a data model used to map source and target document. The design will be tested via direct transformation of the XML to XML using a template engine and SmooKs hosted as a cloud service. An evaluation of the prototype solution will serve as a proof of utility and form an open issue discussion.&lt;/p>
&lt;p>Large enterprises, using customized enterprise resource planning systems (ERP), employ more advanced types of middleware such as enterprise application integration (EAI) or enterprise service bus (ESB) for various types of integration. SMEs, to integrate into B2B, focus on less complicated solutions as data integration (DI) tools or software packages, enabling them to extract, transform and load data (ETL) [11]. The market is dominated by commercial products from Informatica, IBM, Microsoft, Oracle, and Pervasive [12], but there are multiple open source data integration frameworks available (Talend, CoverETL, SmooKs, Pentaho) [13]. Talend is the leader in providing open source data integration frameworks. It uses SmooKs for Electronic Data Interchange (EDI). However, the main difference is the value proposition. SmooKs is a framework for Java programmers, while Talend provides a visual tool for non-programmers.&lt;/p>
&lt;p>Using a visual tool to specify mapping of source and destination is not new, in fact it goes back as far as the first heterogeneous systems [14]. To be more specific, federated database systems (FDBS) managing distributed, autonomous and different databases, laid the cornerstone for a reference architecture of mapping and transformation back in 1980’s [15]. Recent classification as well as analysis of mapping tools for data exchange is highlighting that no tool performs well in all mapping situations [16]. Most of the current market leaders are using integrated development environment (IDE) software applications installed locally on the desktop.&lt;/p>
&lt;p>The implementation of the Web-based editor for mapping models for the data integration framework SmooKs relates to a wide range of technologies. The jQuery framework, a library for JavaScript, is used for the user interface. The transformation works with help of FreeMarker, a template engine, and uses XML related technologies to generate and produce XML, based on a given schema. The entire solution is hosted as a free-of-charge cloud computing service of a Google App engine using Java. In version 1.4 of SmooKs, automatic transformation for UN/EDIFACT was introduced, thus forming solid foundations for support of ANSI X.12, HL7 and other EDI-based data formats. Strong support for various formats (XML, CSV, Fix Width, EDI, Java, JSON, YAML, etc.) and integration with Apache Camel combined with EDI support make SmooKs a strong business document transformation tool used in several other open source products (JBoss ESB, Talend, Mule ESB, WS02).&lt;/p>
&lt;p>A literature survey reveals an increased interest into XML-based architecture in Web services [8,17]. Due to the simplicity of XML compared to SGML (Standard Generalized Markup Language), XML has an important role in the exchange of various kinds of data, in mapping and transformation [8,16,18,19]. Some authors proposed XML to XML transformation using query languages [15,16]. The FreeMarker Template Language (FTL) offers a lightweight alternative to common query languages such as XSLT or XQuery. The SmooKs DI framework in conjunction with FreeMarker can be used to perform XML to XML transformation. Furthermore, SmooKs can extract data from EDI messages or read and write data formats other than XML. Further work is required to explore matching meta-models to automate mapping [20] with help of semantic systems and implement adapters to plug-in other business document standards.&lt;/p>
&lt;p>The master’s programme in Software Engineering &amp;amp; Internet Computing deals with all aspects of distributed heterogeneous software systems, their communication services and standards, and integration into global information networks. This master’s thesis covers areas ranging from Internet technologies, cloud computing or business document standards and their integration into information systems, through innovative design and implementation of the developed prototype. The work outlines relevant technological principles of B2B document mapping and transformation, based on the research and knowledge acquired throughout the study.&lt;/p>
&lt;p>[1] Philipp Liegl, Business Documents for Inter-Organizational Business Processes, PhD thesis, Technische Universität Wien, Fakultät für Informatik, 2009.&lt;/p>
&lt;p>[2] Patrick Ziegler and Klaus R. Dittrich, Three Decades of Data Integration – All Problems Solved?, University of Zurich, Zurich, 2004.&lt;/p>
&lt;p>[3] MulesoftTM, Increasing E-commerce agility. The role of integration in staying ahead of the curve in a changing e-commerce environment, 2010.&lt;/p>
&lt;p>[4] Christoph Koch, Data Integration Against Multiple Evolving Autonomous Schemata, Universität Wien, Institut fuer medizinische Kybernetik and Artificial Intelligence, 2001.&lt;/p>
&lt;p>[5] Christian Zehetmeyer, The Diversity and Penetration of EDI in Austria, An Empirical Analysis, Master thesis, Technische Universität Wien, Fakultät für Informatik, 2011.&lt;/p>
&lt;p>[6] Jeaha Yang, Rangachari Anand, Stacy Hobson, Juhnyoung Lee, Yuan Wang and Jing Min Xu, Data Service Portal for Application Integration in Cloud Computing, IBM TJ Watson Research Center, New York and IBM China Research Laboratory, Beijing, 2011.&lt;/p>
&lt;p>[7] Alan R. Hevner, Salvatore T. March, Jinsoo Park, Sudha Ram, Design Science in Information Systems Research, MIS Quarterly, 2004.&lt;/p>
&lt;p>[8] Daniel Fötsch and Andreas Speck, XTC – The XML Transformation Coordinator for XML Document Transformation Technologies, Friedrich-Schiller-University Jena, 2006.&lt;/p>
&lt;p>[9] Nils Klarlund, Thomas Schwentick and Dan Suciu, XML: Model, Schemas, Types, Logics and Queries, AT&amp;amp;T Labs – Research, USA, University of Marburg, Germany, University of Washington, USA, 2003.&lt;/p>
&lt;p>[10] Akihiko Tozawa, On Binary Tree Logic for XML and Its Satisfiability Test, IBM Research, Tokyo Research Laboratory, 2004.&lt;/p>
&lt;p>[11] Noel Yuhanna, The Forrester WaveTM: Enterprise ETL, Q1 2012, Report, 2012.&lt;/p>
&lt;p>[12] Philip Howard, Comparative costs and uses of Data Integration Platforms, Research and Survey results, 2010.&lt;/p>
&lt;p>[13] Petr Uher, CoverETL vs. Talend, Pentaho, Clover ETL, Whitepaper, 2009.&lt;/p>
&lt;p>[14] SoftwareAG, Process Excellence for Digital Enterprise, Annual Report, 2010.&lt;/p>
&lt;p>[15] Amit P. Sheth, James A. Larson, Federated Database Systems for Managing Distributed, Heterogeneous, and Autonomous Databases, ACM Computing Surveys, 1990.&lt;/p>
&lt;p>[16] Frank Legler, Felix Naumann, A Classification of Schema Mappings and Analysis of Mapping Tools, 12. GI-Fachtagung fuer Datenbanksysteme in Business, Technologie und Web (BTW 2007), 2007.&lt;/p>
&lt;p>[17] Dongwon Lee, Query Relaxation for XML Model, University of California, Los Angeles. 2002.&lt;/p>
&lt;p>[18] Ravi Mani, Joerg Meyer, Pratibha Jamdagneya Sharma, Hovey Raymond Strong, Jr., Tree Construction for XML to XML Transformation, Patent No.: US 7,062,708 B2, 2006.&lt;/p>
&lt;p>[19] Tom Mens and Pieter Van Gorp, Taxonomy of Model Transformation, Electronic Notes in Theoretical Computer Science 152, Elsevier, 2006.&lt;/p>
&lt;p>[20] Gerti Kappel, Hosrt Kargl, Gerhard Kramler, Andrea Schauerhuber, Martina Seidl, Michael Strommer and Manual Wimmer, Matching Metamodels with Semantic Systems – An Experience Report, Vienna University of Technology, Verlag Mainz, 2007.&lt;/p>
&lt;p> &lt;/p></description></item><item><title>A MOOC Prototype on Object-Oriented Modeling: Development, Usage and Evaluation</title><link>https://big.tuwien.ac.at/master-thesis/archive/a-mooc-prototype-on-object-oriented-modeling-development-usage-and-evaluation/</link><pubDate>Tue, 19 May 2020 12:37:53 +0000</pubDate><guid>https://big.tuwien.ac.at/master-thesis/archive/a-mooc-prototype-on-object-oriented-modeling-development-usage-and-evaluation/</guid><description>&lt;p>Learning methods have changed over the years mainly due to technological innovations. Massive Open Online Courses (MOOCs) are a new way of learning. A course is often taken by several hundreds to several thousands of persons. Compared to other learning models, MOOCs are completely open and everybody can take courses via the world wide web. The aim of this Master Thesis is to develop, use and evaluate a MOOC prototype in the area of Object-Oriented Modeling (OOM).&lt;/p>
&lt;p>Abstract and paper may be found in our
&lt;a href="https://publik.tuwien.ac.at/showentry.php?ID=258048&amp;amp;amp;lang=1&amp;amp;amp;head=%3Clink&amp;#43;rel%3D%22stylesheet%22&amp;#43;type%3D%22text%2Fcss%22&amp;#43;href%3D%22https%3A%2F%2Fpublik.tuwien.ac.at%2Fpubdat.css%22%3E%3C%2Fhead%3E%3Cbody%3E" target="_blank" rel="noopener">publication database&lt;/a>.&lt;/p>
&lt;p> &lt;/p></description></item><item><title>Applying SAFE to RFT - Intelligent Feature Extraction for Matching Requirement Documents and Solution Documents</title><link>https://big.tuwien.ac.at/master-thesis/archive/applying-safe-to-rft-intelligent-feature-extraction-for-matching-requirement-documents-and-solution-documents/</link><pubDate>Tue, 19 May 2020 12:37:53 +0000</pubDate><guid>https://big.tuwien.ac.at/master-thesis/archive/applying-safe-to-rft-intelligent-feature-extraction-for-matching-requirement-documents-and-solution-documents/</guid><description/></item><item><title>UML 2.0 in der Praxis</title><link>https://big.tuwien.ac.at/master-thesis/archive/uml-2-0-in-der-praxis/</link><pubDate>Tue, 19 May 2020 12:37:53 +0000</pubDate><guid>https://big.tuwien.ac.at/master-thesis/archive/uml-2-0-in-der-praxis/</guid><description>&lt;p>This work has been finished in January 2009.&lt;/p>
&lt;p>2005 hat die Object Management Group (OMG) mit einer 18 monatigen Verspätung die UML 2.0 verabschiedet. Eine Version der Unified Modeling Language, die kompakter, verständlicher und in sich schlüssiger sein soll. Die bedeutendste Kritik an der UML 1.x ist der Vorwurf, zu groß und komplex zu sein, um sie schnell erlernen und angemessen benutzen zu können.1 Die vorliegende Diplomarbeit beschäftigt sich mit der Frage, ob die UML 2.0 wirklich effektiver und effizienter geworden ist. Diese Frage soll durch die Erstellung eines SW-Projektes beantwortet werden, in dem alle Diagrammtypen zum Einsatz kommen.&lt;/p>
&lt;p>Der theoretische Teil enthält neben der Entstehungsgeschichte der UML auch eine Beschreibung der Diagrammarten. Ziel ist dabei, mit wenig Leseaufwand die Diagramme und deren Einsatz verstehen zu können. Weiters wird die Beispielproblemstellung vorgestellt, die im praktischen Teil mit der UML 2.0 umgesetzt wird. Hierbei geht es um die Vereinigung mehrerer einzelner Software Systeme zu einem bestehenden System für ein Unternehmen. Das Ziel des Unternehmens ist das Arbeiten auf einem System und nicht wie bis jetzt auf mehreren. Zusätzlich wurde im praktischen Teil ein Kriterienkatalog vorgestellt, anhand dessen die Diagramme kritisch hinterfragt werden.&lt;/p>
&lt;p> &lt;/p>
&lt;p>Download the
&lt;a href="https://www.big.tuwien.ac.at/app/uploads/2016/10/Schwaiger_paper.pdf" target="_blank" rel="noopener">paper&lt;/a> and
&lt;a href="https://www.big.tuwien.ac.at/app/uploads/2016/10/Schwaiger_poster.pdf" target="_blank" rel="noopener">poster&lt;/a>&lt;/p></description></item><item><title>Language-Specific Model Versioning for SysML</title><link>https://big.tuwien.ac.at/master-thesis/archive/language-specific-model-versioning-for-sysml/</link><pubDate>Tue, 19 May 2020 12:37:52 +0000</pubDate><guid>https://big.tuwien.ac.at/master-thesis/archive/language-specific-model-versioning-for-sysml/</guid><description/></item><item><title>Web-Transaktionen in der Praxis</title><link>https://big.tuwien.ac.at/master-thesis/archive/web-transaktionen-in-der-praxis/</link><pubDate>Tue, 19 May 2020 12:37:52 +0000</pubDate><guid>https://big.tuwien.ac.at/master-thesis/archive/web-transaktionen-in-der-praxis/</guid><description>&lt;p>This work has been finished in September 2005.&lt;/p>
&lt;p>Die Entwicklung des Internet in den letzten Jahren und Jahrzehnten hat dazu geführt, dass die Anforderungen an angebotene Dienste und deren zugrunde liegende Applikationen ständig gestiegen sind und steigen. Um den Anforderungen gerecht werden zu können, ist oftmals eine Kooperation von mehreren, unabhängigen und heterogenen Systemen zur Bündelung mehrerer Dienste notwendig.&lt;/p>
&lt;p>Da die Art und Weise der Ausführungen von Diensten von dem zu realisierenden, oftmals komplexen Geschäftsprozess abhängt, ist es sehr wichtig, die einzelnen Aktivitäten eines solchen Prozesses zu koordinieren, um ein gemeinsames Ergebnisunter den teilnehmenden Diensten zu erreichen. Weil die Abarbeitung eines Geschäftsprozesses oft länger dauern kann, ist es außerdem ganz wichtig, Nebenläufigkeit und damit verbesserte Performanz zu gewährleisten, um auch große Benutzerzahlen handhaben zu können. Diese Anforderungen werden im Rahmen von Transaktionsmodellen behandelt.&lt;/p>
&lt;p>In dieser Diplomarbeit wird deshalb ein Überblick über relevante Teile der Transaktionstheorie gegeben. Das Augenmerk liegt dabei auf offenen geschachtelten Transaktionen, mittels deren Einsatz sehr komplexen Sachverhalten Rechnung getragenwerden kann. Basierend auf der existierenden Transaktionstheorie ist die Untersuchung von drei Transaktionsprotokollen für Web Services zentraler Punkt dieser Arbeit. Alle drei ermöglichen es, mehrere Web Services untereinander zu koordinieren und ein gemeinsames Ergebnis herbeizuführen. Neben einer detaillierten Erklärung der einzelnen Protokolle werden diese hinsichtlich ihrer Eignung für die Abbildung langer Geschäftsprozesse kritisch betrachtet und gegenübergestellt.&lt;/p>
&lt;p>Um den praktischen Einsatz von Transaktionsprotokollen für Web Services zu demonstrieren, wird neben der Vorstellung einiger aktueller Projekte und Produkte der durchgeführte Test einer Demo-Applikation und die dabei gewonnen Eindrücke, die durchaus sehr positiv waren, geschildert. Auch die in der Praxis sehr wichtigen Frameworks J2EE und .NET werden hinsichtlich ihrer Transaktionsmöglichkeiten untersucht und kritisch betrachtet.&lt;/p>
&lt;p> &lt;/p>
&lt;p>Download the
&lt;a href="https://www.big.tuwien.ac.at/app/uploads/2016/10/Schlosser_paper.pdf" target="_blank" rel="noopener">paper&lt;/a>&lt;/p></description></item><item><title>Entwicklung eines webbasierten Institutsinformationssystems - Separation of Concerns und seine Umsetzung in LAMP</title><link>https://big.tuwien.ac.at/master-thesis/archive/entwicklung-eines-webbasierten-institutsinformationssystems-separation-of-concerns-und-seine-umsetzung-in-lamp/</link><pubDate>Tue, 19 May 2020 12:37:51 +0000</pubDate><guid>https://big.tuwien.ac.at/master-thesis/archive/entwicklung-eines-webbasierten-institutsinformationssystems-separation-of-concerns-und-seine-umsetzung-in-lamp/</guid><description>&lt;p>This work has been finished in October 2004.&lt;/p>
&lt;p>Im Rahmen einer Kooperation dreier laufender Diplomarbeiten (Alexander Heumayer, Nenad Jovanovic, Andrea Schauerhuber) wurde mit Hilfe der Open-Source Web- Development-Plattform LAMP (der Kombination aus dem Betriebssystem Linux, dem Webserver Apache, dem Datenbank-Managementsystem MySQL und der Programmiersprache PHP) ein für die Business Informatics Group (Institut für Softwaretechnik und Interaktive Systeme, Technische Universität Wien) maßgeschneidertes Web-Informationssystem entwickelt. Die Web-Anwendung bietet unterschiedlichen Benutzergruppen, darunter Studierenden und Mitarbeitern des Instituts, verschiedenste Dienste an.&lt;/p>
&lt;p>Der Schwerpunkt der vorliegenden Diplomarbeit ist die Entwicklung eines Architektur- Frameworks für LAMP, das den Anforderungen des Separation of Concerns von Web-Informationssystemen gerecht wird. Die Schwäche der traditionellen Entwicklung unter LAMP liegt in der Vermischung von Inhalten, Anwendungslogik und Präsentation. Zum einen erlaubt HTML keinen Rückschluss auf die Semantik der Inhalte von HTML-Tags, wodurch Inhalte und Präsentation nicht voneinander getrennt werden können. Zum anderen sorgt hinzugefügter PHP-Code, der die Anwendungslogik einbringen soll, für zusätzliche Komplexität. Die Hauptanforderung an die zu entwickelnde Architektur war es daher, diese Schwächen zu beseitigen und im Sinne des Diplomarbeitstitels dem Separation of Concerns-Paradigma zu folgen. Die in der Diplomarbeit entwickelte Architektur basiert auf dem XAO Framework (&lt;a href="http://xaophp.sourceforge.net">http://xaophp.sourceforge.net&lt;/a>), erweitert um die Realisierung des Model View Controller Patterns. Diese Architektur stellt auch die Grundlage für das im praktischen Teil entwickelte Institutsinformationssystem dar.&lt;/p>
&lt;p> &lt;/p>
&lt;p>Download the
&lt;a href="https://www.big.tuwien.ac.at/app/uploads/2016/10/Schauerhuber_paper.pdf" target="_blank" rel="noopener">paper&lt;/a>&lt;/p></description></item><item><title>FROM LEGACY WEB APPLICATIONS TO WEBML MODELS</title><link>https://big.tuwien.ac.at/master-thesis/archive/from-legacy-web-applications-to-webml-models/</link><pubDate>Tue, 19 May 2020 12:37:51 +0000</pubDate><guid>https://big.tuwien.ac.at/master-thesis/archive/from-legacy-web-applications-to-webml-models/</guid><description>&lt;p>This work has been finished in December 2009.&lt;/p>
&lt;p>In the last decade the adoption of web applications instead of desktop applications has grown rapidly. Also the patterns and technologies for developing and running web applications have changed a lot over time. The World Wide Web has evolved from a collection of linked static documents to a space of countless dynamic, data centric applications. One of the oldest and most popular languages for developing dynamic web applications is PHP. Although nowadays there are proved techniques for developing web applications in PHP, many older PHP web applications are written without the notion of applying well-defined design patterns. Those web applications are hard to understand, maintain, extend as well as hard to migrate to new web platforms. Nowadays many web applications are developed using Model Driven Engineering (MDE) techniques where software systems are described as models and code artifacts are generated out of these models. But often the requirement is not to develop a completely new web application but to capture the functionality of an existing legacy application. As it usually takes a lot of time for humans to understand the source code, it can be helpful to have a tool that analyzes the source artifacts and transforms them into a model on a higher level of abstraction. This process is called reverse engineering. The requirements for such a tool to work is the existence of well-known patterns in the source code, which is typically found in Model-View-Controller (MVC) web applications. In this thesis a reverse engineering process from a legacy PHP web shop application into a model of the Web Modeling Language (WebML), based on static code analysis, is presented. First of all the requirements for the source code are analyzed in order to apply an automatic reverse engineering process on it. The source application is refactored to fulfill these requirements, which leads to a MVC version of the example application. The refactored application is the source for the next step, a code to model transformation into an intermediate model of the MVC web application. The last step is a model to model transformation from the the MVC model into a WebML model. The result is aWebML model that shows the most important structural and behavioral aspects of the example application. The benefit of such a model is that that it provides a realistic documentation of the current state of the application. Whenever the application changes, the process can be repeated so the documentation never gets outdated. It helps humans to understand the connections between different parts of the application and can be used to support refactoring activities or the migration to another platform.&lt;/p>
&lt;p> &lt;/p>
&lt;p>Download the
&lt;a href="https://www.big.tuwien.ac.at/app/uploads/2016/10/Rieder_paper.pdf" target="_blank" rel="noopener">paper&lt;/a> and
&lt;a href="https://www.big.tuwien.ac.at/app/uploads/2016/10/Rieder_poster.pdf" target="_blank" rel="noopener">poster&lt;/a>&lt;/p></description></item><item><title>ATL4pros: Introducing Native UML Profile Support into the ATLAS Transformation Language</title><link>https://big.tuwien.ac.at/master-thesis/archive/atl4pros-introducing-native-uml-profile-support-into-the-atlas-transformation-language/</link><pubDate>Tue, 19 May 2020 12:37:50 +0000</pubDate><guid>https://big.tuwien.ac.at/master-thesis/archive/atl4pros-introducing-native-uml-profile-support-into-the-atlas-transformation-language/</guid><description>&lt;p>This work has been finished in October 2011.&lt;/p>
&lt;p>Abstract and paper may be found in our &lt;a class="external" href="http://publik.tuwien.ac.at/showentry.php?ID=199788&amp;amp;lang=2">publication database&lt;/a>.&lt;/p>
&lt;p>Download the
&lt;a href="https://www.big.tuwien.ac.at/app/uploads/2016/10/Randak_poster.pdf" target="_blank" rel="noopener">poster&lt;/a>&lt;/p></description></item><item><title>Evaluierung von UML2-Modellierungswerkzeugen</title><link>https://big.tuwien.ac.at/master-thesis/archive/evaluierung-von-uml2-modellierungswerkzeugen/</link><pubDate>Tue, 19 May 2020 12:37:50 +0000</pubDate><guid>https://big.tuwien.ac.at/master-thesis/archive/evaluierung-von-uml2-modellierungswerkzeugen/</guid><description>&lt;p>This work has been finished in October 2006.&lt;/p>
&lt;p>Ziel dieser Magisterarbeit ist das Überprüfen der Benutzbarkeit von verschiedenen UML2-Modellierugswerkzeugen anhand der Fallstudie „Onlinebuchhandlung“. Als Ergebnis soll für jedes untersuchte Modellierungs-Tool ein detaillierter Bericht entstehen, der folgende Kernpunkte beinhaltet:&lt;/p>
&lt;p>Darüber hinaus soll eine aussagekräftige Zusammenfassung die besonderen Stärken und Schwächen der einzelnen Modellierungs-Tools nochmals hervorheben.&lt;/p>
&lt;p>Grundlage der Untersuchungen ist eine Fallstudie in Form eines durchgängigen Beispiels, in dem für eine bestehende Buchhandlung ein Software-System zum Online-Kauf von Büchern („Onlinebuchhandlung“) erstellt wird.&lt;/p>
&lt;p>Als erstes werden die relevanten Geschäftsprozesse der Buchhandlung mit UML modelliert und daraus die Anforderungen für das Online-System abgeleitet. Um nicht nur die Tool-Unterstützung für die UML-Notation alleine evaluieren zu können, wird den Diagrammen ein (auf dem Unified Process basierender) Software-Entwicklungsprozess zu Grunde gelegt. Durch das damit verbundene inkrementelle und iterative Vorgehen soll untersucht werden, ob das jeweilige Tool Zusammenhänge zwischen Modellen erkennt bzw. es erlaubt, solche Zusammenhänge zu definieren und ggf. Änderungen an solch zusammenhängenden Modellen (automatisch) abzugleichen.&lt;/p>
&lt;p> &lt;/p>
&lt;p>Download the
&lt;a href="https://www.big.tuwien.ac.at/app/uploads/2016/10/Reichhold_paper.pdf" target="_blank" rel="noopener">paper&lt;/a> and
&lt;a href="https://www.big.tuwien.ac.at/app/uploads/2016/10/Reichhold_poster.pdf" target="_blank" rel="noopener">poster&lt;/a>&lt;/p></description></item><item><title>Transfer Monitoring from University to Industry</title><link>https://big.tuwien.ac.at/master-thesis/archive/transfer-monitoring-from-university-to-industry/</link><pubDate>Tue, 19 May 2020 12:37:50 +0000</pubDate><guid>https://big.tuwien.ac.at/master-thesis/archive/transfer-monitoring-from-university-to-industry/</guid><description>&lt;p>The measurement of the knowledge change of employees as well as the subsequent transfer within their companies is discussed in this thesis. Although these two terms are often used synonymously, there is a clear difference between them. Learning is adapting to a situation whereas transfer is applying this knowledge to similar situations. There are various approaches to measuring learning success or transfer, most of which originate in educational science. In this thesis we consider the special case of innovation courses, where there are various additional requirements that must be met for the measurement. Unfortunately, the existing frameworks are not designed for these requirements and are therefore not sufficient. An innovation course is a long-term course in which employees of various companies are taught and trained in a certain topic. Such an innovation course consists of several modules for which both the measurement of learning success and knowledge transfer for the individual participants must take place in the various modules. To achieve this and to make the measurements repeatable and objective, we have developed a framework for transfer monitoring from university to industry. We use the Design Science Approach to develop the framework. However, the goal is not to create a static artefact that can only be applied to the course of our case study, but to design a framework that is also easily adaptable and applicable in other innovation courses or in a similar environment. To test and improve this framework, we use it in four modules of the DigiTrans 4.0 innovation course. For three of the four modules of our case study, the difference between the knowledge before the module and at the end is statistically signiﬁcant. We also create linear models to explain or predict the transfer. The necessary variables for linear regressions are derived from literature research. The models are created both with and without heteroscedasticity adjustment. The results of the models are slightly different, but show a common trend, which originates from the same background formula. Since these characteristics are known in the literature of knowledge transfer, the framework created is well suited for measuring the transfer.&lt;/p></description></item><item><title>Modellgetriebene Entwicklung ubiquitärer Web Anwendungen - Evaluierung aktueller Ansätze und Werkzeuge</title><link>https://big.tuwien.ac.at/master-thesis/archive/modellgetriebene-entwicklung-ubiquitrer-web-anwendungen-evaluierung-aktueller-anstze-und-werkzeuge/</link><pubDate>Tue, 19 May 2020 12:37:49 +0000</pubDate><guid>https://big.tuwien.ac.at/master-thesis/archive/modellgetriebene-entwicklung-ubiquitrer-web-anwendungen-evaluierung-aktueller-anstze-und-werkzeuge/</guid><description>&lt;p>This work has been finished in April 2006.&lt;/p>
&lt;p>Einhergehend mit der zunehmenden Verbreitung und Komplexität von Web-Anwendungen und der daraus resultierenden Wandlung des World Wide Web von einem statischen Informationsmedium zu einem dynamischen Anwendungsmedium, entwickelte sich eine Reihe von Modellierungsansätzen für Web-Anwendungen. Die Bandbreite reicht dabei von sehr spezifischen Modellierungsansätzen, die nur auf Teilaspekte von Web-Anwendungen fokussieren, bis zu solchen, die den gesamten Entwicklungsprozess umfassen. Neue Herausforderungen an diese Ansätze ergeben sich einerseits aus dem zunehmenden Bedürfnis nach Adaptierbarkeit von Web-Anwendungen und andererseits aus dem aufkommenden Trend der modellgetriebenen SoftwareEntwicklung.&lt;/p>
&lt;p>Ziel dieser Arbeit ist es, einen Überblick über aktuelle Modellierungsansätze und deren Werkzeugunterstützung zu geben und diese einer Evaluierung anhand eines Kriterienkataloges zu unterziehen, der die bereits erwähnten Anforderungen berücksichtigt. Um praktische Erfahrung im Umgang mit den untersuchten Werkzeugen zu sammeln sollen die Ansätze auch anhand eines Beispiels verglichen werden.&lt;/p>
&lt;p>Die Evaluierung soll aufzeigen, ob eine modellgetriebene Entwicklung mit aktuellen Modellierungsansätzen bereits möglich ist und in wie weit auf die speziellen Erfordernisse von ubiquitären Web-Anwendungen eingegangen wird.&lt;/p>
&lt;p> &lt;/p>
&lt;p>Download the
&lt;a href="https://www.big.tuwien.ac.at/app/uploads/2016/10/Prinz_poster.pdf" target="_blank" rel="noopener">poster&lt;/a>&lt;/p></description></item><item><title>Towards Model-driven Web Application Development with AspectWebML - An Integrated Graphical Development Environment</title><link>https://big.tuwien.ac.at/master-thesis/archive/towards-model-driven-web-application-development-with-aspectwebml-an-integrated-graphical-development-environment/</link><pubDate>Tue, 19 May 2020 12:37:49 +0000</pubDate><guid>https://big.tuwien.ac.at/master-thesis/archive/towards-model-driven-web-application-development-with-aspectwebml-an-integrated-graphical-development-environment/</guid><description>&lt;p>This work has been finished in December 2007.&lt;/p>
&lt;p>Model Driven Engineering (MDE) and Aspect Oriented Software Development (AOSD) are among what is to be said ’the next big thing’. Despite their youth, both approaches already show their value to the software engineering community manifold and gain more and more attention as well in other domains. For example, in web engineering, some web modeling methodologies have already started to profit from the ideas of MDE and ASOD. Still, the common drawback of most emerging technologies is the inescapable lack of tool support, being especially true for aspect-oriented modeling languages and web modeling languages.&lt;/p>
&lt;p>Recently, the web modeling language WebML, an academic method that is supported by the commercial tool WebRatio, has been extended with concepts from the aspect-orientation paradigm. The resulting aspectWebML modeling language, allows for separately modeling crosscutting concerns such as customization for context-aware web applications, from the rest of the applications functionality. Currently aspectWebML is supported by a simple tree-based modeling editor built upon the Eclipse Modeling Framework (EMF), only. While such EMF editors have been around for some time and proved their usefulness, their clumsy handling certainly does not address the modelers‘ needs.&lt;/p>
&lt;p>The primary objective of this work is to propose an Graphical Integrated Develoment Environment (IDE) for allowing to develop web applications with aspectWebML in the sense of MDE. In this respect, a major focus is placed on integrating views that support the user in modeling and quickly absorbing aspect-orientation-related interconnections between elements, being at the very core of the aspectWebML language. The concepts of Model-driven Development will be extensivley used throughout all phases of this thesis, starting with the IDE’s major graphical editors parts being created with Eclipses Graphical Modeling Framework (GMF) that allows to quickly craft powerful graphical editors on any EMF-based metamodel. Furthermore, some technologies that build the foundation for GMFs success, i.e. EMF and the code generation framework openArchitectureWare (OAW), are to be used in the next step to construct basic model transformation and code generation facilites for aspectWebML that can be easily plugged into the IDE. The ultimate goal is to show how building an integrated toolset for custom metamodels can be done efficiently with current (open source) technologies.&lt;/p>
&lt;p> &lt;/p>
&lt;p>Download the
&lt;a href="https://www.big.tuwien.ac.at/app/uploads/2016/10/Preisinger_paper.pdf" target="_blank" rel="noopener">paper&lt;/a> and
&lt;a href="https://www.big.tuwien.ac.at/app/uploads/2016/10/Preisinger_poster.pdf" target="_blank" rel="noopener">poster&lt;/a>&lt;/p></description></item><item><title>Comparing Frameworks for Distributed Big Data Processing in the Domain of Predictive Maintenance</title><link>https://big.tuwien.ac.at/master-thesis/archive/comparing-frameworks-for-distributed-big-data-processing-in-the-domain-of-predictive-maintenance/</link><pubDate>Tue, 19 May 2020 12:37:48 +0000</pubDate><guid>https://big.tuwien.ac.at/master-thesis/archive/comparing-frameworks-for-distributed-big-data-processing-in-the-domain-of-predictive-maintenance/</guid><description>&lt;p>Big Data Analysis is a core component of many modern companies across industries. Due to their high requirements, many Big Data applications run on distributed computing environments. Depending on the use case these applications can get very complex, comprising of multiple frameworks that need to work together. One prominent and high potential use case is predictive maintenance where machine learning algorithms are used to predict machine failures. The goal is to minimize downtime and maintenance costs. In this thesis, a predictive maintenance use case is implemented to serve as a benchmark for testing various Big Data frameworks. Popular frameworks like Apache Hadoop and Apache Spark are tested on their performance in different combinations. Additionally, a qualitative comparison of the analyzed frameworks is made.&lt;br>
At first this work gives an overview of the landscape of current Big Data frameworks and determines the most popular ones. Secondly the predictive maintenance use case is described. Thirdly the use case is implemented on the various framework combinations and tested on performance. At last the results are compared and conclusions are drawn.&lt;/p></description></item><item><title>Lernstilbasierte Adaptivität von E-Learning Kursen</title><link>https://big.tuwien.ac.at/master-thesis/archive/lernstilbasierte-adaptivitt-von-e-learning-kursen/</link><pubDate>Tue, 19 May 2020 12:37:48 +0000</pubDate><guid>https://big.tuwien.ac.at/master-thesis/archive/lernstilbasierte-adaptivitt-von-e-learning-kursen/</guid><description>&lt;p>This work has been finished in March 2007.&lt;/p>
&lt;p>Der Einsatz von E-Learning Kursen hat sich in der Arbeits- und Ausbildungswelt in den letzten Jahren etabliert. In den Schulen werden immer mehr Computer in den Unterricht eingebunden und in der Arbeitswelt werden diese als Weiterbildungsmittel eingesetzt. Jeder Lernende hat in Bezug auf seine Lernstile verschiedene Präferenzen und lernt erfolgreicher, wenn der Unterricht an diese angepasst ist. In der traditionellen Lehre ist diese Anpassung nur schwer möglich, im E-Learning hingegen durch Adaptivität machbar. Dabei wird versucht, jedem Lernenden einen an seine Lernpräferenzen angepassten Kurs anzubieten, um bestmögliche Lernbedingungen zu erreichen. Im Zuge dieser Diplomarbeit werden einige Lernstile vorgestellt. Ziel der Arbeit ist es, anhand der Lernstiltheorie von Felder und Silverman geeignete Möglichkeiten zu finden, um einen E-Learning Kurs automationsunterstützt an die Lernstile der Lernenden anzupassen. Die Evaluierung des implementierten adaptiven E-Learning-Systems erfolgte anhand des Web Engineering Kurses des Instituts für Softwaretechnik und Interaktive Systeme der Technischen Universität Wien.&lt;/p>
&lt;p> &lt;/p>
&lt;p>Download the
&lt;a href="https://www.big.tuwien.ac.at/app/uploads/2016/10/Potocka_paper.pdf" target="_blank" rel="noopener">paper&lt;/a> and
&lt;a href="https://www.big.tuwien.ac.at/app/uploads/2016/10/Potocka_poster.pdf" target="_blank" rel="noopener">poster&lt;/a>&lt;/p></description></item><item><title>Constraint Checking using DB2 pureXML and DataPower: An Evaluation based on the Healthcare Environment</title><link>https://big.tuwien.ac.at/master-thesis/archive/constraint-checking-using-db2-purexml-and-datapower-an-evaluation-based-on-the-healthcare-environment/</link><pubDate>Tue, 19 May 2020 12:37:47 +0000</pubDate><guid>https://big.tuwien.ac.at/master-thesis/archive/constraint-checking-using-db2-purexml-and-datapower-an-evaluation-based-on-the-healthcare-environment/</guid><description>&lt;p>This work has been finished in October 2008.&lt;/p>
&lt;p>There are a variety of different sources where electronic healthcare information may be produced, such as equipment measuring parameters of the human body or personnel entering patient information into a healthcare information application. Representing healthcare information electronically allows to exchange information quickly utilizing all of information technology’s advantages. One of the keys for electronic healthcare information exchange is a common format to represent information, such as it is specified through healthcare standards.&lt;/p>
&lt;p>Regardless of the source of information, there are different possibilities where healthcare information may result into erroneous or faulty information. The source of erroneous information may be physical equipment producing wrong results, as well as a human entering wrong information into an information system. Having healthcare information available electronically, and moreover represented in a common format such as it is specified through healthcare standards, allows the processing of information using healthcare information applications. Therefore, one of the goals of this thesis is to identify different sources in healthcare information processing where erroneous information may occur. Based on these findings, notations are identified that may be used to define constraints. The purpose of constraints is to allow the definition of rules, which may then be applied to healthcare information, in order to discover inconsistent and erroneous parts thereof. Furthermore, different technologies, including hardware and software, are described which may be used to apply constraints.&lt;/p>
&lt;p>With the necessary theoretical background and technology, a fictional scenario is described. The purpose of the scenario is to illustrate different approaches to define and apply constraints to evaluate the quality and consistency of healthcare information. In particular, three different approaches are implemented and illustrated. It is then shown how constraint notations and the technology to apply constraints may support didactics in the healthcare area. The results found during the implementation and illustration of three different approaches are then evaluated, compared, and described. The findings include characteristics, advantages and disadvantages of each of the approaches taken. It is found that not all constraint notations and technologies are capable to define and apply constraints in order to discover erroneous healthcare information. However, even though certain technologies show limits, they have other advantages such as the configuration of a hardware device instead of creating an entire software application. Finally, the conclusion of this thesis points to further areas where exploratory work is needed, but which has been beyond the scope of this thesis.&lt;/p>
&lt;p> &lt;/p>
&lt;p>Download the
&lt;a href="https://www.big.tuwien.ac.at/app/uploads/2016/10/Pichler_paper.pdf" target="_blank" rel="noopener">paper&lt;/a> and
&lt;a href="https://www.big.tuwien.ac.at/app/uploads/2016/10/Pichler_poster.pdf" target="_blank" rel="noopener">poster&lt;/a>&lt;/p></description></item><item><title>Modelltransformationsanalyse basierend auf Petri Netzen</title><link>https://big.tuwien.ac.at/master-thesis/archive/modelltransformationsanalyse-basierend-auf-petri-netzen/</link><pubDate>Tue, 19 May 2020 12:37:47 +0000</pubDate><guid>https://big.tuwien.ac.at/master-thesis/archive/modelltransformationsanalyse-basierend-auf-petri-netzen/</guid><description>&lt;p>This work has been finished in March 2010.&lt;/p>
&lt;p>Abstract and paper may be found in our &lt;a class="external" href="http://publik.tuwien.ac.at/showentry.php?ID=185372&amp;amp;lang=2">publication database&lt;/a>.&lt;/p>
&lt;p>Download the
&lt;a href="https://www.big.tuwien.ac.at/app/uploads/2016/10/Pessenlehner_poster.pdf" target="_blank" rel="noopener">poster&lt;/a>&lt;/p></description></item><item><title>A State of the Art Comparison of Smart Contract Platforms</title><link>https://big.tuwien.ac.at/master-thesis/archive/a-state-of-the-art-comparison-of-smart-contract-platforms/</link><pubDate>Tue, 19 May 2020 12:37:46 +0000</pubDate><guid>https://big.tuwien.ac.at/master-thesis/archive/a-state-of-the-art-comparison-of-smart-contract-platforms/</guid><description/></item><item><title>Integration of External Libraries into the Foundational Subset of UML</title><link>https://big.tuwien.ac.at/master-thesis/archive/integration-of-external-libraries-into-the-foundational-subset-of-uml/</link><pubDate>Tue, 19 May 2020 12:37:46 +0000</pubDate><guid>https://big.tuwien.ac.at/master-thesis/archive/integration-of-external-libraries-into-the-foundational-subset-of-uml/</guid><description>&lt;p>This work has been finished in February 2014.&lt;/p>
&lt;p>With the introduction of OMG’s Foundational UML (fUML) standard, that precisely defines the execution semantics for a subset of UML, and the conforming virtual machine, completely executable systems can be built and executed with UML. However, the full potential of having executable models has yet to be unleashed. An important aspect that increases the potential of executable models is the ability to re-use existing software components since that reportedly increases the overall quality and productivity of the software development process. Furthermore, large-scale software that is produced nowadays, involves the usage of a high number of existing software components primarily in form of software libraries (i.e., APIs provided for the used programming language).&lt;/p>
&lt;p>This thesis identified that the fUML standard does not offer a procedure to use software libraries. In fact, creating models that build on top of software libraries is not foreseen in the fUML standard. On the contrary, the standard foresees its extendability through the Foundational Model Library. Yet, doing so requires implementing model libraries that basically mimic the functionality provided by currently existing software libraries. This approach imposes a significant drawback. It requires a huge amount of dedicated joint effort to build a set of libraries having similar functional coverage and sophistication as the existing set of software libraries.&lt;/p>
&lt;p>The research question of this thesis is as follows. Is the fUML virtual machine extendable, such that it allows the execution of models referencing external software libraries? Within this work, an approach has been elaborated that enables to use external software libraries in fUML models. The applicability of this approach has been shown by implementing a prototypical Integration Layer that is able to integrate Java libraries with the fUML virtual machine such that the modeler can benefit from the advanced and complex functionalities provided by those libraries. This prototype focuses on creating instances of library classes and calling library operations. Moreover, a two-step procedure to make existing libraries available for their usage in fUML models, has been implemented.&lt;/p>
&lt;p>While conducting several case studies, experiences have been gained that led to further enhancements of the prototype and to the following conclusion. The fUML virtual machine can be extended, such that it allows the execution of models referencing external libraries. Nevertheless, to broaden the applicability of the implemented prototype, and therefore increase the scope of applicable modeling scenarios, an in-depth investigation on common library use cases and their following implementation is recommended.&lt;/p>
&lt;p>Abstract and paper may be found in our &lt;a class="external" href="http://publik.tuwien.ac.at/showentry.php?ID=227306&amp;amp;lang=2">publication database&lt;/a>.&lt;/p>
&lt;p>Download the
&lt;a href="https://www.big.tuwien.ac.at/app/uploads/2016/10/Neubauer_poster.pdf" target="_blank" rel="noopener">poster&lt;/a>&lt;/p></description></item><item><title>Teaching JavaScript to Expert Java Developers</title><link>https://big.tuwien.ac.at/master-thesis/archive/teaching-javascript-to-expert-java-developers/</link><pubDate>Tue, 19 May 2020 12:37:46 +0000</pubDate><guid>https://big.tuwien.ac.at/master-thesis/archive/teaching-javascript-to-expert-java-developers/</guid><description/></item><item><title>Non-functional Testing in Cloud Environments</title><link>https://big.tuwien.ac.at/master-thesis/archive/non-functional-testing-in-cloud-environments/</link><pubDate>Tue, 19 May 2020 12:37:45 +0000</pubDate><guid>https://big.tuwien.ac.at/master-thesis/archive/non-functional-testing-in-cloud-environments/</guid><description>&lt;p>This work has been finished in July 2016.&lt;/p></description></item><item><title>Visualization and Manipulation of Diagrams on The Web – Developing e-Learning Support for Teaching UML in The Large</title><link>https://big.tuwien.ac.at/master-thesis/archive/visualization-and-manipulation-of-diagrams-on-the-web-developing-e-learning-support-for-teaching-uml-in-the-large/</link><pubDate>Tue, 19 May 2020 12:37:45 +0000</pubDate><guid>https://big.tuwien.ac.at/master-thesis/archive/visualization-and-manipulation-of-diagrams-on-the-web-developing-e-learning-support-for-teaching-uml-in-the-large/</guid><description>&lt;p>This work has been finished in December 2009.&lt;/p>
&lt;p>Die Fähigkeit von Software-Entwicklern, zu konkreten Problemstellungen klare und umfassende Modelle zu erstellen, erweist sich als essenzieller Faktor für den Erfolg von Software-Projekten. Die neuen Entwicklungen im Bereich von modellgetriebener Software-Entwicklung (MDSE) verstärken diesen Faktor darüber hinaus. Universitäten haben die Aufgabe, ihre Studenten in diesem Bereich auf hohem Niveau auszubilden,um sie auf diese Herausforderungen vorzubereiten. An der Technischen Universität Wien werden die Grundlagen von Modellierung und der Unified Modeling Language (UML) im Kurs Objektorientierte Modellierung gelehrt. Aufgrund der hohen Studentenzahl wurden bereits zahlreiche eLearning Elemente eingeführt, vor allem im Bereich der theoretischen Grundlagen.&lt;/p>
&lt;p>Ziel dieser Arbeit ist es, mithilfe von Rich Internet Application-Technologien ein Web-basiertes Modellierungstool zu erstellen, das in die Lernplattform der TU Wien integriert werden kann. Mit diesem Tool können Studenten praktische Modellierungsaufgaben einfach und direkt auf der Lernplattform lösen. Dabei soll ein generischer, Metamodell-basierter Ansatz gewählt werden. Die Visualisierung und Manipulierung von 2D-Diagrammen basiert auf bestimmten Mustern. Ein Framework ermöglicht es, nur durch die Angabe der Struktur der Diagrammelemente (abstrakte Syntax) und der visuellen Notationselemente (konkrete Syntax) einen kompletten Editor mit Drag-and-drop-Funktionalität zu erstellen. Damit wird es ermöglicht, verschiedene UML Editoren zu erstellen und die Notationselemente mit denen des Kurses abzustimmen. Im Zuge der Arbeit werden prototypisch drei UML-Editoren (Klassendiagramm, Zustandsdiagramm, Sequenzdiagramm) mithilfe des Frameworks erstellt und in die Lernplattform integriert.&lt;/p>
&lt;p> &lt;/p>
&lt;p>Download the
&lt;a href="https://www.big.tuwien.ac.at/app/uploads/2016/10/Murth_paper.pdf" target="_blank" rel="noopener">paper&lt;/a> and
&lt;a href="https://www.big.tuwien.ac.at/app/uploads/2016/10/Murth_poster.pdf" target="_blank" rel="noopener">poster&lt;/a>&lt;/p></description></item><item><title>Model Transformation By-Example: An Eclipse based Framework</title><link>https://big.tuwien.ac.at/master-thesis/archive/model-transformation-by-example-an-eclipse-based-framework/</link><pubDate>Tue, 19 May 2020 12:37:44 +0000</pubDate><guid>https://big.tuwien.ac.at/master-thesis/archive/model-transformation-by-example-an-eclipse-based-framework/</guid><description>&lt;p>This work has been finished in June 2008.&lt;/p>
&lt;p>Viele momentan existierenden Ansätze sowie Sprachen zur Modelltransformation sind metamodel-basiert, sie setzen detaillierte Kenntnisse der Metamodellebene und deren Syntax voraus. Meist wird die Transformation durch ein vollständiges Regelwerk auf der Metaebene bewerkstelligt. Einen neuen benutzerfreundlichen Ansatz dafür beschreibt die Model Transformation by-Example (MTBE), hierbei wird von einem leeren Regelwerk ausgegangen, bei dem der Benutzer auf Instanzebene grafisch die gewünschten Mappings defineren kann, aus denen dann automatisch Regeln generiert werden. Dies hat zum einen den Vorteil, dass auch Modelle transformiert werden können für welche noch keine Regeln existieren, zum anderen, dass der Benutzer individuelle Regeln erstellen kann ohne mit dem Metamodell oder der Transformationssprache vertraut zu sein. In dieser Arbeit wird versucht, ein Framework für MTBE auf Basis des Graphical Modelling Framework (GMF) zu implementieren. In unserer Implementation wird MTBE in ein Eclipse Plugin eingebettet, die Mappings können mit Hilfe eines automatisch, passend generiertem GMF-Editor gezeichnet werden. Daraus wird mittels eines Analyzers ein Weaving Model beziehungsweise der ATL Regelsatz generiert. In unserer Arbeit werden die dazu nötigen Grundlagen wie beispielsweise das Eclipse Modelling Framework oder die Atlas Transformation Language erläutert, anschließend wird die konkrete Implementation des Frameworks vorgestellt.&lt;/p>
&lt;p> &lt;/p>
&lt;p>Download the
&lt;a href="https://www.big.tuwien.ac.at/app/uploads/2016/10/M%c3%bcller_M%c3%bcller_paper.pdf" target="_blank" rel="noopener">paper&lt;/a> and
&lt;a href="https://www.big.tuwien.ac.at/app/uploads/2016/10/M%c3%bcller_M%c3%bcller_poster.pdf" target="_blank" rel="noopener">poster&lt;/a>&lt;/p></description></item><item><title>Model-based Reverse Engineering of Social Networks</title><link>https://big.tuwien.ac.at/master-thesis/archive/model-based-reverse-engineering-of-social-networks/</link><pubDate>Tue, 19 May 2020 12:37:44 +0000</pubDate><guid>https://big.tuwien.ac.at/master-thesis/archive/model-based-reverse-engineering-of-social-networks/</guid><description>&lt;p>This work has been finished in November 2011.&lt;/p>
&lt;p>Abstract and paper may be found in our &lt;a class="external" href="http://publik.tuwien.ac.at/showentry.php?ID=206543&amp;amp;lang=2">publication database&lt;/a>.&lt;/p>
&lt;p>Download the
&lt;a href="https://www.big.tuwien.ac.at/app/uploads/2016/10/Munk_poster.pdf" target="_blank" rel="noopener">poster&lt;/a>&lt;/p></description></item><item><title>Conceptualization of Feature Models für multi-client capable mobile Applications</title><link>https://big.tuwien.ac.at/master-thesis/archive/conceptualization-of-feature-models-fr-multi-client-capable-mobile-applications/</link><pubDate>Tue, 19 May 2020 12:37:43 +0000</pubDate><guid>https://big.tuwien.ac.at/master-thesis/archive/conceptualization-of-feature-models-fr-multi-client-capable-mobile-applications/</guid><description/></item><item><title>Evaluierung von Clio zur Transformation von Metamodellen</title><link>https://big.tuwien.ac.at/master-thesis/archive/evaluierung-von-clio-zur-transformation-von-metamodellen/</link><pubDate>Tue, 19 May 2020 12:37:43 +0000</pubDate><guid>https://big.tuwien.ac.at/master-thesis/archive/evaluierung-von-clio-zur-transformation-von-metamodellen/</guid><description>&lt;p>This work has been finished in January 2008.&lt;/p>
&lt;p>Clio ist ein Tool zur teilautomatischen Erzeugung von Schema Mappings und der anschließenden Transformation der Instanz eines Quellschemas in die Instanz eines Zielschemas.&lt;/p>
&lt;p>Ein Metamodell ist das Modell eines Modells und dient zur Beschreibung seiner Elemente und ihrer Beziehungen zueinander. Ecore ist eine Implementierung der Meta Object Facility, der standardisierten Sprach der Object Management Group (OMG) zur Beschreibung von Metamodellen.&lt;/p>
&lt;p>Diese Arbeit untersucht Clio in Anwendung auf Ecore-basierte Metamodelle. Es soll festgestellt werden, ob ein Einsatz von Clio zur Transformation dieser Metamodelle möglich und sinnvoll ist. Dabei wird die Bedienung Clios mit besonderem Augenmerk auf den notwendigen Input untersucht. Anschließend wird eine Methode entwickelt, um Metamodelle entsprechend umzuformen. Schließlich werden diese umgeformten Metamodelle verwendet, um sie mit Clio zu transformieren.&lt;/p>
&lt;p> &lt;/p>
&lt;p>Download the
&lt;a href="https://www.big.tuwien.ac.at/app/uploads/2016/10/Motschiunigg_paper.pdf" target="_blank" rel="noopener">paper&lt;/a>&lt;/p></description></item><item><title>Web Scraping: A Tool Evaluation</title><link>https://big.tuwien.ac.at/master-thesis/archive/web-scraping-a-tool-evaluation/</link><pubDate>Tue, 19 May 2020 12:37:43 +0000</pubDate><guid>https://big.tuwien.ac.at/master-thesis/archive/web-scraping-a-tool-evaluation/</guid><description>&lt;p>This work has been finished in March 2009.&lt;/p>
&lt;p>The WWW grows to one of the most important communication and information medium. Companies can use the Internet for various tasks. One possible application area is the information acquisition. As the Internet provides such a huge amount of information it is necessary to distinguish between relevant and irrelevant data. Web scrapers can be used to gather defined content from the Internet. A lot of scrapers and crawlers are available. Hence we decided to accomplish a case study with a company. We analyze available programs which are applicable in this domain.&lt;/p>
&lt;p>The company is the leading provider of online gaming entertainment. They offer sports betting, poker, casino games, soft games and skill games. For the sports betting platform they use data about events (fixtures/results) which are partly supplied by extern feed providers. Accordingly, there is a dependency on providers. Another problem is that smaller sports and minor leagues are not covered by the providers. This approach requires cross checks which are manual checks with websites if provider data differs and the definition of a primary source (source which is used in case of different data from providers) have to be done by data input user. Data about fixtures and results should be delivered by a company owned application.&lt;/p>
&lt;p>This application should be a domain-specific web crawler. It gathers information from well defined sources. This means bwin will not depend on other providers and they can cover more leagues. The coverage of the data feed integration tool will increase. Furthermore, it eliminates the cross checks between different sources. The first aim of this master thesis is to compose a functional specification for the usage of robots to gather event data via Internet and integrate the gathered information into the existing systems. Eight selected web scrapers will be evaluated and checked based on a benchmark catalogue which is created according to the functional specification. The catalogue and the selection are conceived to be reused for further projects of the company. The evaluation should result in a recommendation which web scraper fits best the requirements of the given domain.&lt;/p>
&lt;p> &lt;/p>
&lt;p>Download the
&lt;a href="https://www.big.tuwien.ac.at/app/uploads/2016/10/Mehlf%c3%bchrer_paper.pdf" target="_blank" rel="noopener">paper&lt;/a> and
&lt;a href="https://www.big.tuwien.ac.at/app/uploads/2016/10/Mehlf%c3%bchrer_poster.pdf" target="_blank" rel="noopener">poster&lt;/a>&lt;/p></description></item><item><title>Breathing New Life into Models: An Interpreter-Based Approach for Executing UML Models</title><link>https://big.tuwien.ac.at/master-thesis/archive/breathing-new-life-into-models-an-interpreter-based-approach-for-executing-uml-models/</link><pubDate>Tue, 19 May 2020 12:37:42 +0000</pubDate><guid>https://big.tuwien.ac.at/master-thesis/archive/breathing-new-life-into-models-an-interpreter-based-approach-for-executing-uml-models/</guid><description>&lt;p>This work has been finished in May 2011.&lt;/p>
&lt;p>Over the past years the development paradigm Model-Driven Development (MDD) gained significant in popularity. With the usage of this paradigm the software engineering process becomes more model-centric and less code-centric. This means that models become the main artifact in the software development process and therewith the whole software development process relies on these models and their correctness. For this reason the need for executable models that can be tested and validated arose. The Model Driven Architecture (MDA) is the MDD approach developed by the Object Management Group (OMG) that relies on the usage of a bunch of OMG standards. This approach designates the usage of UML to define a platform-independent model of the system that should be developed. The problem is that UML models are not executable because UML has no precise and complete specified semantics. Its semantics is defined informally in English prose and this definition is scattered throughout the standard which is about 1000 pages. Because of this ambiguities arise and models can be interpreted and executed in different ways. This also led to the development of execution tools that are not interoperable because they implement different execution semantics.&lt;/p>
&lt;p> &lt;/p>
&lt;p>OMG recognized the need for executable models and the corresponding issues with UML and developed a new standard called Semantics of a Foundational Subset of Executable UML Models or foundational UML (fUML) that was released in February 2011. This standard defines the precise execution semantics of a selected subset of UML 2, the so-called foundational UML subset.&lt;/p>
&lt;p> &lt;/p>
&lt;p>The research question of this thesis is as follows. Is the semantics definition of the fUML standard sound and applicable for building tools that enable the execution of UML activity diagrams? To answer this question, a prototype of a model-interpreter has been developed in this thesis that is able to execute and debug UML models according to the execution semantics defined in the fUML standard. This model-interpreter prototype focuses on executing activity diagrams that model the manipulation of objects and links in a system. Furthermore, the prototype provides reasonable debugging functionality similar to the functionality offered for debugging code like the step-wise execution and the displaying of the debugging progress. The experiences gained during the implementation of the model-interpreter prototype were reflected in order to evaluate the fUML standard itself as well as its applicability. The main conclusion of this evaluation is that the fUML standard is applicable for implementing tools that support the execution of UML activity diagram, but that high efforts are necessary to develop a user-friendly and efficiently usable tool supporting features like the debugging of models or the execution of incomplete models.&lt;/p>
&lt;p>Abstract and paper may be found in our &lt;a class="external" href="http://publik.tuwien.ac.at/showentry.php?ID=196765&amp;amp;lang=2">publication database&lt;/a>.&lt;/p>
&lt;p>Download the
&lt;a href="https://www.big.tuwien.ac.at/app/uploads/2016/10/Mayerhofer_poster.pdf" target="_blank" rel="noopener">poster&lt;/a>&lt;/p></description></item><item><title>Ubiquitäre Web-Anwendungen – Entwicklung endgeräteunabhängiger Lösungsansätze</title><link>https://big.tuwien.ac.at/master-thesis/archive/ubiquitre-web-anwendungen-entwicklung-endgerteunabhngiger-lsungsanstze/</link><pubDate>Tue, 19 May 2020 12:37:42 +0000</pubDate><guid>https://big.tuwien.ac.at/master-thesis/archive/ubiquitre-web-anwendungen-entwicklung-endgerteunabhngiger-lsungsanstze/</guid><description>&lt;p>This work has been finished in February 2007.&lt;/p>
&lt;p>Ubiquitäre Web-Anwendungen haben das anytime/anywhere/anymedia Paradigma zugrunde liegen, und sollen dem Anwender, egal wann, wo und mit welchem Gerät er diese nutzt, einen individuell abgestimmten und auf die Rahmenbedingungen des Benutzers angepassten Inhalt bieten.&lt;/p>
&lt;p>Im Rahmen einer Kooperation von drei Magisterarbeiten [Brosch, Mayer, Weissensteiner] wurde ein ubiquitäres Tourismusinformationssystem entwickelt. Das Ziel dieses umfangreichen Projekts war die Konzeption, Modellierung und Implementierung einer Web-Anwendung mit Customizationunterstützung, dh. einer Web-Anwendung, die aufgrund mehrerer Kontextfaktoren wie Benutzer, Zeit, Ort, Gerät, etc., mit der Adaptierung ihrer Dienste reagiert. Die Implementierung der Customizationfunktionalität ist allerdings komplex, da sie an vielen Stellen der Web-Anwendung Berücksichtigung finden muss und sich quer durch den Code des Systems zieht. Separation of Concerns ist daher im Sinne der Wartbarkeit, Erweiterbarkeit und Änderbarkeit eines Systems anzustreben.&lt;/p>
&lt;p>Im speziellen Fokus dieser Arbeit stand der anymedia Aspekt von ubiquitären Web-Anwendungen. Die Anpassung der Web-Anwendung an die technischen Kontextfaktoren des Endgeräts unter besonderer Berücksichtigung der verschiedenen Techniken zur Erkennung der Eigenschaften des Endgeräts, wurde untersucht. Anschließend wurden die Adaptierungstechniken für die Anpassung der Inhalte evaluiert und im Rahmen eines praktischen Prototyps umgesetzt.&lt;/p>
&lt;p>Die Adaptierung an das Endgerät ist Teil der Customization der ubiquitären Web-Anwendung und zieht sich somit als Crosscutting Concern durch die gesamte Anwendung. Speziell im Hinblick auf die Endgerätunabhängigkeit gilt es schon von Beginn an genau festzulegen, welche Inhalte wie granular und mit welchen Metainformationen gespeichert werden. Weiters ist es wichtig, im Hinblick auf die nötigen Adaptierungstechniken festzulegen, welche Authoring Methode zum Einsatz kommt. Ebenso notwendig für die Adaptierung ist die Erkennung der Geräteeigenschaften, denn in Abhängigkeit dieser erfolgt die eigentliche Selektion und Aggregation der Inhalte und anschließend die Transformation der Darstellung an die Einschränkungen des Endgeräts.&lt;/p>
&lt;p> &lt;/p>
&lt;p>Download the
&lt;a href="https://www.big.tuwien.ac.at/app/uploads/2016/10/Mayer_paper.pdf" target="_blank" rel="noopener">paper&lt;/a> and
&lt;a href="https://www.big.tuwien.ac.at/app/uploads/2016/10/Mayer_poster.pdf" target="_blank" rel="noopener">poster&lt;/a>&lt;/p></description></item><item><title>Auswirkungen von modernen Softwareentwicklungstechniken auf die Barrierefreiheit von Web-Anwendungen</title><link>https://big.tuwien.ac.at/master-thesis/archive/auswirkungen-von-modernen-softwareentwicklungstechniken-auf-die-barrierefreiheit-von-web-anwendungen/</link><pubDate>Tue, 19 May 2020 12:37:41 +0000</pubDate><guid>https://big.tuwien.ac.at/master-thesis/archive/auswirkungen-von-modernen-softwareentwicklungstechniken-auf-die-barrierefreiheit-von-web-anwendungen/</guid><description>&lt;p>This work has been finished in September 2009.&lt;/p>
&lt;p>Die Modellgetriebene Softwareentwicklung ist ein aktueller Trend in der Softwareentwicklung. Dabei ist die Grundidee, mit Hilfe von Code-Generatoren aus abstrakten Softwaremodellen ausführbaren Code automatisch zu generieren. Aktuelle Ansätze legen dabei hauptsächlich Wert auf funktionale Aspekte des zu generierenden Codes, z.B. wie aus UML-Diagrammen Java Code generiert werden kann. Jedoch werden Qualitätsaspekte, die nicht aus den technischen Anforderungen hervorgehen, nur selten berücksichtigt. Ein wichtiger Qualitätsaspekt stellt u.a. die Barrierefreiheit von Webseiten dar. Der Gesetzgeber in Österreich verlangt, dass der barrierefreie Zugang zu behördlichen Internetauftritten für Menschen mit besonderen Bedürfnissen bis 1.1.2008 umgesetzt hätte werden sollen. Um die Barrierefreiheit von Web-Anwendungen festzustellen, werden so genannte Web Accessibilty Guidelines (WAG) vorgegeben. Zum Beispiel gibt es von der W3C die WCAG (Web Content Accessibility Guidelines), welche sich bereits als ein Web Accessibility de facto Standard durchgesetzt haben. Um die Konformität mit den oben geforderten rechtlichen Bestimmungen zu erfüllen, müssen öffentliche Internetauftritte den jeweilig geforderten Richtlinien entsprechen. In dieser Diplomarbeit wird nun eruiert, in welcher Weise moderne Komponenten-Frameworks und Code-Generatoren die sich aus den Richtlinien ergebenden Anforderungen erfüllen. Dazu werden WAG (Web Accessibility Guidelines) konforme statische HTML-Seiten als Ausgangspunkt verwendet, welche dann mittels Komponenten-Frameworks und Code-Generatoren dynamisch weiter entwickelt und als Web-Anwendungen abgebildet werden. Das Ergebnis dieses Generierungsprozesses wird schließlich in Form von HTML-Seiten im Browser gerendert. Diese gerenderten Seiten werden mittels WAG-Validatoren (Prüfprogramme für die WAG-Konformität) hinsichtlich zuvor gewählter Richtlinien geprüft. Aus dem Ergebnis dieser Konformitätsprüfung ist ersichtlich, welche Verletzungen der gewählten WAG auftreten und wie gut die jeweiligen Entwicklungstechnologien für die Erstellung von WAG-konformen Web-Anwendungen geeignet sind. Es hat sich gezeigt, dass der generierte Code der evaluierten HTML-Seiten noch mit vielen Barrieren behaftet ist und noch großes Verbesserungspotential bei den eingesetzten Entwicklungswerkzeugen gegeben ist.&lt;/p>
&lt;p> &lt;/p>
&lt;p>Download the
&lt;a href="https://www.big.tuwien.ac.at/app/uploads/2016/10/Mauerhofer_papers.pdf" target="_blank" rel="noopener">paper&lt;/a> and
&lt;a href="https://www.big.tuwien.ac.at/app/uploads/2016/10/Mauerhofer_poster.pdf" target="_blank" rel="noopener">poster&lt;/a>&lt;/p></description></item><item><title>User centric Evaluation of Product Variants: A Method based on Feature Models and House of Quality</title><link>https://big.tuwien.ac.at/master-thesis/archive/user-centric-evaluation-of-product-variants-a-method-based-on-feature-models-and-house-of-quality/</link><pubDate>Tue, 19 May 2020 12:37:41 +0000</pubDate><guid>https://big.tuwien.ac.at/master-thesis/archive/user-centric-evaluation-of-product-variants-a-method-based-on-feature-models-and-house-of-quality/</guid><description>&lt;p>This work has been finished in March 2015.&lt;/p>
&lt;p>Variabilität spielt in modernen Produkten eine zunehmende Rolle. Kunden erwarten sich individuelle Produkte, die ihre speziellen Anforderungen erfüllen. Daraus folgt eine zunehmende Herausforderung in der Produktentwicklung, geprägt durch die Vielzahl an Produktkonfigurationsmöglichkeiten und die daraus resultierende Komplexität. Aus diesem Grund ist zur Auswahl geeigneter Varianten eine adäquate methodische Unterstützung durch Informationssysteme unabdingbar. Besonders schwierig ist der Umgang mit Kundenanforderungen, wenn sie von denen eines durchschnittlichen Benutzers abweichen. Ein Problem, wie es vor allem bei der (Weiter-) Entwicklung von medizinischen Produkten oft der Fall ist. In dieser Domäne resultieren individuelle – vom Durchschnittsbenutzer oft stark abweichende – Anforderungen an ein Produkt meist aufgrund gesundheitlicher Einschränkungen des Endnutzers. Zurzeit ist es nicht möglich, diese individuellen Anforderungen bei der Konfiguration von Varianten zu berücksichtigen. Diese Arbeit beschreibt eine Methode, mittels der Produktvariabilität bewertet und evaluiert werden kann. Zu diesem Zweck werden das House of Quality und Feature Models kombiniert. Die Zusammenführung von Konzepten beider Techniken verwenden wir, um sie für eine benutzerorientierte Evaluierung von variablen Produkten zu adaptieren. Zur Veranschaulichung der Vorgehensweise und als Proof-of-Concept wird eine Fallstudie aus dem Bereich Health Care mit der vorgestellten Methode durchgeführt. Dadurch soll die praktische Durchführbarkeit und Relevanz der Methode geprüft werden. Im Anschluss an die Fallstudie wird diese evaluiert, wodurch zusätzliche Problemfelder und noch offene Fragen identifiziert werden. Zu diesem Zweck wurde die Arbeit bei einem internationalen Workshop für Variantenmodellierung vorgestellt. Zusätzlich wurden Interviews mit Experten aus dem Bereich Variantenmodellierung durchgeführt.&lt;/p>
&lt;p> &lt;/p>
&lt;p>Download the
&lt;a href="https://www.big.tuwien.ac.at/app/uploads/2016/10/Maetzler_paper.pdf" target="_blank" rel="noopener">paper&lt;/a> and
&lt;a href="https://www.big.tuwien.ac.at/app/uploads/2016/10/Maetzler_poster.pdf" target="_blank" rel="noopener">poster&lt;/a>&lt;/p></description></item><item><title>Model-based Deployment and Provisioning of Applications to the Cloud</title><link>https://big.tuwien.ac.at/master-thesis/archive/model-based-deployment-and-provisioning-of-applications-to-the-cloud/</link><pubDate>Tue, 19 May 2020 12:37:40 +0000</pubDate><guid>https://big.tuwien.ac.at/master-thesis/archive/model-based-deployment-and-provisioning-of-applications-to-the-cloud/</guid><description>&lt;p>This work has been finished in December 2013.&lt;/p>
&lt;p>Cloud computing had and still has a major impact on how applications are made accessible for the users. Due to the advantages cloud computing has, there is a demand to migrate applications to the cloud. Unfortunately there does not exist general guidelines how to define the required application execution environments and deployment requirements so that they can be interpreted by any arbitrary cloud provider.&lt;/p>
&lt;p>In the last years, cloud providers came up with approaches to be able to describe cloud resources in form of an interpretable template. Just recently, in November 2013, OASIS published the open standard TOSCA, which aims to unite existing proprietary approaches and standardise them. Approaches following a declarative way of describing orchestrated cloud resources are quite recent and are extended frequently, as it is a promising possibility of illustrating complex dependencies and limitations of computing resources in a way that can be read by human beings as well.&lt;/p>
&lt;p>This thesis firstly discusses model driven engineering and cloud computing separately and afterwards, how they can be combined. The main aim is to create a model that contains enough information about dependencies, limitations and application specific requirements, which can support the migration of the application to the cloud.&lt;/p>
&lt;p>Furthermore, the master’s thesis proposes a process, which is subdivided into two parts: Deployment and Provisioning. The first step is about creating UML models and refining them with UML extensions (classifiers, profiles and stereotypes), which consists out of cloud computing specific attributes. The second step converts the model into a template, by means of applying model to text transformations, in order to be interpretable and executable by cloud providers.&lt;/p>
&lt;p>Existing solutions only address partial aspects of the whole problem, focusing on other objectives. One of the main goal of this thesis is the creation of a unified and model-based solution, whose processes and tools support the application modeler and make a (semi-)automatic execution of the deployment and provisioning of an application in the cloud possible.&lt;/p>
&lt;p> &lt;/p></description></item><item><title>ProfileGen - Ein Eclipse Plugin für Interoperabilität zwischen DSML und UML</title><link>https://big.tuwien.ac.at/master-thesis/archive/profilegen-ein-eclipse-plugin-fr-interoperabilitt-zwischen-dsml-und-uml/</link><pubDate>Tue, 19 May 2020 12:37:40 +0000</pubDate><guid>https://big.tuwien.ac.at/master-thesis/archive/profilegen-ein-eclipse-plugin-fr-interoperabilitt-zwischen-dsml-und-uml/</guid><description>&lt;p>This work has been finished in February 2011.&lt;/p>
&lt;p>Current software development projects comprise the development of complex software systems under immense time pressure. In the past decade, model-driven software development (MDSD) has become mainstream to tackle these challenges. In MDSD, domain specific modelling languages (DSML) are becoming more and more important. These languages allow to concisely represent all the peculiarities of a given domain in a model. But being so specific, interoperability is needed with standardized modeling languages such as UML, because they offer a more common way of communication between different stakeholders. At the moment, interoperability can only be achieved by manually creating transformations between DSMLs and UML which is a challenging task.&lt;/p>
&lt;p>This thesis presents a tool named ProfileGen, which tackles this challenge by proposing a semi-automatic approach for generating such transformations needed for interoperability between DSMLs and UML. In particular, a mapping language is presented which allows to manually link DSML elements with UML elements on a high-level of abstraction. From such mappings, a generator framework automatically creates all artifacts needed for interoperability, including transformations from the DSMLs to UML and vice versa, as well as UML profiles for ensuring information loss free transformations .The approach is evaluated by a real-world case study, namely integrating WebML (a DSML for data-intensive Web applications) with UML.&lt;/p>
&lt;p> &lt;/p></description></item><item><title>SERAPIS 2 Ecore - Bridging Two Modeling Spaces in Eclipse</title><link>https://big.tuwien.ac.at/master-thesis/archive/serapis-2-ecore-bridging-two-modeling-spaces-in-eclipse/</link><pubDate>Tue, 19 May 2020 12:37:40 +0000</pubDate><guid>https://big.tuwien.ac.at/master-thesis/archive/serapis-2-ecore-bridging-two-modeling-spaces-in-eclipse/</guid><description>&lt;p>This work has been finished in September 2013.&lt;/p>
&lt;p>Abstract and paper may be found in our &lt;a class="external" href="http://publik.tuwien.ac.at/showentry.php?ID=220876&amp;amp;lang=2">publication database&lt;/a>.&lt;/p>
&lt;p>Download the
&lt;a href="https://www.big.tuwien.ac.at/app/uploads/2016/10/Margreiter_poster.pdf" target="_blank" rel="noopener">poster&lt;/a>&lt;/p></description></item><item><title>Evaluation of Software Development Paradigms and Processes for Web Application Engineering</title><link>https://big.tuwien.ac.at/master-thesis/archive/evaluation-of-software-development-paradigms-and-processes-for-web-application-engineering/</link><pubDate>Tue, 19 May 2020 12:37:39 +0000</pubDate><guid>https://big.tuwien.ac.at/master-thesis/archive/evaluation-of-software-development-paradigms-and-processes-for-web-application-engineering/</guid><description>&lt;p>This work has been finished in February 2011.&lt;/p>
&lt;p>The thesis deals with the process of web engineering. Its purpose is to find a development model, covering all phases of the involved processes and the majority of aspects influencing the design of a web based software product. This knowledge is translated into the implementation of a template framework for the Microsoft Team Foundation Server (TFS). The usage of this template set is demonstrated by documenting the life cycle of a web software project to be carried out.&lt;/p>
&lt;p>In order to meet this objective, it is necessary to determine the differences between developing classical (desktop-centric) software and applications being accessed via the web, both from a product and process point of view. The first part of this thesis will therefore screen existing literature on this topic to identify established solutions and approaches. Well-known attributes are then combined, distinguishing web engineering from other disciplines, with personal analysis to gather a comprehensive set of peculiarities identifying this field of software development.&lt;/p>
&lt;p>Subsequently this work gives an introduction into common software development paradigms, both heavy weight (such as the Rational Unified Process) and light weight (such as Scrum and Extreme Programming). Those processes are outlined and evaluated against the specific requirements found in the previous chapter. Conclusively, the main objective is to find a single, or a combination of a certain set of paradigms, covering the needs of Web Engineering as complete as possible.&lt;/p>
&lt;p>The practical part of the thesis capitalizes on the insights retrieved in the theoretical chapters. The ambition is to create a development framework consisting of templates for the Microsoft Team Foundation Server (TFS) reflecting all steps of the software development cycle. The TFS provides source control, data collection, reporting, and project tracking, and so provides a platform for collaborative software development projects. The implemented development framework leverages these features leading to efficient processes and usable work items. The latter is demonstrated by utilizing this basis to conduct a web software project involving a team of developers, designers and project managers.&lt;/p>
&lt;p> &lt;/p></description></item><item><title>Transformation von XML Schema nach UML - Implementierung und Evaluierung</title><link>https://big.tuwien.ac.at/master-thesis/archive/transformation-von-xml-schema-nach-uml-implementierung-und-evaluierung/</link><pubDate>Tue, 19 May 2020 12:37:39 +0000</pubDate><guid>https://big.tuwien.ac.at/master-thesis/archive/transformation-von-xml-schema-nach-uml-implementierung-und-evaluierung/</guid><description>&lt;p>This work has been finished in June 2005.&lt;/p>
&lt;p>Die vorliegende Arbeit erläutert die Transformation von XML-Schema Dokumenten nach UML. Als Basis der formalen Beschreibung der UML-Darstellung einzelner XML-Schema Elemente wurde die Arbeit [Bern03] herangezogen. Diese wurde konkretisiert und den Anforderungen von BOTL angepasst. Insbesondere wurden die Transformationsregeln durch aussagekräftige Beispiele illustriert.&lt;/p>
&lt;p>Die Realisierung erfolgte mithilfe der ArgoUML4BOTL-Applikation, welche die „Bidirectional Object oriented Transformation Language“ (BOTL) als Transformationssprache verwendet. Diese Arbeit erläutert die Prinzipien und Funktionsmöglichkeiten der BOTL-Transformation. Es werden Vor- und Nachteile sowie Grenzen von ArgoUML4BOTL aufgezeigt. Personen, die ein Transformationsprojekt mittels BOTL in Erwägung ziehen, werden durch diese Arbeit einen besseren Einblick über den Aufwand der Projekterstellung bekommen und abschätzen können, inwieweit dieses Tool ihren Anforderungen entspricht.&lt;/p>
&lt;p> &lt;/p>
&lt;p>Download the
&lt;a href="https://www.big.tuwien.ac.at/app/uploads/2016/10/Lentsch_paper.pdf" target="_blank" rel="noopener">paper&lt;/a>&lt;/p></description></item><item><title>Konflikterkennung in der Modellversionierung</title><link>https://big.tuwien.ac.at/master-thesis/archive/konflikterkennung-in-der-modellversionierung/</link><pubDate>Tue, 19 May 2020 12:37:38 +0000</pubDate><guid>https://big.tuwien.ac.at/master-thesis/archive/konflikterkennung-in-der-modellversionierung/</guid><description>&lt;p>This work has been finished in February 2009.&lt;/p>
&lt;p>In den letzten Jahren gewannen Softwaremodelle als zentrale Artefakte der Softwareentwicklung zunächst mit dem CASE-Ansatz (Computer Aided Software Engineering) und später mit dem MDE-Ansatz (Model Driven Engineering) immer mehr an Bedeutung. Sie dienen mittlerweile nicht nur zur Dokumentation und zur Bildung des gemeinsamen Verständnisses sondern auch als Grundlage für die Generierung eines lauffähigen Systems. Der modellgetriebene Ansatz ist in der Softwareentwicklung zu einer etablierten und weit verbreiteten Methode geworden.&lt;/p>
&lt;p>An dem Softwareentwicklungsprozess ist in größeren Softwareprojekten üblicherweise eine Vielzahl an EntwicklerInnen beteiligt. Diese verfeinern in einem zumeist iterativen Prozess das zu entwickelnde System und passen es stetig an sich verändernde Anforderungen, Verständnisse und laufend zu treffende Designentscheidungen an. Für eine erfolgreiche Durchführung eines Softwareprojekts ist daher ein effizientes Änderungs- und Konfigurationsmanagement ausschlaggebend und ermöglicht erst die effektive Zusammenarbeit mehrerer EntwicklerInnen. Traditionelle Versionierungssysteme implementieren größtenteils nur zeilenbasierte Konflikterkennung und bieten daher keine ausreichende Unterstützung für Erkennung und Resolution von Konflikten bei der Versionierung von Softwaremodellen, die eine graphenbasierte Form aufweisen.&lt;/p>
&lt;p>Das Ziel dieser Arbeit ist die Erarbeitung und Implementierung einer intelligenten, adaptierbaren Konflikterkennung für die Versionierung von Modellen. Es wird ein Rahmenwerk geschaffen, das out-of-the-box einen verwendbaren Vergleichs- und Konflikterkennungsalgorithmus für Modelle bietet und bei Bedarf durch die Erstellung spezifischer Beschreibungen für eine konkrete Modellierungssprache oder -domäne adaptiert werden kann. Diese sprachspezifischen Erweiterungen erhöhen die Qualität und Genauigkeit der Konflikterkennung und verhindern dadurch unnötige Konfliktmeldungen und manuelle Eingriffe.&lt;/p>
&lt;p> &lt;/p>
&lt;p>Download the
&lt;a href="https://www.big.tuwien.ac.at/app/uploads/2016/10/Langer_paper.pdf" target="_blank" rel="noopener">paper&lt;/a> and
&lt;a href="https://www.big.tuwien.ac.at/app/uploads/2016/10/Langer_poster.pdf" target="_blank" rel="noopener">poster&lt;/a>&lt;/p></description></item><item><title>Model Driven Reverse Engineering of C# Code to fUML Models</title><link>https://big.tuwien.ac.at/master-thesis/archive/model-driven-reverse-engineering-of-c-code-to-fuml-models/</link><pubDate>Tue, 19 May 2020 12:37:38 +0000</pubDate><guid>https://big.tuwien.ac.at/master-thesis/archive/model-driven-reverse-engineering-of-c-code-to-fuml-models/</guid><description/></item><item><title>Evaluation von e-Learning Techniken zur Abhaltung eines MOOC</title><link>https://big.tuwien.ac.at/master-thesis/archive/evaluation-von-e-learning-techniken-zur-abhaltung-eines-mooc/</link><pubDate>Tue, 19 May 2020 12:37:37 +0000</pubDate><guid>https://big.tuwien.ac.at/master-thesis/archive/evaluation-von-e-learning-techniken-zur-abhaltung-eines-mooc/</guid><description>&lt;p>Durch die hohe Anzahl von Studierenden gewinnt die Verwendung von e-Learning Techniken immer mehr an Bedeutung. Im Rahmen dieser Arbeit sollen bestehende Plattformen zur Abhaltung von Massive Open Online Courses (MOOCs) verglichen und für deren Tauglichkeit zur Abhaltung von Lehrveranstaltungen an der TU Wien evaluiert werden. Diese Evaluation beinhaltet insbesondere eine Abhandlung über bestehende MOOCs an ausländischen Universitäten. Die Arbeit soll im Speziellen auf die Lehrsituation im ersten Studienjahr der Bachelorstudien der Informatik und Wirtschaftsinformatik an der TU Wien Bezug nehmen—insbesondere sollen die notwendigen personellen Ressourcen erörtert werden. Die Arbeit soll erklären, welche e-Learning Techniken in diesem Szenario sinnvoll eingesetzt werden können, um in Folge auch die Kursmaterialien für eine breitere Öffentlichkeit in Form eines MOOC anzubieten.  Dabei soll auch auf Software-Systeme zur automatischen Feedback-Generierung eingegangen werden und diese anhand deren Praxistauglichkeit bewertet werden. Im praktischen Teil der Arbeit soll ein prototypisches Kursmodell für einen Programmier-Kurs im ersten Studienjahr der Informatik erarbeitet werden.&lt;/p></description></item><item><title>SOMA - A Service-Oriented Mobile Learning Architecture</title><link>https://big.tuwien.ac.at/master-thesis/archive/soma-a-service-oriented-mobile-learning-architecture/</link><pubDate>Tue, 19 May 2020 12:37:37 +0000</pubDate><guid>https://big.tuwien.ac.at/master-thesis/archive/soma-a-service-oriented-mobile-learning-architecture/</guid><description>&lt;p>This work has been finished in June 2010.&lt;/p>
&lt;p>Service-Oriented Mobile learning Architecture (SOMA) is a project focusing on interactive learning using mobile devices, with the main focus on devices running on the Google Android operating system. While state-of-the-art solutions mainly cover text-based, multiple choice interrogator-responder concepts, our approach will be characterized by interactivity, allowing multimedia-based e-learning concepts. Providing access to different hardware features enables a variety of novel input methods. Examples include obtaining user input through hardware accelerometers or cameras. In order to provide these advanced features we implement the SOMA-Framework (SOMAF) as part of this work, which acts as wrapper between the e-learning application and the underlying hardware components. The realization of the concrete features is based on a plug-in system, which enables almost unlimited extension of the SOMA application. Thereby, we use a custom implementation of Java Reflection to guarantee extensibility. The basic idea of our approach is based on Sabine Graf’s work on learning styles. Concerning this topic, we will mainly concentrate on capturing all user input needed for the evaluation of learning styles. Another important aspect is the integration of the e-learning process into social networks. The system will allow users to publish their results online and invite friends to take the same course. We assume this will improve learning motivation significantly. Users can compete and incite each other to enhance their learning progress. Besides the SOMA framework itself, a sample plug-in will be developed as part of this work. For the evaluation of our solution we will provide a sample course that uses this basic plug-in. The sample course will be created in cooperation with the Austrian Youth Red Cross Klosterneuburg, covering basic first aid content.&lt;/p>
&lt;p> &lt;/p>
&lt;p>Download the
&lt;a href="https://www.big.tuwien.ac.at/app/uploads/2016/10/Kromer_Kuntner_paper.pdf" target="_blank" rel="noopener">paper&lt;/a> and
&lt;a href="https://www.big.tuwien.ac.at/app/uploads/2016/10/Kromer_Kuntner_poster.pdf" target="_blank" rel="noopener">poster&lt;/a>&lt;/p></description></item><item><title>UML-Profil für Geschäftsprozesse</title><link>https://big.tuwien.ac.at/master-thesis/archive/uml-profil-fr-geschftsprozesse/</link><pubDate>Tue, 19 May 2020 12:37:37 +0000</pubDate><guid>https://big.tuwien.ac.at/master-thesis/archive/uml-profil-fr-geschftsprozesse/</guid><description>&lt;p>This work has been finished in January 2005.&lt;/p>
&lt;p>Geschäftsprozesse sind häufig der Ausgangspunkt für die Softwareentwicklung und definieren die Anforderungen für die zu entwickelnden Softwaresysteme. Meist kennen die Softwareentwickler die Geschäftsprozesse nicht bzw. können Geschäftsprozessmodelle nicht lesen, da in den beiden Gebieten unterschiedliche Modellierungssprachen verwendet werden, die sich unterschiedlicher Diagramme und Notationen bedienen. In dieser Arbeit wurde ein UML-Profil für Geschäftsprozesse entwickelt, mit dem Ziel Geschäftsprozessmodelle für Softwareentwickler durch eine in der Softwareentwicklung geläufige Notation lesbar zu machen.&lt;/p>
&lt;p>Das UML-Profil besteht aus zwei Sichten, aus einer Überblickssicht (generelles Prozessmodell) und einer Detailsicht (Detailmodell). Das generelle Prozessmodell beschreibt die Zusammenhänge mit anderen Prozessen, die zu erzeugende Leistung, die Prozessziele, den Prozesstyp, den Prozesskunden und -eigner. Das Detailmodell ist eine Verfeinerung des generellen Prozessmodells und stellt den detaillierten Prozessablauf mittels einer 1-1 Abbildung zwischen Ereignisgesteuerten Prozessketten und Aktivitätsdiagramm dar. Das UML-Profil wurde mittels des „Urlaubsgenehmigungsprozesses“ beispielhaft realisiert.&lt;/p>
&lt;p> &lt;/p>
&lt;p>Download the
&lt;a href="https://www.big.tuwien.ac.at/app/uploads/2016/10/Korherr_papers.pdf" target="_blank" rel="noopener">paper&lt;/a>&lt;/p></description></item><item><title>A Kernel Language for Behavioural Modeling Languages</title><link>https://big.tuwien.ac.at/master-thesis/archive/a-kernel-language-for-behavioural-modeling-languages/</link><pubDate>Tue, 19 May 2020 12:37:36 +0000</pubDate><guid>https://big.tuwien.ac.at/master-thesis/archive/a-kernel-language-for-behavioural-modeling-languages/</guid><description/></item><item><title>Verteilte Transaktionen für Webservices</title><link>https://big.tuwien.ac.at/master-thesis/archive/verteilte-transaktionen-fr-webservices/</link><pubDate>Tue, 19 May 2020 12:37:36 +0000</pubDate><guid>https://big.tuwien.ac.at/master-thesis/archive/verteilte-transaktionen-fr-webservices/</guid><description>&lt;p>This work has been finished in January 2005.&lt;/p>
&lt;p>In einer Service orientierten IT Landschaft ist das Bereitstellen von ausgewählten Services, welche firmeninterne Prozesse starten und die Resultate an den Aufrufer schicken, von großem Interesse, weil dadurch Firmen und Organisationen ihre Leistungen weitflächig und automatisiert im Web zur Verfügung stellen können.&lt;/p>
&lt;p>Verteilte Transaktionen ermöglichen es den Benutzern von Services, die Dienste miteinander zu vergleichen und Bedingungen an das Ausführen eines Services von den Informationen oder Resultaten eines anderen Services abhängig zu machen. Web Services bieten dabei die Interoperabilitätsschnittstelle an, mit der es heterogenen IT Systemen möglich wird miteinander zu kommunizieren.&lt;/p>
&lt;p>Die vorliegende Diplomarbeit erörtert anfangs den Background zu den Bereichen Web Services und verteilten Transaktionen. Zuerst werden Web Services der ersten und zweiten Generation betrachtet. Das Thema der verteilten Transaktionen wird anhand bestehender wissenschaftlicher Literatur aufgearbeitet.&lt;/p>
&lt;p>Nach diesen Grundlagen werden die Standard Spezifikationen DTP und OTS als Bindeglied zwischen Theorie und aktuellen Spezifikationen untersucht. Weiters werden die existierenden transaktionsunterstützenden Web Service Spezifikationen miteinander verglichen, sowie die Voraussetzungen erforscht um mit Web Services transaktionsverarbeitende Mechanismen zu unterstützen.&lt;/p>
&lt;p>Ein einfacher Proof Of Concept Prototyp, realisiert mit JOTM-BTP, wird vorgestellt, der eine verteilte Two Phase Commit Transaktion auf Basis des Business Transaction Protocol, welches bei der OASIS Organisation liegt, umsetzt. Dieser Prototyp wird hinsichtlich der Erfüllung von Transaktionsanforderungen betrachtet und es werden weitergehende Vorschläge und Ideen, die aus der Entwicklung des Prototypen entstanden, gebracht.&lt;/p>
&lt;p>Der letzte Teil der Arbeit fasst die gewonnen Erkenntnisse zusammen, zieht eine Trennlinie zu anderen Bereichen, wie J2EE und BPEL, und gibt eine Prognose zur weiteren Entwicklung der Spezifikationen ab.&lt;/p>
&lt;p> &lt;/p>
&lt;p>Download the
&lt;a href="https://www.big.tuwien.ac.at/app/uploads/2016/10/Kiraly_papers.pdf" target="_blank" rel="noopener">paper&lt;/a>&lt;/p></description></item><item><title>Codegenerierung mit AndroMDA</title><link>https://big.tuwien.ac.at/master-thesis/archive/codegenerierung-mit-andromda/</link><pubDate>Tue, 19 May 2020 12:37:35 +0000</pubDate><guid>https://big.tuwien.ac.at/master-thesis/archive/codegenerierung-mit-andromda/</guid><description>&lt;p>This work has been finished in October 2006.&lt;/p>
&lt;p>Mit der Model Driven Architecture (kurz: MDA) gibt es einen neuen Standard zur generativen Softwareentwicklung. Dieser wurde von der Object Management Group im Juni 2003 spezifiziert. Ziel der MDA ist es, technologienunabhängige Spezifikationen zu erstellen, die für automatische Codegenerierung auf unterschiedlichen Plattformen wie .NET, J2EE, oder CORBA genutzt werden können.&lt;/p>
&lt;p>Mit dem Einsatz von MDA liegt der Fokus hauptsächlich auf der Modellebene, die eigentliche Programmierung rückt zusehends in den Hintergrund. Der Idealfall wäre eine auf unterschiedlichen Plattformen völlig automatisierte sowie vollständige Codegenerierung aus den UML Modellen. Da dies aber noch nicht der Fall ist, müssen Software Entwickler bis dato auf 2 unterschiedlichen Abstraktions- und Technologieebenen, der Modellebene und der Codeebene, arbeiten.&lt;/p>
&lt;p>Bis dato implementieren schon eine geraume Anzahl von Tools die MDA Spezifikation (AndroMDA, ArcStyler, Rational Software Architect etc.). Das in dieser Arbeit untersuchte AndroMDA ist ein Open Source Framework und wurde im März 2003 vorgestellt. Es benutzt zur Codetransformation aus UML-Modellen verschiedene, sogenannte Cartridges1. Mit diesen Cartridges verarbeitet AndroMDA Metamodell-Elemente die durch Stereotypen und Schlüsselwörtern, wie z.B. «Entity» oder «Service» gekennzeichnet werden und generiert daraus Codefragmente. AndroMDA unterstützt derzeit primär die Zielsprachen Java und C#/.NET. Die Codegenerierung wird über Templates gesteuert, so dass jede erdenklich Zielsprache (HTML, PHP etc.) damit realisiert werden kann.&lt;/p>
&lt;p>Ziel dieser Magisterarbeit ist es, das MDA Framework „AndroMDA“ anhand einer Beispielanwendung (Onlinebuchhandlung) zu evaluieren. Hierbei soll die Funktionsweise der einzelnen Komponenten, unterstützte Technologien sowie Stärken und Schwächen des Frameworks bezüglich Codegenerierung ermittelt werden. Aus diesen Ergebnissen soll im weiteren Verlauf der Arbeit die Codegenerierungsfunktionalität hinsichtlich möglichst vollständiger Codegenerierung optimiert werden.&lt;/p>
&lt;p>Als Grundlage dieser Untersuchungen, dient das Referenzbeispiel „Onlinebuchhandlung“. Zuerst soll die Anwendung der Onlinebücherei als UML Modell abgebildet und modelliert werden. Im weiteren Verlauf muss das UML Modell an die Erfordernisse AndroMDA’s so angepasst werden (Stereotypen), dass es als Input für die Codegenerierung (Cartridges) dienen kann. Anschließend werden die jeweiligen Codefragmente generiert. Danach soll die Codegenerierungsfunktionalität analysiert und Verbesserungspotential davon abgeleitet werden. Nach diesem Schritt werden ausgewählte Verbesserungsmöglichkeiten bezüglich der Vollständigkeit der Codegenerierung (z.B. mittels Entwicklung eigener oder erweiterte Cartridges) anhand der gleichen Referenzanwendung entwickelt und evaluiert.&lt;/p>
&lt;p> &lt;/p>
&lt;p>Download the
&lt;a href="https://www.big.tuwien.ac.at/app/uploads/2016/10/Karner_paper.pdf" target="_blank" rel="noopener">paper&lt;/a> and
&lt;a href="https://www.big.tuwien.ac.at/app/uploads/2016/10/Karner_poster.pdf" target="_blank" rel="noopener">poster&lt;/a>&lt;/p></description></item><item><title>SmartMatching in der Praxis - Evaluierung und Erweiterung eines Forschungsprototyps</title><link>https://big.tuwien.ac.at/master-thesis/archive/smartmatching-in-der-praxis-evaluierung-und-erweiterung-eines-forschungsprototyps/</link><pubDate>Tue, 19 May 2020 12:37:35 +0000</pubDate><guid>https://big.tuwien.ac.at/master-thesis/archive/smartmatching-in-der-praxis-evaluierung-und-erweiterung-eines-forschungsprototyps/</guid><description>&lt;p>This work has been finished in August 2009.&lt;/p>
&lt;p>In software projects most of the data is saved in a structured way to simplify the usage of it. These data structures are persisted in relational or XML (Extensible Markup Language) databases. In case of new software releases these data structures have to be modified to save new data or adapted data. The usage of a new technology often implies changes in the data structures as well. If changes are made on the data structure, in most of the cases the old data must be migrated to the new data structure to avoid data loss. This process, called information integration, is a time intensive job, and must be done by experts, who create the mapping rules manually and have to take care of the data structure limitations. With schema matching this process can be solved more efficient by schema matching tools build automatically the mapping rules which can be used to transform the data into a new data structure.&lt;/p>
&lt;p>SmartMatcher is a schema matching tool prototype, which has been developed at the Vienna University of Technology. This prototype generates mappings out of a source and target schema with their corresponding training instances. The latest release of the SmartMatcher contains a new internal data structure, which should allow more complex mapping operations in future. The effect of this new data structure regard-ing the quality of mappings has been evaluated in this work. Furthermore, a new feature has been integrated which allows to import existing mappings. With this fea-ture the SmartMatcher will be able to use results from other matching tools to im-prove them. In the past the SmartMatcher was limited to one training instance per schema. Thus, a further feature was implemented, called Multiple Samples. This allows more training instances to be used by the SmartMatcher, and improves the user experience by providing a better clarity of the training instances.&lt;/p>
&lt;p>Abstract and paper may be found in our &lt;a class="external" href="http://publik.tuwien.ac.at/showentry.php?ID=184543&amp;amp;lang=2">publication database&lt;/a>.&lt;/p>
&lt;p>Download the
&lt;a href="https://www.big.tuwien.ac.at/app/uploads/2016/10/Karall_posters.pdf" target="_blank" rel="noopener">poster&lt;/a>&lt;/p></description></item><item><title>Geschäftsprozessmanagement in der Vermögensverwaltung: Konzepte, Methoden und Werkzeuge anhand einer aktuellen Fallstudie</title><link>https://big.tuwien.ac.at/master-thesis/archive/geschftsprozessmanagement-in-der-vermgensverwaltung-konzepte-methoden-und-werkzeuge-anhand-einer-aktuellen-fallstudie/</link><pubDate>Tue, 19 May 2020 12:37:34 +0000</pubDate><guid>https://big.tuwien.ac.at/master-thesis/archive/geschftsprozessmanagement-in-der-vermgensverwaltung-konzepte-methoden-und-werkzeuge-anhand-einer-aktuellen-fallstudie/</guid><description>&lt;p>This work has been finished in November 2008.&lt;/p>
&lt;p>Ein wichtiges Thema, mit dem sich heutige Unternehmen auseinandersetzen müssen, ist die effiziente Bewältigung der sich ständig ändernden Anforderungen. Dies betrifft sowohl Kundenanforderungen, wie auc gesetzliche Rahmenbedingungen. Auch Vermögensverwaltungen sind davon nicht ausgenommen. Dies zeigen einerseits die Einführung des neuen WAGs 2007 (Wertpapieraufsichtsgesetz 2007) und andererseits die aktuellen Ereignisse am Finanzmarkt.&lt;/p>
&lt;p>Doch wie am Besten mit diesen Herausforderungen umgehen? Diese Arbeit untersucht deshalb, wie Geschäftsprozessmanagement dazu beitragen kann. Dazu werden zum einen die Aspekte von ganzheitlichem Geschäftsprozessmanagement im Allgemeinen betrachtet und zum anderen, anhand einer Fallstudie, Methoden aus dem Geschäftsprozessmanagement zur Erhebung der Ist-Prozesse angewendet. Anhand dieses Beispiels wird eine Prozesslandkarte mit den Kernprozessen präsentiert. Zusätzlich zur Detaildokumentation der Kernprozesse, werden diese zum Großteil auch mit BPMN (Business Process Modelling Notation) modelliert. Außerdem wird eine Gesamtbeurteilung der Kernprozesse im Bezug auf Verbesserungsmöglichkeiten abgegeben.&lt;/p>
&lt;p>Fazit ist, dass kontinuierliches Geschäftsprozessmangement für Unternehmen eine Möglichkeit ist, sich rechtzeitig den Veränderungen anzupassen. Eine reine Dokumentation der Prozesse bedeutet aber noch nicht, dass Geschäftsprozessmanagement effizient eingesetzt wird.&lt;/p>
&lt;p> &lt;/p>
&lt;p>Download the
&lt;a href="https://www.big.tuwien.ac.at/app/uploads/2016/10/Horner_Stockinger_poster.pdf" target="_blank" rel="noopener">poster&lt;/a>&lt;/p></description></item><item><title>How to Efficiently Collaborate in Model Versioning: A Guideline to Reduce and Resolve Conflicts</title><link>https://big.tuwien.ac.at/master-thesis/archive/how-to-efficiently-collaborate-in-model-versioning-a-guideline-to-reduce-and-resolve-conflicts/</link><pubDate>Tue, 19 May 2020 12:37:34 +0000</pubDate><guid>https://big.tuwien.ac.at/master-thesis/archive/how-to-efficiently-collaborate-in-model-versioning-a-guideline-to-reduce-and-resolve-conflicts/</guid><description>&lt;p>This work has been finished in August 2010.&lt;/p>
&lt;p>Abstract and paper may be found in our &lt;a class="external" href="http://publik.tuwien.ac.at/showentry.php?ID=187690&amp;amp;lang=2">publication database&lt;/a>.&lt;/p>
&lt;p>Download the
&lt;a href="https://www.big.tuwien.ac.at/app/uploads/2016/10/Kapellner_poster.pdf" target="_blank" rel="noopener">poster&lt;/a>&lt;/p></description></item><item><title>The Model Transformation Language Jungle - An Evaluation and Extension of Existing Approaches</title><link>https://big.tuwien.ac.at/master-thesis/archive/the-model-transformation-language-jungle-an-evaluation-and-extension-of-existing-approaches/</link><pubDate>Tue, 19 May 2020 12:37:34 +0000</pubDate><guid>https://big.tuwien.ac.at/master-thesis/archive/the-model-transformation-language-jungle-an-evaluation-and-extension-of-existing-approaches/</guid><description>&lt;p>This work has been finished in May 2008.&lt;/p>
&lt;p>Model Transformations are a key-prerequisite for Model Driven Engineering and therefore represent an active research area. Many model transformation languages are available, whereas the languages can be categorized into different approaches. Depending on the particular situation, one model transformation approach might be better suited to accomplish the given task than another approach. Classifications of model transformation languages exist, which also includes a taxonomy of general features a model transformation language may support. Based on this taxonomy, it is possible to compare model transformation approaches in order to find out how suitable they are for a given problem. Like in common object oriented programming approaches, such as Java, there are some particular problems which appear repeatedly. For example, it is often necessary to transform an attribute value in the source model to an object in the target model. For such cases, it should be considered to solve these problems in a generic way. In addition, the generic solutions can be reused in other model transformations.&lt;/p>
&lt;p>In this thesis, four model transformation languages, namely ATL, SmartQVT, Kermeta and Triple Graph Grammars (TGG) (using MOFLON as transformation tool) are evaluated based on the taxonomy proposed by Czarnecki et al. These languages are chosen, because the represent the state of the art in model transformation. ATL and SmartQVT are hybrid (a mixture of declarative and imperative) languages. More specifically, SmartQVT implements the „operational“ part of the OMG QVT standard. Kermeta acts as example for an imperative language, whereas TTGs represent a declarative approach with a graphical syntax.&lt;/p>
&lt;p>For the purpose of conducting the evaluation, several model transformation examples are defined and implemented using the languages mentioned above. These examples cover model transformation problems appearing in practice, in order to emphasize the advantages and limitations of the particular language. In the second part of this thesis, Kermeta is used to implement a library which solves common problems appearing in model transformations. This library can then be used in practical transformations for simplifying the development process. Finally, the results of the evaluation are interpreted and discussed, in order to propose guidelines on which model transformation approaches are suitable for which problems.&lt;/p>
&lt;p>Krzysztof Czarnecki and Simon Helsen. Classification of model transformation approaches. OOPSLA’03 Workshop on Generative Techniques in the Context of Model-Driven Architecture, 2003.&lt;/p>
&lt;p> &lt;/p>
&lt;p>Download the
&lt;a href="https://www.big.tuwien.ac.at/app/uploads/2016/10/Huber_paper.pdf" target="_blank" rel="noopener">paper&lt;/a> and
&lt;a href="https://www.big.tuwien.ac.at/app/uploads/2016/10/Huber_poster.pdf" target="_blank" rel="noopener">poster&lt;/a>&lt;/p></description></item><item><title>Die Divergenz von Studieninhalten - eine vergleichende Analyse von Curricula der Wirtschaftsinformatik</title><link>https://big.tuwien.ac.at/master-thesis/archive/die-divergenz-von-studieninhalten-eine-vergleichende-analyse-von-curricula-der-wirtschaftsinformatik/</link><pubDate>Tue, 19 May 2020 12:37:33 +0000</pubDate><guid>https://big.tuwien.ac.at/master-thesis/archive/die-divergenz-von-studieninhalten-eine-vergleichende-analyse-von-curricula-der-wirtschaftsinformatik/</guid><description>&lt;p>This work has been finished in October 2014.&lt;/p>
&lt;p>Die vielfältigen Gestaltungsmöglichkeiten, die zahlreichen Studienangebote für Wirtschaftsinformatik und die rasche ständige Weiterentwicklung, insbesondere in der Informatik, und die mit der zunehmenden Universitätsautonomie notwendige Positionierung im Wettbewerb, legen einen Vergleich von Lehrinhalten im Sinne eines Benchmarkings nahe. In der geplanten Arbeit soll daher primär der Frage, inwieweit sich Lehrinhalte des Studiums Wirtschaftsinformatik an der Technischen Universität von Studienplaninhalten anderer ausgewählter Universitäten unterscheiden, nachgegangen werden. Vorab muss allerdings geklärt werden, welche Kategorien/Inhalte überhaupt verglichen werden können, wodurch sich zusätzlich Fragen nach der Unterschiedlichkeit im Studienaufbau ergeben.&lt;/p>
&lt;p>Abstract and paper may be found in our &lt;a class="external" href="http://publik.tuwien.ac.at/showentry.php?ID=247866&amp;amp;lang=2">publication database&lt;/a>.&lt;/p></description></item><item><title>Modellgetriebene Entwicklung von Webanwendungen aus Anforderungsspezifikationen</title><link>https://big.tuwien.ac.at/master-thesis/archive/modellgetriebene-entwicklung-von-webanwendungen-aus-anforderungsspezifikationen/</link><pubDate>Tue, 19 May 2020 12:37:33 +0000</pubDate><guid>https://big.tuwien.ac.at/master-thesis/archive/modellgetriebene-entwicklung-von-webanwendungen-aus-anforderungsspezifikationen/</guid><description>&lt;p>This work has been finished in December 2007.&lt;/p>
&lt;p>Betrachtet man den Trend der vergangenen Jahre, so ist die modellgetriebene Softwareentwicklung, kurz MDSD, der nächste logische Schritt in der Anwendungsentwicklung. Die leichte Verständlichkeit und die rasche Anpassung an wechselnde Implementierungstechnologien werden als großer Vorteil von MDSD gesehen.&lt;/p>
&lt;p>In derzeitigen Softwareentwicklungsprozessen trifft man bei der Entwicklung von Anwendungen auf eine Vielzahl von Problemen. Die Dominierung von Fachlichkeit durch Technik, die Divergenz der Änderungszyklen und der methodische Bruch zwischen Analyse, Design und Implementierung sind einige nennenswerte Beispiele. Der modellgetriebene Ansatz versucht diese Probleme zu vermindern, indem er die ohnehin für die Entwicklung notwendigen Softwaremodelle als Sourcecode behandelt.&lt;/p>
&lt;p>Diese Arbeit zeigt eine mögliche Lösung dieser Probleme durch die Verwendung eines modellgetriebenen Ansatzes. Das Ziel ist es, eine modellgetriebene Entwicklungsumgebung für Modellierung und Generierung von Webanwendungen auf Basis des JBoss Seam Frameworks, welches gängige Java-Technologien miteinander kombiniert, anzubieten.&lt;/p>
&lt;p>Neben der Generierung der benötigten Backend-Datein aus UML 2.0 Strukturdiagrammen wird weiters die Generierung einer prototypischen Benutzeroberfläche aus UML Verhaltensdiagrammen gezeigt. Diese kann für Tests und als Ausgangsbasis für das Design der Webanwendung herangezogen werden. Neben dem Frontend und dem Backend der Anwendung wird auch der Qualitäts-Aspekt in der Arbeit behandelt. Hierbei werden Möglichkeiten gezeigt, wie Testinformationen aus den Modellen gewonnen werden können. Dies soll den Bereich der Softwarequalitätssicherung abdecken und den effektiven Testaufwand in einer realen Entwicklung reduzieren. Als Referenzanwendung dient ein Web-DVD-Shop, der für die Erstellung der Generatoren und Modelle herangezogen wird. Anhand dieser Referenzanwendung wird auch der derzeitige Automatisationsgrad durch MDSD besprochen.&lt;/p>
&lt;p> &lt;/p>
&lt;p>Download the
&lt;a href="https://www.big.tuwien.ac.at/app/uploads/2016/10/Hiebler_paper.pdf" target="_blank" rel="noopener">paper&lt;/a> and
&lt;a href="https://www.big.tuwien.ac.at/app/uploads/2016/10/Hiebler_poster.pdf" target="_blank" rel="noopener">poster&lt;/a>&lt;/p></description></item><item><title>A Comparison of Open Source ERP Systems</title><link>https://big.tuwien.ac.at/master-thesis/archive/a-comparison-of-open-source-erp-systems/</link><pubDate>Tue, 19 May 2020 12:37:32 +0000</pubDate><guid>https://big.tuwien.ac.at/master-thesis/archive/a-comparison-of-open-source-erp-systems/</guid><description>&lt;p>This work has been finished in June 2006.&lt;/p>
&lt;p>Open source ERP systems are often targeted to enterprises whose requirements are not covered by standard software. Similar circumstances apply to organizations that need continuous adaption of the software to changing processes and needs. In this work the suitability of current open source ERP systems for these enterprises will be examined.&lt;/p>
&lt;p>It provides sufficient information for a small or medium enterprise to choose a flexible and adaptable open source ERP system. Starting from the question which opportunities a company has to support its processes with IT, the advantages of flexible systems are elaborated. Besides the focus on flexibility, open source specific criteria for support, continuity and maturity are worked out. Then selected open source ERP projects are reviewed and classified according to these criteria. The results are a criteria catalog and a classification of selected open source ERP systems.&lt;/p>
&lt;p> &lt;/p>
&lt;p>Download the
&lt;a href="https://www.big.tuwien.ac.at/app/uploads/2016/10/Herzog_paper.pdf" target="_blank" rel="noopener">paper&lt;/a>&lt;/p></description></item><item><title>Entwicklung eines webbasierten Institutsinformationssystems unter besonderer Berücksichtigung des Multi Delivery</title><link>https://big.tuwien.ac.at/master-thesis/archive/entwicklung-eines-webbasierten-institutsinformationssystems-unter-besonderer-bercksichtigung-des-multi-delivery/</link><pubDate>Tue, 19 May 2020 12:37:32 +0000</pubDate><guid>https://big.tuwien.ac.at/master-thesis/archive/entwicklung-eines-webbasierten-institutsinformationssystems-unter-besonderer-bercksichtigung-des-multi-delivery/</guid><description>&lt;p>This work has been finished in November 2004.&lt;/p>
&lt;p>Im Rahmen einer Kooperation von drei Diplomarbeiten (Alexander Heumayer, Nenad Jovanovic und Andrea Schauerhuber) wurde mit Hilfe des Open-Source-Produkts LAMP (der Kombination aus dem Betriebssystem Linux, dem Webserver Apache, dem Datenbank-Managementsystem MySQL und der Programmiersprache PHP) ein für die Arbeitsgruppe Business Informatics (Institut für Softwaretechnik und Interaktive Systeme, TU Wien) maßgeschneidertes Web-Informationssystem entwickelt. Neben der Entwicklung dieses gemeinsamen Teils fand eine individuelle Spezialisierung in unterschiedlichen Bereichen statt.&lt;/p>
&lt;p>Die vorliegende schriftliche Ausarbeitung befaßt sich ausschließlich mit der Thematik des Spezialgebiets, den Aspekten des Multi Delivery. Die Konzentration auf die Gerätegattung Mobiltelefon schränkt das weitläufige Forschungsfeld auf eine Teilmenge ein. Die hohe Marktdurchdringung, die ständige Präsenz im Alltag und der Trend, Maschinen mit einer möglichst umfangreichen Funktionalität auszustatten, heben das große Potential von den sogenannten Handys als Informationsträger hervor. Das Marketingkonzept der Herstellerfirmen, die einzelnen Produkte in ihren Eigenschaften deutlich voneinander abzugrenzen, führt dabei zu einer extremen Artenvielfalt.&lt;/p>
&lt;p>Die Diplomarbeit beleuchtet folglich die Möglichkeiten, eine Anwendung an die technischen Gegebenheiten eines Endgeräts anzupassen. Dazu werden in einem ersten Schritt jene Quellen untersucht, die Informationen über die entsprechenden Charakteristika der Mobiltelefone enthalten. Im weiteren Verlauf zeigt ein Vergleich die Güte jener Werkzeuge auf, die zur automatischen Adaption der darzustellenden Inhalte dienen.&lt;/p>
&lt;p>Letztlich veranschaulicht die eigenständige Entwicklung einer WAP-Schnittstelle (Wireless Application Protocol) für das Web-Informationssystem einen möglichen Ansatz zur Bewältigung der Aufgabenstellung. Mit Hilfe des angewendeten Verfahrens, WML-Dateien (Wireless Markup Language) mittels der Programmiersprache PHP (PHP Hypertext Preprocessor) dynamisch zu erzeugen, werden Lösungen für die zentralen Problembereiche des mobilen Telefons, wie beispielsweise die eingeschränkte Bildschirmgröße und die geringe Speicherkapazität, angeboten. Die Gestaltung des Layouts orientiert sich dabei an Richtlinien und empirischen Untersuchungen zur Thematik der Benutzerfreundlichkeit.&lt;/p>
&lt;p>Neben diesem Kerngebiet beinhaltet die Diplomarbeit Instruktionen zur Realisierung eines SMS-Versands (Short Message Service) und zur Erzeugung von PDF-Dateien (Portable Document Format).&lt;/p>
&lt;p> &lt;/p>
&lt;p>Download the
&lt;a href="https://www.big.tuwien.ac.at/app/uploads/2016/10/Heumayer_paper.pdf" target="_blank" rel="noopener">paper&lt;/a>&lt;/p></description></item><item><title>Synchronous Collaborative Modeling for the Eclipse Modeling Framework</title><link>https://big.tuwien.ac.at/master-thesis/archive/synchronous-collaborative-modeling-for-the-eclipse-modeling-framework/</link><pubDate>Tue, 19 May 2020 12:37:32 +0000</pubDate><guid>https://big.tuwien.ac.at/master-thesis/archive/synchronous-collaborative-modeling-for-the-eclipse-modeling-framework/</guid><description>&lt;p>This work has been finished in July 2011.&lt;/p>
&lt;p>The high complexity of modern software makes it unavoidable to develop software with the help of graphical, model based editors. Software models serve not only as documentation or as a rough system overview. They are also the fundament to generate an executable system.&lt;/p>
&lt;p>The larger the application the more persons are involved in the design and development process. Simultaneous changes on a model are very common. With these concurrent changes conflicts can occur.&lt;/p>
&lt;p>There is a need of interpersonal communication to solve appearing questions and avoid misunderstandings. Specially in the early stage of software development diversities in interpretation may occur because the semantics of models may be interpreted differently. To avoid such problems the communication channels within the team should be supported as much as possible. With good communication it should be possible to achieve a consolidated solution of the problem in a collaborative way.&lt;/p>
&lt;p>Within this thesis ways and means are sought to enable interactive model-driven software development with the Eclipse Modeling Framework. It turned out that there are already several approaches for this interactive development method.&lt;/p>
&lt;p>These budding candidates where reviewed and analyzed. Unfortunately each of the tested systems had some disadvantages or they were not mainly designed for model-driven software development. Using them for serious software development would not have been possible.&lt;/p>
&lt;p>As soon as the analysis of various existing approaches was finished a list of requirements has been created. The search for a tool that matches the requirements as good as possible and that can be extended easily was started and finished with an acceptable result.&lt;/p>
&lt;p>Therefore the implementation part consists of an extension of a existing tool. The chosen tool is CDO, ”Connected Data Objects“, a plugin for Eclipse. CDO was selected because it is the best match to our requirements and is supported by a very competent development team. We think we found the optimal candidate to develop a sustainable solution.&lt;/p>
&lt;p>Within this thesis we developed a functionality that enables the user to merge two branches of the versioning system, CDO.&lt;/p>
&lt;p>Abstract and paper may be found in our &lt;a class="external" href="http://publik.tuwien.ac.at/showentry.php?ID=199046&amp;amp;lang=2">publication database&lt;/a>.&lt;/p>
&lt;p>Download the
&lt;a href="https://www.big.tuwien.ac.at/app/uploads/2016/10/Halemtschlager_poster.pdf" target="_blank" rel="noopener">poster&lt;/a>&lt;/p></description></item><item><title>Business Model Driven ERP Customization</title><link>https://big.tuwien.ac.at/master-thesis/archive/business-model-driven-erp-customization/</link><pubDate>Tue, 19 May 2020 12:37:31 +0000</pubDate><guid>https://big.tuwien.ac.at/master-thesis/archive/business-model-driven-erp-customization/</guid><description>&lt;p>This work has been finished in January 2014.&lt;/p>
&lt;p>Enterprise Resource Planning (ERP) systems encompass the administration of all resources that are needed for companies to run their business. They support several functional areas, like accounting, manufacturing, and sales in form of modules that are integrated by a single database where all business relevant information is stored. In order to guarantee a flawless and productive use of the system, the economic phenomena underlying the business of the company need to be reflected in the user interface as well as the data structure itself. Usually ERP-systems are purchased by customers from vendors in form of standard software. Such software supports a predefined set of functionality and has to be further customized to the specific needs of an enterprise, which is not a trivial task and often leads to additional costs. Furthermore standard software only supports specific processes that are based on best-practice assumptions of the vendors. Therefore adjusting ERP-systems to changed market demands is hard, since they are missing a business semantic base. Often changed business needs can only be represented by drastic changes in the data structure or the code which can lead to inconsistencies.&lt;/p>
&lt;p>The REAlist project uses a model-driven approach to overcome the aforementioned problems with existing ERP-systems, and enhance their adaptability. Business needs can be represented in an easy and unambiguous way in the form of business models. REAlist uses the Resource-Event-Agent (REA) ontology as business modeling language, since it was initially proposed to support IT-system implementations and is related to data modeling. REA allows the specification of events that have happened or are happening in the near future, resources affected by the events, and agents participating in them. Furthermore policies and commitments can be defined, which are both important concepts for ERP-systems. The underlying database of the REAlist project (REA-DB) is based on REA. Its data structure is generic, meaning that changed business needs (defined with REA concepts) can be saved without changing it. Instead of using the classic class-diagram-like representation of REA, a domain specific language (REA-DSL) is used to simplify the creation of REA business models.&lt;/p>
&lt;p>The aim of this thesis is to undertake the first steps of the REAlist project and create a mapping from REA-DSL business models to the generic REA-DB. Furthermore user interfaces are (semi-)automatically generated based on the saved models during runtime to reduce the effort that is needed during the customization tasks in existing ERP-systems.&lt;/p>
&lt;p> &lt;/p>
&lt;p>Download the
&lt;a href="https://www.big.tuwien.ac.at/app/uploads/2016/10/G%c3%bcrth_paper.pdf" target="_blank" rel="noopener">paper&lt;/a> and
&lt;a href="https://www.big.tuwien.ac.at/app/uploads/2016/10/G%c3%bcrth_poster.pdf" target="_blank" rel="noopener">poster&lt;/a>&lt;/p></description></item><item><title>Design and Conception of an ERP System for SMEs</title><link>https://big.tuwien.ac.at/master-thesis/archive/design-and-conception-of-an-erp-system-for-smes/</link><pubDate>Tue, 19 May 2020 12:37:31 +0000</pubDate><guid>https://big.tuwien.ac.at/master-thesis/archive/design-and-conception-of-an-erp-system-for-smes/</guid><description>&lt;p>This work has been finished in May 2012.&lt;/p>
&lt;p>In today’s business world, enterprise resource planning (ERP) systems are essential for larger enterprises to conduct their business. ERP solutions fulfill several tasks in companies, including the management of resources, sales, warehouse, employees, and accounting. Since even small and medium enterprises (SMEs) can gain profits using them, ERP solutions especially for those are developed. The main difference between them is the reduced complexity of ERP software for SMEs. Since about 98% of all Austrian companies have less than 50 employees, the market for appropriate ERP systems is large. Those statistics also apply to the entire European Union. Many SMEs do not work with an ERP system yet, but instead use Microsoft Excel and send business documents via email.&lt;/p>
&lt;p>Another reason for a basic ERP system is that e-Invoicing is becoming more and more essential for SMEs. Larger enterprises are already using e-Invoicing for many years, but smaller enterprises lack the technical requirements. Most electronic data interchange (EDI) standards are too complex and the software is too expensive. Therefore a cheap and easy to use approach for SMEs to exchange business documents is desirable. The Vienna University of Technology project „E-business Registry Permitting Enterprise Liaisons“ (ERPEL) fulfills those requirements. The main purpose of ERPEL is both to enable business clients to search for companies and their products and services and to facilitate the transmission of documents (like invoices, offers, quotes,…) between different ERP systems. In order to motivate even small companies without any ERP system in use to partake, a basic ERP system is needed. A self-made solution is built especially including messaging, instead of adopting an existing open source ERP system.&lt;/p>
&lt;p>Hence, if a new ERP solution for SMEs should be developed, it is beneficial to use and analyze best practices. Those are figured out by comparing existing ERP systems for SMEs. Messaging functionalities (exchange of business documents) are the key to success. Therefore they should be considered in the whole design process.&lt;/p>
&lt;p>All basic features are described shortly, together with the way they are implemented in different ERP solutions. The focus lies on sale and warehouse management functionalities, due to the requirements of the research project ERPEL. Other features are examined as well, but not in detail. The final artifacts are among other things wireframes, showing the functional requirements for a basic ERP system. The goal is to design a widespread ERP adoption for SMEs, supporting seamless communication between different enterprises.&lt;/p>
&lt;p> &lt;/p></description></item><item><title>Automatisiertes White-box Testen von Regel-basierten Modelltransformationen</title><link>https://big.tuwien.ac.at/master-thesis/archive/automatisiertes-white-box-testen-von-regel-basierten-modelltransformationen/</link><pubDate>Tue, 19 May 2020 12:37:30 +0000</pubDate><guid>https://big.tuwien.ac.at/master-thesis/archive/automatisiertes-white-box-testen-von-regel-basierten-modelltransformationen/</guid><description>&lt;p>This work has been finished in September 2013.&lt;/p>
&lt;p>Seit mehreren Jahren ist die modellgetriebene Softwareentwicklung (englisch: Model Driven Engineering (MDE) beziehungsweise Model Driven Software Development (MDSD)) auf dem Vormarsch und Softwaremodelle werden nicht mehr nur für Entwurfszwecke genutzt, sondern sind ein Hauptelement im Software Engineering Prozess geworden. Modellierungssprachen wurden entwickelt um Modelle darzustellen, die eine Basis für die weitere Entwicklung bilden. Die bekannteste Modellierungssprache ist Unified Modeling Language (UML), ein Standard der Object Management Group (OMG). In diesem Zusammenhang stehen auch Ecore Metamodelle, welche der Hauptbestandteil von Eclipse Modeling Framework (EMF) sind und als vereinfachte UML Klassendiagramme gesehen werden können. Neben den Modellierungssprachen spielen in der modellgetriebenen Softwareentwicklung auch Modelltransformationen eine entscheidende Rolle. Das Ziel einer Modelltransformation ist ein bestimmtes Quellmodell in ein gewünschtes Zielmodell zu transformieren. Eine der bekanntesten regelbasierten Modelltransformationssprachen ist die Atlas Transformation Language (ATL). Oftmals schlagen Transformationen fehl und die Fehlererkennung ist mühsam und langwierig, da diese in der Transformation selbst oder in den Metamodellen liegen können. Ziel dieser Arbeit ist es einen automatisierten Ablauf zu finden, der regelbasierte Transformationen testen kann. Dabei soll ein Tool in Java entwickelt werden, welches auf der Metamodellierungssprache Ecore und regelbasierten Modelltransformationen in ATL aufbaut. Hierbei beschäftigt sich die Diplomarbeit mit mehreren Fragen. Ist es möglich einen White Box Test Ansatz für ATL Transformationen zu finden? Wie können Modelle(Testinstanzen) aus einem Metamodell automatisch generiert werden? Wie hoch ist die Fehlererkennungsrate? Welche Art von Fehlern können bei den Transformationen festgestellt werden? In dieser Arbeit werden zuerst die nötigen Grundlagen wie zum Beispiel Answer Set Programming (ASP) und Testen im Allgemeinen erläutert. Anschließend wird auf die konkrete Implementierung eines möglichen Ansatzes eingegangen. Abschließend wird die Evaluierung des entwickelten Tools anhand der vorhandenen Übungsaufgaben zum Thema Modelltransformationen aus der Lehrveranstaltung “Model Engineering” der Technischen Universität Wien der Jahre 2008 bis 2012 präsentiert und ein Ausblick für weitere Möglichkeiten gegeben.&lt;/p>
&lt;p> &lt;/p></description></item><item><title>Formalization of the Operation Recorder based on Graph Transformation Theory</title><link>https://big.tuwien.ac.at/master-thesis/archive/formalization-of-the-operation-recorder-based-on-graph-transformation-theory/</link><pubDate>Tue, 19 May 2020 12:37:30 +0000</pubDate><guid>https://big.tuwien.ac.at/master-thesis/archive/formalization-of-the-operation-recorder-based-on-graph-transformation-theory/</guid><description>&lt;p>This work has been finished in April 2011.&lt;/p>
&lt;p>Software engineering has come a long way in its short history. With the recent advent of modeldriven development, which places models at the center of all development efforts, some of the existing deficiencies of traditional, code-centric software development approaches have been addressed. However, at the same time new problems arose, which require, for example, techniques to describe, control and verify the evolution of models. Drawing from past experiences and findings in the field of code-centric software evolution is only partly feasible due to the inherent graph-based nature of models, which renders the adoption and porting of previously developed solutions for text-based software development impractical.&lt;/p>
&lt;p>The graph-based nature of models suggests the application of graph transformation-theoretic concepts to models, in order to formally describe their manipulation by means of graph-rewriting rules. Though the concepts and techniques provided by the theory of graph transformation may seem intuitive, the specification of accurate rewriting rules is a non-trivial and time-consuming task, which requires adequate tool support and thorough knowledge of the underlying theory. Unfortunately, due to the heterogeneity of the employed approaches, a tool’s capability to specify graph rewriting rules and the degree of assistance offered for this task is hard to determine without prior investigation. Thus, a survey of existing tools was conducted, which revealed the Operation Recorder as a suitable tooling environment. In contrast to all other surveyed tools, it offers a by-demonstration environment, which allows to showcase the intended transformation instead of requiring its manual construction by means of dedicated transformation languages.&lt;/p>
&lt;p>The Operation Recorder, however, lacks a concise, formal basis which prevents the verification of its ransformations. Therefore, a framework to describe attributed graphs with inheritance, composition and multiplicities is presented with the aim to embed the Operation Recorder into this framework. For this purpose, a conceptual alignment is pursued which demonstrates the equivalence and interchangeability of the concepts provided by the Operation Recorder and those provided by the theory of graph transformation.&lt;/p>
&lt;p>Abstract and paper may be found in our &lt;a class="external" href="http://publik.tuwien.ac.at/showentry.php?ID=196648&amp;amp;lang=2">publication database&lt;/a>.&lt;/p>
&lt;p>Download the
&lt;a href="https://www.big.tuwien.ac.at/app/uploads/2016/10/Gabmeyer_poster.pdf" target="_blank" rel="noopener">poster&lt;/a>&lt;/p></description></item><item><title>Refactoring Support for ATL-based Model Transformations</title><link>https://big.tuwien.ac.at/master-thesis/archive/refactoring-support-for-atl-based-model-transformations/</link><pubDate>Tue, 19 May 2020 12:37:30 +0000</pubDate><guid>https://big.tuwien.ac.at/master-thesis/archive/refactoring-support-for-atl-based-model-transformations/</guid><description>&lt;p>This work has been finished in February 2012.&lt;/p>
&lt;p>Abstract and paper may be found in our &lt;a class="external" href="http://publik.tuwien.ac.at/showentry.php?ID=207245&amp;amp;lang=2">publication database&lt;/a>.&lt;/p></description></item><item><title>Code Generation with fUML</title><link>https://big.tuwien.ac.at/master-thesis/archive/code-generation-with-fuml/</link><pubDate>Tue, 19 May 2020 12:37:29 +0000</pubDate><guid>https://big.tuwien.ac.at/master-thesis/archive/code-generation-with-fuml/</guid><description/></item><item><title>Web-Transaktionen: Erweiterung der WS-BusinessActivity-Spezifikation um WS-BusinessActivity–Initiator und Implementierung der beiden Protokolle im Open Source-Projekt Apache Kandula</title><link>https://big.tuwien.ac.at/master-thesis/archive/web-transaktionen-erweiterung-der-ws-businessactivity-spezifikation-um-ws-businessactivity-initiator-und-implementierung-der-beiden-protokolle-im-open-source-projekt-apache-kandula/</link><pubDate>Tue, 19 May 2020 12:37:29 +0000</pubDate><guid>https://big.tuwien.ac.at/master-thesis/archive/web-transaktionen-erweiterung-der-ws-businessactivity-spezifikation-um-ws-businessactivity-initiator-und-implementierung-der-beiden-protokolle-im-open-source-projekt-apache-kandula/</guid><description>&lt;p>This work has been finished in April 2007.&lt;/p>
&lt;p>Derzeit ist der Trend bemerkbar, dass Unternehmen ihre Geschäftsprozesse in IT-Systemen abbilden und ihre internen Abläufe mit Hilfe von Geschäftsprozess-Engines koordinieren und teilweise automatisieren. Bisher waren Automatismen auf Berechnungen mit bereits vorhandenen Daten beschränkt oder auf aufwändig und individuell angepassten Schnittstellen zu anderen Systemen angewiesen.&lt;/p>
&lt;p>Web Services ermöglichen die einfache, weltweite Vernetzung von Computerprogrammen über das Internet und damit auch die Einbindung von Diensten, die Geschäfspartner betreiben. Um über diese Schnittstellen auch tatsächliches „business“ betreiben zu können, ist es erforderlich dass die beteiligten Computerprogramme Protokolle verwenden, die eine einheitliche Sicht beider Geschäftspartner auf die gemeinsamen Aktivitäten sicherstellen. In der vorliegenden Arbeit wird die WS-Transaction–Protokollfamilie analysiert und eine Implementierung des WS-BusinessActivity (WS-BA)–Protokolls vorgestellt. Diese umfasst sowohl einen Coordinator für WS-BA–Transaktionen als auch Client-Bibliotheken für das Benutzen des Koordinators und zum Entwickeln WS-BA–fähiger Web Services. Die Einsatzfähigkeit des implementierten WS-BA–Protokolls wird im Rahmen einer Demoapplikation gezeigt.&lt;/p>
&lt;p> &lt;/p>
&lt;p>Download the
&lt;a href="https://www.big.tuwien.ac.at/app/uploads/2016/10/Erven_Hicker_paper.pdf" target="_blank" rel="noopener">paper&lt;/a> and
&lt;a href="https://www.big.tuwien.ac.at/app/uploads/2016/10/Erven_Hicker_poster.pdf" target="_blank" rel="noopener">poster&lt;/a>&lt;/p></description></item><item><title>From Modeling Languages to Query Languages: A Generative Approach</title><link>https://big.tuwien.ac.at/master-thesis/archive/from-modeling-languages-to-query-languages-a-generative-approach/</link><pubDate>Tue, 19 May 2020 12:37:28 +0000</pubDate><guid>https://big.tuwien.ac.at/master-thesis/archive/from-modeling-languages-to-query-languages-a-generative-approach/</guid><description>&lt;p>Domain experts often use Domain Specific Languages (DSL) for creating their models. They prefer DSLs over General Purpose Languages (GPL) for the following reasons.&lt;br>
Firstly, DSLs are computer languages that are designed to be only used in a particular area of application and to meet as many needs of domain experts of this area as possible.&lt;br>
In contrast, GPLs are meant to be used in various domains and are therefore not tailored towards particular areas of application. Hence, domain experts can be confronted with modelling problems that are easily solvable by the means of DSLs but hardly via GPLs.&lt;br>
Secondly, domain experts may lack IT-training and can therefore be overwhelmed by the task of learning a particular GPL. They will use a DSL instead, which can be much easier to learn and to apply in the particular modelling domain.&lt;br>
Despite of the benefits, the use of a DSL can also lead to some difficulties. Domain Experts need to query their models for all sorts of data.&lt;br>
In order to query a model that was designed in a DSL one needs to use a more general query language, which is not perfectly suited to the considered domain and may not be capable to express everything that is necessary.&lt;br>
The possibility to have a query language that is already based on the characteristics of the corresponding DSL-model and does not require excessive training of their modellers would be of great use.&lt;br>
The aim of this work is to provide a DSL-based query engine, more precisely an EMF-based tool for querying models that are designed in the DSL AutomationML.&lt;br>
A transformation engine will be developed, which will handle the generation of the query language’s meta-model based on AutomationML’s meta-model.&lt;br>
Afterwards an engine based on VIATRA will be developed to process the queries that were designed in the generated query language.&lt;br>
The resulting query engine will be evaluated in terms of efficiency (average query-length,intuitiveness,execution time,…) and effectiveness (amount of supported functions).&lt;/p></description></item><item><title>Hot Code Reload for QML Applications</title><link>https://big.tuwien.ac.at/master-thesis/archive/hot-code-reload-for-qml-applications/</link><pubDate>Tue, 19 May 2020 12:37:28 +0000</pubDate><guid>https://big.tuwien.ac.at/master-thesis/archive/hot-code-reload-for-qml-applications/</guid><description/></item><item><title>Java Transformation Library (jTL)</title><link>https://big.tuwien.ac.at/master-thesis/archive/java-transformation-library-jtl/</link><pubDate>Tue, 19 May 2020 12:37:28 +0000</pubDate><guid>https://big.tuwien.ac.at/master-thesis/archive/java-transformation-library-jtl/</guid><description>&lt;p>This work has been finished in October 2014.&lt;/p>
&lt;p>Transformation is an important field of software migration and modernization. Although transformation is the purest form of migration, because the conversion takes place in a 1:1 form, there are also some strong arguments why a transformation could face a lot of difficulties and challenges. The superior problem is that a transformation, regardless of whether code, model or data has to be transformed, is only as good as the tool and the underlying transformation library is. So there are many challenges to overcome, like the deep understanding of the source and target technology, the mostly very complex task of the mapping between them, as well as the financial effort. This master thesis focuses on the architecture and techniques of a source code transformation with Java. Based on an simple transformation Library called SiTra and an already existing PL/1/Cobol to Java Transformer, improvement especially by adding new Java 8 features and adaption to the architecture, should lead to a better performance of the transformation and a better readability and maintainability of transformation code. The findings should result in a library called Java Transformation Library (jTL).&lt;/p>
&lt;p>To test and demonstrate parts of the jTL, a transformation of PL/I source code to Java source code should serve as examples. There is also a special interest in transforming legacy code to state-of-the-art programming language, since the challenge of migrating over decades growing legacy software application is a well-known problem since many years in industry. A well-designed transformation can be the answer to this problem or at least can act as a main element of source code migration.&lt;/p>
&lt;p>Abstract and paper may be found in our &lt;a class="external" href="http://publik.tuwien.ac.at/showentry.php?ID=247865&amp;amp;lang=2">publication database&lt;/a>.&lt;/p></description></item><item><title>Implementation of a semantic app on a mobile device</title><link>https://big.tuwien.ac.at/master-thesis/archive/implementation-of-a-semantic-app-on-a-mobile-device/</link><pubDate>Tue, 19 May 2020 12:37:27 +0000</pubDate><guid>https://big.tuwien.ac.at/master-thesis/archive/implementation-of-a-semantic-app-on-a-mobile-device/</guid><description>&lt;p>This work has been finished in April 2016.&lt;/p>
&lt;p>The aim of this work is to implement a prototype of an android app in domain of food, which al- lows the user to take a photo of the restaurant menu he/she is interested in, which textual content is translated from the original language into the language of the user. This result will be returned embedded in original photo as a display output. For this purpose there are already available the core technologies Optical Character Recognition (OCR) and Machine Translation (MT). Their integration in the mobile sector would be a new developing domain within which there are not so many apps on the market.&lt;/p>
&lt;p>The bridge to the semantic technologies will be the second part of the work, coming out to the part while receiving extracted text. The text will be not only translated, but also semantically enriched by the information and pictures, so that a user can find out more about the content text. Another type of information the user gets, is the nutrition description of the food and their category in sense of vegetarian, vegan, etc.&lt;/p>
&lt;p> &lt;/p></description></item><item><title>Supporting Metamodel and Model Extensions in RubyTL</title><link>https://big.tuwien.ac.at/master-thesis/archive/supporting-metamodel-and-model-extensions-in-rubytl/</link><pubDate>Tue, 19 May 2020 12:37:27 +0000</pubDate><guid>https://big.tuwien.ac.at/master-thesis/archive/supporting-metamodel-and-model-extensions-in-rubytl/</guid><description/></item><item><title>An Interactive Modeling Editor for QVT Relations</title><link>https://big.tuwien.ac.at/master-thesis/archive/an-interactive-modeling-editor-for-qvt-relations/</link><pubDate>Tue, 19 May 2020 12:37:26 +0000</pubDate><guid>https://big.tuwien.ac.at/master-thesis/archive/an-interactive-modeling-editor-for-qvt-relations/</guid><description/></item><item><title>Codegeneration with Ruby on Rails – Bridging the gap between Design and Implementation</title><link>https://big.tuwien.ac.at/master-thesis/archive/codegeneration-with-ruby-on-rails-bridging-the-gap-between-design-and-implementation/</link><pubDate>Tue, 19 May 2020 12:37:26 +0000</pubDate><guid>https://big.tuwien.ac.at/master-thesis/archive/codegeneration-with-ruby-on-rails-bridging-the-gap-between-design-and-implementation/</guid><description>&lt;p>This work has been finished in October 2006.&lt;/p>
&lt;p>Durch die Veränderung des World Wide Web von einem statischen Informationsmedium hin zu einem dynamischen Anwendungsmedium ist der Bedarf an Webanwendungen, die für die Bereitstellung von Diensten über das Web verantwortlich sind, so hoch wie nie. Es haben sich bereits sehr viele Technologien etabliert, mit Hilfe derer es möglich ist, Webanwendungen zu entwickeln. Die Anforderungen an solche Webanwendungen sind sehr vielfältig und mit einer oft kürzeren Entwicklungszeit, die für die Erzeugung der Anwendung zur Verfügung steht, geht eine meist höhere Komplexität der benötigten Funktionalität einher.&lt;/p>
&lt;p>Um es den Entwicklern zu ermöglichen, sich mit dem eigentlichen Problem auseinander zu setzen und nicht für jede Webanwendung das Rad neu erfinden zu müssen, werden für die verschiedenen Technologien Frameworks geschaffen, die den Programmierer mit Hilfe integrierter Funktionalitäten bei der Implementierung unterstützen sollen.&lt;/p>
&lt;p>Eines dieser Frameworks, das sich erst seit kurzer Zeit im Web etabliert, ist Ruby on Rails. Es bietet Funktionalitäten, die es dem Entwickler ermöglichen rasch einen ersten, funktionstüchtigen Prototyp einer Webanwendung zu generieren, mit Hilfe dessen sofort Feedback vom Benutzer eingeholt werden kann. Wie es bei vielen Anwendungen im Web der Fall ist, basieren auch die Applikationen, die mit Ruby on Rails erstellt werden auf einem relationalen Datenbanksystem. Der Prototyp, der mit Hilfe eines in Rails integrierten Codegenerators erzeugt wird, bietet jedoch nur eingeschränkte Funktionalität und es wäre wünschenswert einerseits diese zu erweitern und andererseits die Anwendung ausgehend von einem Modell, das die Datenbank beschreibt, generieren zu können.&lt;/p>
&lt;p>Diese Arbeit versucht in einem ersten Schritt den von Ruby on Rails bereitgestellten Scaffold-Generator so zu erweitern, dass der Prototyp auch Validierungsfunktionalität beherrscht. Dies geschieht mit Hilfe zweier zusätzlicher Datenbanktabellen, die Regeln für die Validierung bereitstellen sollen. Weiters soll die Abbildung von Beziehungen zwischen Datenbanktabellen automatisch in die Modellklassen der Webanwendung eingebunden werden.&lt;/p>
&lt;p>Im zweiten Schritt wird ein grafischer Editor erstellt, der für die Erstellung von logischen Datenbankmodellen herangezogen werden kann.&lt;/p>
&lt;p>Schließlich soll am Ende ein Framework entstehen, das zuerst zur Modellierung von ER-Diagrammen dient, danach aus dem Modell über einen Zwischenschritt der Codegeneration die Struktur der Datenbank erstellt und zum Abschluss mit Hilfe des erweiterten Ruby-Generators den Prototyp einer datenintensiven Webanwendung erstellt. Aufgrund der Kombination von Modellierung und dem Einsatz von Ruby on Rails wird dieses Framework Models on Rails genannt.&lt;/p>
&lt;p> &lt;/p>
&lt;p>Download the
&lt;a href="https://www.big.tuwien.ac.at/app/uploads/2016/10/Dick_paper.pdf" target="_blank" rel="noopener">paper&lt;/a> and
&lt;a href="https://www.big.tuwien.ac.at/app/uploads/2016/10/Dick_poster.pdf" target="_blank" rel="noopener">poster&lt;/a>&lt;/p></description></item><item><title>Development of a Web Application for the Worldwide Management of Fire Trucks CAN-Data</title><link>https://big.tuwien.ac.at/master-thesis/archive/development-of-a-web-application-for-the-worldwide-management-of-fire-trucks-can-data/</link><pubDate>Tue, 19 May 2020 12:37:25 +0000</pubDate><guid>https://big.tuwien.ac.at/master-thesis/archive/development-of-a-web-application-for-the-worldwide-management-of-fire-trucks-can-data/</guid><description>&lt;p>This work has been finished in October 2009.&lt;/p>
&lt;p>In a technologically improving world the effective execution of business processes and workflows requires a lot of knowledge and information. As a consequence a sustainable knowledge management and sophisticated tool support are extremely important for every successfully operating company. Within an extremely wide range of tools, Web applications gain more and more importance to meet the constantly increasing requirements. Outstanding benefits are worldwide accessibility and interoperability on a very large scale. Moreover, in many cases no installation on single clients is needed, updates can be provided easily, and centralized data management on the server-side avoids costly synchronizations. These factors lead to reduced costs for the information infrastructure and support the employees to do their work. For example, a constructor of firefighting cars can query the headquarters database on the other side of the world to find out which CAN data (Controller–area network) is needed to configure a specific vehicle.&lt;/p>
&lt;p>Building such solutions is not a trivial task and therefore disciplines like Web Engineering and Internet Computing emerged. Furthermore, developers can choose from a wide range of technologies to realize their solutions. Handling these technologies leads to successful development of Web Applications.&lt;/p>
&lt;p>This master’s thesis describes in detail the solution for a specific problem in the industry, namely a Web application called CORA to manage the CAN-Data for Rosenbauer International AG. According to the company’s it-infrastructure MSSQL Server, IIS, and ASP.NET had been chosen as core technologies. On one hand the .NET framework provides the possibility to develop applications in a rather short time, also known as Rapid Application Development (RAD). On the other hand many RAD-techniques are not applicable on large enterprise solutions where the complexity has to be broken down to several layers. This work presents approaches, patterns and techniques for each layer.&lt;/p>
&lt;p>The Data Access Layer is responsible for retrieving data and uses Linq to SQL as object relational mapper. In addition the possibilities of model driven development to create the fundamental data manipulation objects will be evaluated. The Business Layer handles the communication between the Data Access Layer and the Presentation Layer and adds business functionality. Finally, the Presentation Layer presents the data in an appropriate format and handles the user interaction.&lt;/p>
&lt;p>Furthermore, the database schema of the sample application has been constantly renewed and improved to cover additional requirements like multiple CAN bus systems, multilingualism, user administration, and a history of important entities. Therefore, schema evolution and data migration has played an additional important role in this thesis.&lt;/p>
&lt;p>All these aspects have been elaborated theoretically and explained practically with the help of CORA. Consequently, this thesis provides a method in state of the art web application development for small business projects.&lt;/p>
&lt;p> &lt;/p>
&lt;p>Download the
&lt;a href="https://www.big.tuwien.ac.at/app/uploads/2016/10/Bruckmayer_papers.pdf" target="_blank" rel="noopener">paper&lt;/a> and
&lt;a href="https://www.big.tuwien.ac.at/app/uploads/2016/10/Bruckmayer_poster.pdf" target="_blank" rel="noopener">poster&lt;/a>&lt;/p></description></item><item><title>Integrating fUML in Enterprise Architect</title><link>https://big.tuwien.ac.at/master-thesis/archive/integrating-fuml-in-enterprise-architect/</link><pubDate>Tue, 19 May 2020 12:37:25 +0000</pubDate><guid>https://big.tuwien.ac.at/master-thesis/archive/integrating-fuml-in-enterprise-architect/</guid><description>&lt;p>This work has been finished in April 2015.&lt;/p>
&lt;p>The foundational UML standard (fUML) specifies precise execution semantics for a subset of the Unified Modeling Language (UML). The main purpose of this standard is to make models containing the detailed elements interpretable and executable. This enables additional use cases for the models, such as visualization of the execution of behavior models, or automatic validation.&lt;/p>
&lt;p>However, the fUML standard does not have a significant market penetration in commercial UML simulation tools yet. These tools still rely on proprietary and mostly incompatible solutions, leading to migration and compatibility problems.&lt;/p>
&lt;p>The main question that is dealt with in this master’s thesis is therefore: Can the proprietary solution of such a commercial UML simulation tool be replaced with the definitions and technologies proposed in the fUML standard? And, if so, which changes does this adaptation bring?&lt;/p>
&lt;p>This master’s thesis focuses on the commercial UML tool Enterprise Architect [http://www.sparxsystems.com/products/ea/index.html], and the simulation engine provided by the plugin AMUSE [http://www.lieberlieber.com/amuse/] – a proprietary UML simulation tool based on code generation. For the purpose of this thesis, AMUSE’s execution engine is modified to execute fUML standard-compliant models using the execution engine specified in the fUML standard instead of using its own, proprietary engine.&lt;/p>
&lt;p> &lt;/p></description></item><item><title>State of the Art in Enterprise Web Application Development</title><link>https://big.tuwien.ac.at/master-thesis/archive/state-of-the-art-in-enterprise-web-application-development/</link><pubDate>Tue, 19 May 2020 12:37:25 +0000</pubDate><guid>https://big.tuwien.ac.at/master-thesis/archive/state-of-the-art-in-enterprise-web-application-development/</guid><description>&lt;p>This work has been finished in June 2006.&lt;/p>
&lt;p>The software industry is a very dynamic market that forces software companies to react as fast as possible and to adjust their software products to the actual market requirements. To enable this, one of the most important factors of software development is the underlying architecture of the software and component reuse.&lt;/p>
&lt;p>An enterprise application is very valuable for the enterprise. Enterprise applications usually involve persistent data and many people access data concurrently. There is also a rich set of graphical user interfaces to offer the users a convenient way to do their work. In addition, it is also necessary to intergrate other enterprise applications scattered around the enterprise.&lt;/p>
&lt;p>With the rise of object-oriented thinking, frameworks became more popular and sprout out than never before. A framework is an approach of software reuse and enables developers to establish the software on an abstract layer. On the web there are a lot of frameworks for web development. Current frameworks include Java Server Faces, Struts, Spring, Hibernate, Cocoon, OpenLaszlo, JBPM, Maven and many others. Software developers recognize that due to the use of such frameworks most of the code in an application becomes declarative which enables software companies to react fast to new requirements in their software product.&lt;/p>
&lt;p>To develop successfull framework-based applications, developers should know what frameworks are and how to deal with them. This is an important part, because the use of frameworks influences the underlying architecture of the application. It depends on the requirements of an application, which set of frameworks will be used. Hence you take a different set of frameworks for a server side application than for a rich internet application (RIA).&lt;/p>
&lt;p>This diploma thesis gives an introduction to the world of frameworks related to enterprise web application development and how to use and combine them. Therefore, a couple of frameworks will be evaluated by studying their capabilities, each one pursuing different goals.&lt;/p>
&lt;p>The diploma thesis is attended by a practical example which demonstrates the employment of the frameworks in an enterprise application, and explores their compatibility and practical usability. This practical example uses a set of frameworks to make the software components maintainable, re-useable, exensible, and configurable through declarative programming.&lt;/p>
&lt;p> &lt;/p>
&lt;p>Download the
&lt;a href="https://www.big.tuwien.ac.at/app/uploads/2016/10/Demolsky_papers.pdf" target="_blank" rel="noopener">paper&lt;/a> and
&lt;a href="https://www.big.tuwien.ac.at/app/uploads/2016/10/Demolsky_posters.pdf" target="_blank" rel="noopener">poster&lt;/a>&lt;/p></description></item><item><title>Towards an Understanding of the practical use of UML</title><link>https://big.tuwien.ac.at/master-thesis/archive/towards-an-understanding-of-the-practical-use-of-uml/</link><pubDate>Tue, 19 May 2020 12:37:24 +0000</pubDate><guid>https://big.tuwien.ac.at/master-thesis/archive/towards-an-understanding-of-the-practical-use-of-uml/</guid><description>&lt;p>This work has been finished in November 2013.&lt;/p>
&lt;p>Abstract and paper may be found in our &lt;a class="external" href="http://publik.tuwien.ac.at/showentry.php?ID=223100&amp;amp;lang=2">publication database&lt;/a>.&lt;/p>
&lt;p>Download the
&lt;a href="https://www.big.tuwien.ac.at/app/uploads/2016/10/Bohn_poster.pdf" target="_blank" rel="noopener">poster&lt;/a>&lt;/p></description></item><item><title>Ubiquitäre Web-Anwendungen - Realisierung von Adaptierung mit Hilfe aspektorientierter Programmierung</title><link>https://big.tuwien.ac.at/master-thesis/archive/ubiquitre-web-anwendungen-realisierung-von-adaptierung-mit-hilfe-aspektorientierter-programmierung/</link><pubDate>Tue, 19 May 2020 12:37:24 +0000</pubDate><guid>https://big.tuwien.ac.at/master-thesis/archive/ubiquitre-web-anwendungen-realisierung-von-adaptierung-mit-hilfe-aspektorientierter-programmierung/</guid><description>&lt;p>This work has been finished in October 2006.&lt;/p>
&lt;p>Ubiquitäre Web-Anwendungen haben das anytime/anywhere/anymedia Paradigma zugrunde liegen, und sollen dem Anwender, egal wann, wo und mit welchem Gerät er diese nutzt, einen individuell abgestimmten und auf die Rahmenbedingungen des Benutzers angepassten Inhalt bieten.&lt;/p>
&lt;p>Im Rahmen einer Kooperation von drei Magisterarbeiten [Brosch, Mayer, Weissensteiner] wurde ein ubiquitäres Tourismusinformationssystem entwickelt. Das Ziel dieses umfangreichen Projekts war die Konzeption, Modellierung und Implementierung einer Web-Anwendung mit Customizationunterstützung, dh. einer Web-Anwendungen die aufgrund mehrerer Kontextfaktoren wie Benutzer, Zeit, Ort, Gerät, etc., mit der Adaptierung ihrer Dienste reagiert. Die Implementierung der Customizationfunktionalität ist allerdings komplex, da sie an vielen Stellen der Web-Anwendung Berücksichtigung finden muss und sich quer durch den Code des Systems zieht. Separation of Concerns ist daher im Sinne der Wartbarkeit, Erweiterbarkeit, Änderbarkeit, etc. eines Systems anzustreben.&lt;/p>
&lt;p>Der Fokus dieser Arbeit liegt auf Aspektorientierung in der Entwicklung von ubiquitären Web-Anwendungen. Die aspektorientierte Programmierung unterstützt die Modularisierung von so genannten Crosscutting Concerns mit Hilfe eines neuen Konzepts, dem Aspekt. Diese Crosscutting Concerns lassen sich mit herkömmlichen Modularisierungsmethoden, die beispielsweise die objektorientierte Programmierung bietet, nicht kapseln, sondern sind über viele Komponenten eines Programms hinweg verteilt. Typische Beispiele für Crosscutting Concerns sind so genannte System-level Concerns wie Logging, Authentifizierung und Fehlerbehandlung. Die Kernfunktionalität eines Systems, so genannte Core Concerns, lassen sich üblicherweise in Klassen der Geschäftslogik kapseln, nicht so die Customizationfunktionalität. Daher demonstrieren wir anhand eines ubiquitären Tourismusinformationssystems den Nutzen und Beitrag von Aspektorientierung zur Behandlung von Separation of Concerns im Allemeinen und insbesondere für die Trennung des Customization Concerns.&lt;/p>
&lt;p> &lt;/p>
&lt;p>Download the
&lt;a href="https://www.big.tuwien.ac.at/app/uploads/2016/10/Brosch_paper.pdf" target="_blank" rel="noopener">paper&lt;/a> and
&lt;a href="https://www.big.tuwien.ac.at/app/uploads/2016/10/Brosch_poster.pdf" target="_blank" rel="noopener">poster&lt;/a>&lt;/p></description></item><item><title>Advanced Model Decoration with EMF Profiles</title><link>https://big.tuwien.ac.at/master-thesis/archive/advanced-model-decoration-with-emf-profiles/</link><pubDate>Tue, 19 May 2020 12:37:23 +0000</pubDate><guid>https://big.tuwien.ac.at/master-thesis/archive/advanced-model-decoration-with-emf-profiles/</guid><description>&lt;p>This work has been finished in February 2015.&lt;/p>
&lt;p>EMF Profiles is an adaptation of the well-known UML profile concept to DSMLs. Profiles have been a key enabler for the success of UML by providing a lightweight language-inherent extension mechanism which is expressive enough to cover an important subset of adaptation scenarios. Thus, we believe a similar concept for DSMLs provides an easier extension mechanism that has been so far neglected by current metamodeling tools.&lt;/p>
&lt;p>With EMF Profiles, users can apply profiles within graphical modeling editors that are created in GMF. Applied stereotypes are visualized using icons that are attached to shapes that represent the model elements to which stereotypes are applied. However, in many scenarios, visualization methods going beyond simple icons are helpful for locating and grasping the applied stereotypes and to allow for more domain-specific decorations according to the domain of the applied profile. For instance, a specific background color or a dedicated shape reflects the meaning of a stereotype application more adequately than a simple icon.&lt;/p>
&lt;p>This thesis aims at providing decoration methods for applied stereotype in EMF Profiles going beyond simple icons. Therefore, we investigate the decoration facilities in GMF and Graphiti and extend the profile definition language to allow users to define specific decorations for stereotypes. Once a specific decoration is defined, applications of these stereotypes are visualized using the defined decorations in any GMF-based and Graphiti-based modeling editor. The results and benefits of the extensions developed in this thesis are evaluated in the context of a case study. In particular, we will assess how the runtime information of executable models can be visualized appropriately and dynamically updated during the execution with EMF Profiles.&lt;/p>
&lt;p> &lt;/p></description></item><item><title>Agile Software Performance Engineering</title><link>https://big.tuwien.ac.at/master-thesis/archive/agile-software-performance-engineering/</link><pubDate>Tue, 19 May 2020 12:37:23 +0000</pubDate><guid>https://big.tuwien.ac.at/master-thesis/archive/agile-software-performance-engineering/</guid><description>&lt;p>Performance is an important non-functional requirement and a key-characteristic of software systems. Software performance engineering (SPE), alongside a software engineering process, covers any activity related to performance management of software systems and highlights the importance of engineering principles instead of ad-hoc try and error approaches. However, SPE is split into two main areas: The model-based- and the measurement-based approach. With the rise of agile software development methodologies in the last decade, the importance of continuous delivery and thus the early provisioning of operations resources increased. Given the new possibilities that these concepts together with DevOps and Cloud solutions offer, it appears practically usable to combine the model-based approach with the measurement-based approach. The combination of these two approaches in SPE is the research interest of this thesis.&lt;/p>
&lt;p>Abstract and paper may be found in our
&lt;a href="https://publik.tuwien.ac.at/showentry.php?ID=258053&amp;amp;amp;lang=1&amp;amp;amp;head=%3Clink&amp;#43;rel%3D%22stylesheet%22&amp;#43;type%3D%22text%2Fcss%22&amp;#43;href%3D%22https%3A%2F%2Fpublik.tuwien.ac.at%2Fpubdat.css%22%3E%3C%2Fhead%3E%3Cbody%3E" target="_blank" rel="noopener">publication database&lt;/a>.&lt;/p>
&lt;p> &lt;/p></description></item><item><title>Towards Software Model Checking in the Context of Model–Driven Engineering</title><link>https://big.tuwien.ac.at/master-thesis/archive/towards-software-model-checking-in-the-context-of-model-driven-engineering/</link><pubDate>Tue, 19 May 2020 12:37:23 +0000</pubDate><guid>https://big.tuwien.ac.at/master-thesis/archive/towards-software-model-checking-in-the-context-of-model-driven-engineering/</guid><description>&lt;p>This work has been finished in March 2014.&lt;/p>
&lt;p>The aim of this master thesis is to reduce the conceptual gap between software modeling and model checking. While model checking is successfully applied for hardware verification, it is not widespreadly used in model–driven engineering (MDE). Thus, we tried to reduce this gap by combining modeling and model checking concepts.&lt;/p>
&lt;p>This thesis first describes the history and basic idea of both MDE and model checking with a focus on the technologies used in this thesis. Before presenting our new approach, existing solutions are compared. Most approaches propose to extend the Object Constraint Language (OCL) by temporal aspects. This allows to describe the behavior of a software system additionally to various properties of static models. However, one of the main missing features in general seems to be a user–friendly representation of the verification result helpful for debugging. Often, the technical spaces are changed.&lt;/p>
&lt;p>With our solution we provide (i) a temporal OCL extension based on the Computational Tree Logic (CTL) and (ii) an OCL extension that introduces path selectors to extract interesting system configurations from the state space. Both OCL extensions were formally defined and implemented. We describe systems in terms of state spaces consisting of EMOF–model states and state transitions containing a mapping between model elements of different states. The system behavior is specified using an initial Ecore model and graph transformations based on the Henshin tool2. The approach, however, is designed to be flexible enough to allow an easy integration of any kind of behavior specification as long as a suitable state space can be derived thereof. Our model checking framework is developed with a focus on delivering not only the results, but also making the system behavior leading to the result comprehensible by providing a suitable tool including a web interface.&lt;/p>
&lt;p>The implementation was evaluated in terms of performance to find out the maximum evaluable model size and query complexity. Further, a qualitative user study was conducted for evaluating the CTL extension and the tool. The results of this study indicate that both the CTL–based extension of OCL as well as the tool are a promising first step to integrate model checking in the MDE life cycle.&lt;/p>
&lt;p>Abstract and paper may be found in our &lt;a class="external" href="http://publik.tuwien.ac.at/showentry.php?ID=227939&amp;amp;lang=2">publication database&lt;/a>.&lt;/p>
&lt;p>Download the
&lt;a href="https://www.big.tuwien.ac.at/app/uploads/2016/10/Bill_poster.pdf" target="_blank" rel="noopener">poster&lt;/a>&lt;/p></description></item><item><title>On the Usability of Triple Graph Grammars for the Transformation Business Process Models - An Evaluation based on FUJABA</title><link>https://big.tuwien.ac.at/master-thesis/archive/on-the-usability-of-triple-graph-grammars-for-the-transformation-business-process-models-an-evaluation-based-on-fujaba/</link><pubDate>Tue, 19 May 2020 12:37:22 +0000</pubDate><guid>https://big.tuwien.ac.at/master-thesis/archive/on-the-usability-of-triple-graph-grammars-for-the-transformation-business-process-models-an-evaluation-based-on-fujaba/</guid><description>&lt;p>This work has been finished in January 2008.&lt;/p>
&lt;p>In recent years the need for business process model transformation has increased. The primary reason for this is the importance of business to business interopeability. A lot of research is done in this area Several transformation techniques exist in the field of MDA which is the model driven architecture as defined by Object Management Group (OMG).&lt;/p>
&lt;p>In Business Process Modeling many modeling languages such as BPMN, activity diagrams, Event-Driven Process Chains et cetera are used. There is also a certain diversity in transformation techniques such as ATL, QVT or Kermeta. Most model transformation approaches focus on software development, and less in business processes. Therefore some approaches may be more or less suitable for this task than others.&lt;/p>
&lt;p>In this master thesis, a transformation approach, namely Triple Graph Grammars will be inspected for its suitability in business process model transformation. Event-driven process chains and activity diagrams from UML 2.x are chosen as business process modeling languages because of the wide spread popularity of these languages. Fujaba will be used as transformation tool for its Triple Graph Grammar support and its extendibility.&lt;/p>
&lt;p>In the thesis the business process modeling languages event-driven process chains and activity diagrams are described. Furthermore, several example models for event-driven process chains and activity diagrams are defined. In the practical part the goal is to develop Fujaba plug-ins for those modeling languages, as well as to define the Triple Graph Grammars rules based on the new plug-ins. The example models will be needed to test if the Triple Graph Grammar rules are intend correctly.&lt;/p>
&lt;p>Fujaba is an open source project from the University of Paderborn. Its primary topic is to provide an extendable platform for UML, Story Driven Modeling and Graph Transformation platform with the ability to add plug-ins. In the master thesis this tool is used because of its mature Triple Graph Grammar support Another reason is its extensibility which is useful for creating custom plug-ins for event-driven process chains and activity diagrams.&lt;/p>
&lt;p>The plug-ins are developed with Java and rely on the meta models of Activity diagrams and Event-driven process chains. The prepared meta models are also used when defining the Triple Graph Grammar rules as initial point. The meta models and the transformation are focused on control flow of business processes, because of its central importance in business process modeling. Organizational flow is also included as a secondary view.&lt;/p>
&lt;p>In order to make a statement on how suitable the described approach is, a list of criteria is defined. Based on this criteria business process model transformation with triple graph grammars will be evaluated.&lt;/p>
&lt;p> &lt;/p>
&lt;p>Download the
&lt;a href="https://www.big.tuwien.ac.at/app/uploads/2016/10/Altan_papers.pdf" target="_blank" rel="noopener">paper&lt;/a> and
&lt;a href="https://www.big.tuwien.ac.at/app/uploads/2016/10/Altan_poster.pdf" target="_blank" rel="noopener">poster&lt;/a>&lt;/p></description></item><item><title>Visualizing Domain-Specific Languages Utilizing JavaFX</title><link>https://big.tuwien.ac.at/master-thesis/archive/visualizing-domain-specific-languages-utilizing-javafx/</link><pubDate>Tue, 19 May 2020 12:37:22 +0000</pubDate><guid>https://big.tuwien.ac.at/master-thesis/archive/visualizing-domain-specific-languages-utilizing-javafx/</guid><description/></item></channel></rss>