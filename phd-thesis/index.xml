<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>PhD Theses | BIG TU Wien</title><link>https://big.tuwien.ac.at/phd-thesis/</link><atom:link href="https://big.tuwien.ac.at/phd-thesis/index.xml" rel="self" type="application/rss+xml"/><description>PhD Theses</description><generator>Source Themes Academic (https://sourcethemes.com/academic/)</generator><language>en-us</language><copyright>© by Business Informatics Group (BIG), TU Wien, 2020</copyright><lastBuildDate>Tue, 19 May 2020 12:38:30 +0000</lastBuildDate><image><url>https://big.tuwien.ac.at/images/logo_hub5239f9a002a777103d549dfca2a9392_18033_300x300_fit_lanczos_2.png</url><title>PhD Theses</title><link>https://big.tuwien.ac.at/phd-thesis/</link></image><item><title>Conflict-tolerant Model Versioning</title><link>https://big.tuwien.ac.at/phd-thesis/archive/conflict-tolerant-model-versioning/</link><pubDate>Tue, 19 May 2020 12:38:30 +0000</pubDate><guid>https://big.tuwien.ac.at/phd-thesis/archive/conflict-tolerant-model-versioning/</guid><description>&lt;p>This work has been finished in December 2011.&lt;/p>
&lt;p>Model-driven software engineering (MDSE), which has recently gained momentum in academia as well as in industry, changed the way in which modern software systems are built. In MDSE, the task of programming, i.e., writing code in a textual programming language, is replaced by modeling in a language such as the Unified Modeling Language (UML). The powerful abstraction mechanisms of models are not only used for documentation purposes, but also for compiling executable code directly out of models. With the rise of MDSE, several problems solved for traditional software engineering became urgent again because well established solutions are not directly transferable from code to models. Among others, the collaborative development of models is currently only limited supported by modeling tools and, consequently, it is mostly a one-(wo)man show. Especially in the field of model versioning, which supports the asynchronous modification of modeling artifacts by multiple developers, only first solutions start to emerge.&lt;/p>
&lt;p>The urgent need for a suitable infrastructure supporting effective model versioning has been widely recognized by researchers as well as practitioners. Currently, however, there is a lack of empirical studies on the needs of software developers in practice concerning the collaborative development of software systems. The first contribution of this thesis tackles this problem and provides an extensive survey about versioning in practice by the means of an online questionnaire and qualitative expert interviews. One result of the empirical study shows that conflicts due to parallel modifications are considered harmful and, thus, developers try to avoid them. Conflicts, however, should not be seen as negative result of collaboration but as chance for discussing ideas and for improving the system under development. As consequence, the second contribution is a conflict-tolerant model versioning approach, where the developers may commit their changes in the central repository without worrying about possible conflicts. This approach merges two or more parallel versions by applying dedicated merge rules and, by this, it incorporates all modifications of the developers. This builds a good basis for discussing and resolving conflicts collaboratively. Finally, when resolving conflicts a high degree of user interaction is required. When setting models under version control with state-of-the art tools, however, conflicts are hardly accessible for the users. Also the empirical study has shown, that current version control systems lack for a dedicated representation and visualization. Moreover, user support is required to better understand the reasons behind the conflicting changes. The third contribution tackles these deficiencies by visualizing occurred conflicts in terms of model annotations and enriching them automatically with additional meta information to better understand the parallel evolution of the model under development. The implemented prototype is evaluated by means of a quasi-experimental study, which demonstrates the advantages of developing models in a collaborative manner.&lt;/p>
&lt;p>Abstract and paper may be found in our &lt;a class="external" href="http://publik.tuwien.ac.at/showentry.php?ID=209022&amp;amp;lang=2">publication database&lt;/a>.&lt;/p></description></item><item><title>From Mining to Mapping and Roundtrip Transformations – A Systematic Approach to Model-based Tool Integration</title><link>https://big.tuwien.ac.at/phd-thesis/archive/from-mining-to-mapping-and-roundtrip-transformations-a-systematic-approach-to-model-based-tool-integration/</link><pubDate>Tue, 19 May 2020 12:38:30 +0000</pubDate><guid>https://big.tuwien.ac.at/phd-thesis/archive/from-mining-to-mapping-and-roundtrip-transformations-a-systematic-approach-to-model-based-tool-integration/</guid><description>&lt;p>This work has been finished in March 2008.&lt;/p>
&lt;p>Model-Driven Engineering (MDE) gains momentum in academia as well as in practice. A wide variety of modeling tools is already available supporting different development tasks and advocating different modeling languages. In order to fully exploit the potential of MDE, modeling tools must work in combination, i.e., a seamless exchange of models between different modeling tools is crucial for MDE. Current best practices to achieve interoperability use model transformation languages to realize necessary mappings between the metamodels defining the modeling languages supported by different tools. However, the development of such mappings is still done in an ad-hoc and implementation-oriented manner which simply does not scale for large integration scenarios. The reason for this is twofold. First, various modeling languages are not based on metamodeling standards but instead define proprietary languages rather focused on notational aspects. And second, existing model transformation languages both do not support expressing mappings on a high-level of abstraction and lack appropriate reuse mechanisms for already existing integration knowledge.&lt;/p>
&lt;p>This thesis contributes to the above mentioned problems. It proposes a comprehensive approach for realizing model-based tool integration, which is inspired from techniques originating from the field of database integration, but employed in the context of MDE. For tackling the problem of missing metamodel descriptions, a semi-automatic approach for mining metamodels and models from textual language definitions is presented, being a prerequisite for the subsequent steps which are based on metamodels and models, only. For raising the level of abstraction and for ensuring the reuse of mappings between metamodels, a framework is proposed for building, applying, and executing reusable mapping operators. To demonstrate the applicability of the framework, it is applied to the definition of mapping operators which are intended to resolve typical structural heterogeneities occurring between the core concepts of metamodels. Finally, for ensuring roundtrip capabilities of transformations, two approaches are proposed evolving non-roundtripping transformations with roundtrip capabilities.&lt;/p>
&lt;p>Abstract and paper may be found in our &lt;a class="external" href="http://publik.tuwien.ac.at/showentry.php?ID=141768&amp;amp;lang=2">publication database&lt;/a>.&lt;/p></description></item><item><title>Conceptual Models and Model-Based Business Metadata to Bridge the Gap between Data Warehouses and Organizations</title><link>https://big.tuwien.ac.at/phd-thesis/archive/conceptual-models-and-model-based-business-metadata-to-bridge-the-gap-between-data-warehouses-and-organizations/</link><pubDate>Tue, 19 May 2020 12:38:29 +0000</pubDate><guid>https://big.tuwien.ac.at/phd-thesis/archive/conceptual-models-and-model-based-business-metadata-to-bridge-the-gap-between-data-warehouses-and-organizations/</guid><description>&lt;p>This work has been finished in November 2007.&lt;/p>
&lt;p>Data warehouse systems are used by decision makers for performance measurement and decision support. Measures such as the number of transactions per customer or the increase of sales during a promotion are used to recognize warning signs and to decide on future investments with regard to the strategic goals of the organization.&lt;/p>
&lt;p>Currently, the main focus of the data warehouse research field is on database issues. The data warehouse’s interaction with the organization and the way it supports the organization’s strategic goals have not yet been considered in depth. Conceptual models that describe the data warehouse from various viewpoints, including an outside view of the data warehouse system, its environment and expected usage, are missing. Moreover, even though the data in the data warehouse by its very nature has to be closely related to the concerns of the organization, current data warehouses also lack sufficient business meta-data that would inform users about the organizational context and implications of what they are analyzing.&lt;/p>
&lt;p>This thesis targets the relationship between the data warehouse and the structure, behavior, and goals of the organization.&lt;/p>
&lt;p>In order to describe this relationship, a conceptual modeling language was developed. It consists of models for describing the interdependencies between data warehouses and business processes, including so-called active data warehouse solutions; a model for identifying business objects such as customers and products in the data warehouse data model, and for constructing data models that comply to the state models of such business objects; as well as a model of data warehouse usage, which includes modeling the users, user groups, and user skill levels, the intensity with which they use the data warehouse infrastructure, temporal issues such as the required time and urgency of data access, and indicators of the relative importance of data warehouse usage.&lt;/p>
&lt;p>This thesis also introduces an approach to using models to enhance the way users access the data in the data warehouse. It presents model-based business metadata, which links enterprise models such as business process models or goal models to the data model of the data warehouse through the mechanism of model weaving. A prototype illustrating how models can be weaved and used for business metadata in a business intelligence tool has been developed as part of this thesis.&lt;/p>
&lt;p> &lt;/p>
&lt;p>Download the
&lt;a href="https://www.big.tuwien.ac.at/app/uploads/2016/10/Stefanov_pdf.pdf" target="_blank" rel="noopener">paper&lt;/a>&lt;/p></description></item><item><title>Model Transformation by Example</title><link>https://big.tuwien.ac.at/phd-thesis/archive/model-transformation-by-example/</link><pubDate>Tue, 19 May 2020 12:38:29 +0000</pubDate><guid>https://big.tuwien.ac.at/phd-thesis/archive/model-transformation-by-example/</guid><description>&lt;p>This work has been finished in May 2008.&lt;/p>
&lt;p>Model-Driven Engineering (MDE) is getting more and more attention as a viable alternative to the traditional code-centric software development paradigm. With its progress, several model transformation approaches and languages have been developed in the past years. Most of these approaches are metamodel-based and, therefore, require knowledge of the abstract syntax of the modeling languages, which in contrast is not necessary for defining domain models using the concrete syntax of the respective languages.&lt;/p>
&lt;p>Based on the by-example paradigm, we propose Model Transformation By-Example (MTBE), to cope with shortcomings of current model transformation approaches. Our approach allows the user to define semantic correspondences between concrete syntax elements with the help of special mapping operators. This is more user-friendly than directly specifying model transformation rules and mappings on the metamodel level. In general, the user’s knowledge about the notation of the modeling language and the meaning of mapping operators is sufficient for the definition of model transformations. The definition of mapping operators is subject to extension, which has been applied for the definition of mapping operators for the structural and the behavioral modeling domain. However, to keep things transparent and user-friendly, only a minimal set of mapping operators has been implemented. To compensate for the additional expressiveness inherent in common model transformation languages we apply reasoning algorithms on the models represented in concrete as well as in abstract syntax and on the metamodels generating adequate transformation code.&lt;/p>
&lt;p>In order to fulfill the requirements for a user-friendly application of MTBE, proper tool support and methods to guide the mapping and model transformation generation tasks are a must. Hence, a framework for MTBE was designed that builds on state-of-the-art MDE tools on the Eclipse platform, such as the Eclipse Modeling Framework (EMF), the Graphical Modeling Framework (GMF), the Atlas Transformation Language (ATL), and the Atlas Model Weaver (AMW). The decision to base our implementation on top of Eclipse and further Eclipse projects was driven by the fact, that there is a huge community we can address with our MTBE plug-in.&lt;/p>
&lt;p>Finally, we evaluate our approach by means of two case studies covering the structural as well as behavioral modeling language domain.&lt;/p>
&lt;p> &lt;/p>
&lt;p>Download the
&lt;a href="https://www.big.tuwien.ac.at/app/uploads/2016/10/Strommer_M.pdf" target="_blank" rel="noopener">paper&lt;/a>&lt;/p></description></item><item><title>Towards a Sustainable DWH Approach for Evidence-Based Healthcare</title><link>https://big.tuwien.ac.at/phd-thesis/archive/towards-a-sustainable-dwh-approach-for-evidence-based-healthcare/</link><pubDate>Tue, 19 May 2020 12:38:29 +0000</pubDate><guid>https://big.tuwien.ac.at/phd-thesis/archive/towards-a-sustainable-dwh-approach-for-evidence-based-healthcare/</guid><description>&lt;p>This work has been finished in September 2007.&lt;/p>
&lt;p>The healthcare industry is one of the world’s largest, fastest developing and most information-rich industries. Rapid growth of information technologies has brought immense opportunities for patient data sharing, development and dissemination of evidence-based medical knowledge and analysis across distributed, heterogeneous healthcare data sources.&lt;/p>
&lt;p>In contrast to other industries, where data warehouses have been successfully applied, healthcare is an area in which the information technology had only been able to permeate the administrative and logistic aspects of information processing. The growing need for integrated healthcare has led this industry to open towards adoption of extensive clinical decision support systems.&lt;/p>
&lt;p>Evidence-based medicine (EBM) offers a collection of proven best practise guidelines for recommending drugs and medical treatments. This thesis states that the way data warehouse (DWH) technology can facilitate EBM is twofold: (1) by supporting the rule development process, and (2) by providing the EBM-enriched knowledge base to support the decision-making process of the care givers.&lt;/p>
&lt;p>With respect to (1), we explain that data warehousing and data mining support the creation of the evidence-based rules by providing a platform and tools for knowledge discovery and pattern recognition. Large amounts of data can be analysed to confirm known or discover unknown trends and correlations in data.&lt;/p>
&lt;p>Regarding (2), we argue that the care giving process can benefit significantly from the application of DWH technology at the point of care. Given an integrated knowledge base, built upon broad variety of patient-related information sources and incorporating evidence-based rules, our approach offers a unique decision support for the practitioners in their every-day work.&lt;/p>
&lt;p>In order to guarantee the confidentiality of patient data in today´s increasingly information-based, multi-site health delivery environment, this thesis recommends a federated DWH approach instead of collecting data from remote sources into a centralized system. We endorse the application of de-personalisation, pseudonymization and role-based access mechanism for protection of sensitive healthcare data.&lt;/p>
&lt;p>This dissertation is intended to provide a roadmap for achieving sustainable healthcare decision support system based on federated data warehouses, facilitating evidence-based medicine that safeguards patient´s personal privacy. It postulates four rules to follow when building a modern medical decision support system and we hope that its advisory nature will prove to be helpful in designing future healthcare projects.&lt;/p>
&lt;p> &lt;/p>
&lt;p>Download the
&lt;a href="https://www.big.tuwien.ac.at/app/uploads/2016/10/Stolba_N.pdf" target="_blank" rel="noopener">paper&lt;/a>&lt;/p></description></item><item><title>Model Driven Product Line Engineering: Core Asset and Process Implications</title><link>https://big.tuwien.ac.at/phd-thesis/archive/model-driven-product-line-engineering-core-asset-and-process-implications/</link><pubDate>Tue, 19 May 2020 12:38:28 +0000</pubDate><guid>https://big.tuwien.ac.at/phd-thesis/archive/model-driven-product-line-engineering-core-asset-and-process-implications/</guid><description>&lt;p>This work has been finished in February 2011.&lt;/p>
&lt;p>Reuse is at the heart of major improvements in productivity and quality in Software Engineering. Both Model Driven Engineering (MDE) and Software Product Line Engineering (SPLE) are software development paradigm that promote reuse. Specifically, they promote systematic reuse and a departure from craftsmanship towards an industrialization of the software development process. MDE and SPLE have established their benefits separately. Their combination in Model Driven Product Line Engineering (MDPLE), gathers together the advantages of both.&lt;/p>
&lt;p> &lt;/p></description></item><item><title>Modelling Ubiquitous Web Applications - Requirements and Concepts</title><link>https://big.tuwien.ac.at/phd-thesis/archive/modelling-ubiquitous-web-applications-requirements-and-concepts/</link><pubDate>Tue, 19 May 2020 12:38:28 +0000</pubDate><guid>https://big.tuwien.ac.at/phd-thesis/archive/modelling-ubiquitous-web-applications-requirements-and-concepts/</guid><description>&lt;p>This work has been finished in November 2001.&lt;/p>
&lt;p>E-commerce and m-commerce have dramatically boosted the demand for services which enable ubiquitous access. Ubiquity offers new opportunities and challenges in terms of time-aware, location-aware, device-aware and personalized services. The fundamental objective of ubiquitous web applications is to provide services not only to people at any time, any where, with any media but specifically to communicate the right thing at the right time in the right way. The user should be enabled to interact efficiently with the application despite restrictions in the physical environment, thus preserving semantic equivalence of services and to take advantage from knowledge about the situation of use, leading to semantic enhancement of services. The prerequisite for this is that the application is aware of it`s context. For developing ubiquitous web applications, one must understand what context is to determine its relevancy and how it can be exploited for adapting the provided services towards this context, called customisation. Not least to customisation, the development of ubiquitous web applications is far from easy and calls for appropriate modelling techniques. There exists, however, only a few methods dedicated to the modelling of traditional web applications neglecting to a great extent ubiquity in terms of customisation.&lt;/p>
&lt;p>This thesis proposes a modelling method for ubiquitous web applications. Customisation is regarded as a new modelling dimension, influencing all other dimensions of ubiquitous web application modelling. As a prerequisite for supporting customisaiton, a set of generic models is introduced comprising a context model and arule model, togehter with several sub models. Generic means that the models provide, in the sense of an object-oriented framework, pre-defined classes and language constructs in order to model customisation. For separation of concerns the application is divided into a stable part, comprising the default, i.e., context-independent structure and behaviour and a variable, context-dependent part, thus being subject to adaptations. A set of generic adaptation operations is provided which can be complemented by application specific ones. These adaptation operations can be integrated into the ubiquitous web application on the basis of adaptation hooks. A customisation toolkit in terms of a customisation rule editor and browser supports an integrated modelling process and facilitates reusability on the basis of a repository of customisation rules, macros and patterns. Finally, a process is introduced, covering the whole task of customisation modelling, with a special focus on reusability, herewith providing a holistic view on the development process of ubiquitous web applications.&lt;/p>
&lt;p> &lt;/p></description></item><item><title>aspectUWA - Applying Aspect-Orientation to the Model-Driven Development of Ubiquitous Web Applications</title><link>https://big.tuwien.ac.at/phd-thesis/archive/aspectuwa-applying-aspect-orientation-to-the-model-driven-development-of-ubiquitous-web-applications/</link><pubDate>Tue, 19 May 2020 12:38:27 +0000</pubDate><guid>https://big.tuwien.ac.at/phd-thesis/archive/aspectuwa-applying-aspect-orientation-to-the-model-driven-development-of-ubiquitous-web-applications/</guid><description>&lt;p>This work has been finished in October 2007.&lt;/p>
&lt;p>Ubiquitous web applications (UWA) are a new type of web applications which are accessed in various contexts, i.e., through different devices, by users with various interests, at anytime from anyplace around the globe. In this respect, customization functionality exploits information on this context of use in order to adapt the application’s services accordingly. In web application development, customization is considered a new dimension which increases complexity by ”crosscutting” the content, hypertext, and presentation levels of a web application. Hence, from a software engineering point of view, a systematic development of UWAs on the basis of models is crucial. In model-driven engineering (MDE), models are employed ”as programs” to (semi-) automatically generate applications, which results in more efficient development processes as well as better maintainability and evolution of software. Customization functionality, however, is typically intermingled with the core functionality in a web application model, having a negative effect on understandability, reuse, maintenance and evolution. The aspect-orientation paradigm provides a new way of modularizing crosscutting concerns such as customization within so-called aspects, as well as the necessary means for composing the previously separated concerns in order to obtain the complete application model. There are already some web modeling approaches dealing with the ubiquitous nature of web applications, amongst them, first proposals to use aspect-orientation. Nevertheless, these approaches suffer from the following problems: First, they don’t consider the crosscutting nature of customization comprehensively, but for the hypertext level, only. Second, just very basic aspect-oriented modeling (AOM) concepts are used, resulting in less powerful mechanisms for separating customization. Third, composition of concerns is not regarded for the modeling level. And fourth, model-driven development of UWAs in the sense of MDE is still limited due to missing metamodel specifications and lack of tool support.&lt;/p>
&lt;p>The overall aim of this thesis is the exhaustive use of aspect-orientation as driving paradigm for comprehensively modeling customization aspect separately from all web application levels as well as providing means for composing the aspect with the web application model. Therefore, this thesis proposes the aspectUWA approach, which suggests a generic framework for extending existing web modeling languages with AOM concepts within the realms of MDE. In the context of this thesis, aspectUWA is applied to the web modeling anguageWebML, which doesn’t allow to separately model customization. The major contributions of this thesis are as follows: (i) A Conceptual Reference Model (CRM) for AOM has been developed to form the aforementioned general framework. (ii) A metamodel for WebML has been semi-automatically generated from an existing DTD-based language specification in order to allow for MDE. (iii) The aspectWebML language has been desiged on basis of the CRM and represents WebML’s port to AOM allowing for modeling customization separately as well as for composing the customization aspect with the rest of the web application model. (iv) An initial set of guidelines to be used for modeling customization within aspectWebML is proposed. And (v), the aspectWebML Modeling Environment provides the often missing tool support for modeling crosscutting concerns as well as their composition.&lt;/p>
&lt;p> &lt;/p>
&lt;p>Download the
&lt;a href="https://www.big.tuwien.ac.at/app/uploads/2016/10/Schauerhuber_A.pdf" target="_blank" rel="noopener">paper&lt;/a>&lt;/p></description></item><item><title>Testing and Debugging of Model Transformations</title><link>https://big.tuwien.ac.at/phd-thesis/archive/testing-and-debugging-of-model-transformations/</link><pubDate>Tue, 19 May 2020 12:38:27 +0000</pubDate><guid>https://big.tuwien.ac.at/phd-thesis/archive/testing-and-debugging-of-model-transformations/</guid><description>&lt;p>This work has been finished in December 2011.&lt;/p>
&lt;p>Model-Driven Engineering (MDE) proposes an active use of models to conduct the different phases of software development. The major vision is a shift from the idea of “everything is an object” in the object-oriented paradigm to the idea of “everything is a model” in MDE. Following this vision, it becomes obvious that transformations between models play a key role. Just like any other software, transformations should be engineered using sound and robust engineering techniques. However, current engineering techniques focus on the implementation phase of transformations, but fail to provide means for the analysis, design, testing and debugging phases.&lt;/p>
&lt;p>In particular, to support the analysis and design phase, means are needed that allow to formally describe the requirements of a certain transformation in order to allow for automatic validation in the testing phase. In case of a failure, additional means are needed to efficiently debug model transformations. However, current transformation languages provide only scarce support for debugging. This is mainly due to the fact that low-level information of an according execution engine is provided only, e.g., variable values. Finally, the operational semantics is hidden by these execution engines, which further aggravates finding failures and hampers understanding of transformation specifications.&lt;/p>
&lt;p>To tackle the aforementioned limitations, this thesis provides three main contributions. First, a declarative, visual language called PAMOMO is proposed, which allows to formally specify requirements on model transformations by means of contracts. To test if a model transformation fulfills the specified requirements, the contracts are compiled into check-only QVT Relations, providing dedicated error traces in case a contract fails. These traces may then be used as hints for debugging. To support debugging, Transformation Nets as a DSL on top of CPNs are proposed, which provide a dedicated runtime model for model transformations, making the hidden operational semantics explicit as a second major contribution. Finally, based on this runtime model various means of debugging are presented as a third contribution.&lt;/p>
&lt;p>To evaluate the contributions, relations to competing approaches are drawn in a first step. Second, case studies are used to show the applicability of the presented approaches. To evaluate the runtime model, the operational semantics of dedicated transformation languages is made explicit in terms of Transformation Nets. Finally, the debugging support is evaluated again by case studies and a first user study.&lt;/p>
&lt;p>Abstract and paper may be found in our &lt;a class="external" href="http://publik.tuwien.ac.at/showentry.php?ID=209018&amp;amp;lang=2">publication database&lt;/a>.&lt;/p></description></item><item><title>A Tour on TriGS - Development of an Active System and Application of Rule Patterns for Active Database Design</title><link>https://big.tuwien.ac.at/phd-thesis/archive/a-tour-on-trigs-development-of-an-active-system-and-application-of-rule-patterns-for-active-database-design/</link><pubDate>Tue, 19 May 2020 12:38:26 +0000</pubDate><guid>https://big.tuwien.ac.at/phd-thesis/archive/a-tour-on-trigs-development-of-an-active-system-and-application-of-rule-patterns-for-active-database-design/</guid><description>&lt;p>This work has been finished in September 1996.&lt;/p></description></item><item><title>BOOM: An Approach for an Object-Oriented Fourth Generation System</title><link>https://big.tuwien.ac.at/phd-thesis/archive/boom-an-approach-for-an-object-oriented-fourth-generation-system/</link><pubDate>Tue, 19 May 2020 12:38:26 +0000</pubDate><guid>https://big.tuwien.ac.at/phd-thesis/archive/boom-an-approach-for-an-object-oriented-fourth-generation-system/</guid><description>&lt;p>This work has been finished in March 1998.&lt;/p></description></item><item><title>Approximate Constraint Logic Programming</title><link>https://big.tuwien.ac.at/phd-thesis/archive/approximate-constraint-logic-programming/</link><pubDate>Tue, 19 May 2020 12:38:25 +0000</pubDate><guid>https://big.tuwien.ac.at/phd-thesis/archive/approximate-constraint-logic-programming/</guid><description>&lt;p>This work has been finished in June 1998.&lt;/p>
&lt;p>This thesis describes results that can be used to improve constraint logic programming (CLP) by increasing its expressivity and efficiency. This is done by introducing&lt;/p>
&lt;p>into constraint logic programming and providing a computer implementation of a CLP system using these inprovements. For reaching this goal, work has been done in the following main areas, corresponding to the three parts of the term „constraint logic programming“:&lt;/p>
&lt;p>Logic: An extension of the first-order predicate language, defining the notions of „approximate solution set“ and „approximate quantifier“ has been introduced.&lt;/p>
&lt;p>Programming (Language Design and Implementation): The syntax and semantics of a new constraint logic programming language allowing first-order constraints with approximate quantifiers and approximate answers has been defined and implemented.&lt;/p>
&lt;p>Constraint (Solving): A new algorithm for approximately solving first-order constraints with approximate quantifiers has been devised. The algorithm has been implemented over the domain of the real numbers.&lt;/p>
&lt;p> &lt;/p></description></item><item><title>De Modo Operandi: Towards the Interoperability of Workflow Information</title><link>https://big.tuwien.ac.at/phd-thesis/archive/de-modo-operandi-towards-the-interoperability-of-workflow-information/</link><pubDate>Tue, 19 May 2020 12:38:25 +0000</pubDate><guid>https://big.tuwien.ac.at/phd-thesis/archive/de-modo-operandi-towards-the-interoperability-of-workflow-information/</guid><description>&lt;p>This work has been finished in April 1995.&lt;/p>
&lt;p>The research reported in this dissertation deals with workflow management and electronic publishing. Recent developments like the evolvement of international standards, advanced communication services, as well as new delivery platforms, have resulted in a bewildering number of workflow systems, each of them being a proprietary solution. The consequences are non-interoperable systems where workflow information cannot be exchanged, a fact which does backfire with the ideas of recent developments.&lt;/p>
&lt;p>HyTime is an international standard for the exchange of time-dependent, structured information. So-called HyTime architectural forms were developed for representing workflow information. Through this as well as through additional layers in the architecture of our workflow system we enable the interoperability of workflow information between different systems.&lt;/p>
&lt;p>We investigate the publishing process and derive requirements for system support. Existing systems, both research prototypes as well as commercial systems are subject of the following investigation. Based on these investigations we have specified an architecture for workflow systems. Specification and Implementation of a prototypical system developed in Visualworks\Smalltalk demonstrate the usability of the concept by a running system. The role of workflow within CSCW (Computer Supported Cooperative Work) is investigated. Concluding remarks including the significance of our approach as well as future work finish the dissertation.&lt;/p>
&lt;p> &lt;/p></description></item><item><title>TriGSflow - Workflow Management Based on Active Object-Oriented Database Systems and Extended Transaction Mechanisms</title><link>https://big.tuwien.ac.at/phd-thesis/archive/trigsflow-workflow-management-based-on-active-object-oriented-database-systems-and-extended-transaction-mechanisms/</link><pubDate>Tue, 19 May 2020 12:38:25 +0000</pubDate><guid>https://big.tuwien.ac.at/phd-thesis/archive/trigsflow-workflow-management-based-on-active-object-oriented-database-systems-and-extended-transaction-mechanisms/</guid><description>&lt;p>This work has been finished in February 1997.&lt;/p>
&lt;p>Effective business process management is a key success factor of today’s organizations acting in global markets. Their business processes have to dynamically adapt to changing requirements while executing in a consistent and reliable manner, even at the presence of activities performing concurrently. This book addresses the very vivid area of workflow management which provides a promising technology to solve these problems. The first part of the book describes a prototype workflow management system that gains flexibility and adaptability by building on object-oriented database technologies, Event-Condition-Action rules, and the role concept. The second part proposes an extension to the well-known nested transaction model that addresses the specific consistency and reliability requirements of workflow management systems.&lt;/p>
&lt;p>The book is directed likewise at researchers and practitioners interested in the broad field of workflow technology. It gives a comprehensive survey of the various aspects of business process research. The overview of prominent representatives of commercial workflow management systems and the rich bibliography provide an invaluable guide for further reading&lt;/p>
&lt;p> &lt;/p></description></item><item><title>A Four Level Architecture for Hypermedia Database Management Systems</title><link>https://big.tuwien.ac.at/phd-thesis/archive/a-four-level-architecture-for-hypermedia-database-management-systems/</link><pubDate>Tue, 19 May 2020 12:38:24 +0000</pubDate><guid>https://big.tuwien.ac.at/phd-thesis/archive/a-four-level-architecture-for-hypermedia-database-management-systems/</guid><description>&lt;p>This work has been finished in March 1998.&lt;/p>
&lt;p>In this thesis the Hypermedia Database Management System (HyperD) Architecture for hypermedia database management systems and the classes needed to implement the architecture are described. The HyperD architecture allows to model the structure as well as the content of hypermedia data in a consistent, highly flexible, and object oriented manner. The HyperD architecture can be extended easily to accommodate new media types and is flexible enough to model domain specific information. This thesis also describes implementation issues regarding a prototypical implementation for images.&lt;/p>
&lt;p>One focus of the work is to show that the concept of physical and logical data independence can be applied beneficially to hypermedia database management systems. The approach to physical data independence presented here takes the characteristics of multimedia data into account and allows a controlled reuse of multimedia objects. The approach to logical data independence presented in this thesis is highly flexible and allows a clean separation of application specific and general knowledge.&lt;/p>
&lt;p>This thesis also shows how the HyperD architecture can be extended with the concept of Corresponding Information Content (CIC). CIC allows to model the amount and quality of the pieces of information in one media object in relationship to the pieces of information in another media object.&lt;/p>
&lt;p> &lt;/p></description></item><item><title>Definition of Behavior in Object-Oriented Databases by View Integration</title><link>https://big.tuwien.ac.at/phd-thesis/archive/definition-of-behavior-in-object-oriented-databases-by-view-integration/</link><pubDate>Tue, 19 May 2020 12:38:24 +0000</pubDate><guid>https://big.tuwien.ac.at/phd-thesis/archive/definition-of-behavior-in-object-oriented-databases-by-view-integration/</guid><description>&lt;p>This work has been finished in September 1998.&lt;/p>
&lt;p>Databases in large organizations are usually designed by a group of people including potential future users of the database who know the application domain from everyday business. The design of databases by view integration means that several users or groups of users define their views on the proposed database. These views are collected and integrated to one conceptual database schema.&lt;/p>
&lt;p>We treat view integration in the context of modeling business processes and workflows and use the object-oriented data model Object/Behavior Diagrams to define the structure and behavior of business objects. In this work, we will focus on the definition and integration of views of the behavior of objects. Behavior of business objects is defined based on a two-schema architecture: Business processes define the overall behavior of business objects according to external business rules, which mainly reflect long-term business rules due to natural facts or law; workflows represent the current processing of business objects in an organization according to internal business rules.&lt;/p>
&lt;p>Users define their views as they perceive processing of business objects in everyday business, thereby modeling workflows. Further, views of different users comprise different information: (1) Views model behavior of different entities of the real world; (2) views define processes at different levels of detail or omit parts of the processes; (3) views contain comparable information that is defined using different modeling concepts; (4) views define specifications of activities by providing an interface or refer to activities without defining an interface.&lt;/p>
&lt;p>The goal of view integration is to define the complete set of object types and business processes in the conceptual database schema. Thus, information relevant for the business processes is extracted from the workflows, the object types of the integrated schema are determined, and a business process as well as the activity specifications are defined for each object type. The goal of view integration is to define object types with business processes in a way that the processing of objects according to a business process in the conceptual schema can be observed as a correct processing in each view if information that is not defined in the view is ignored.&lt;/p>
&lt;p> &lt;/p></description></item><item><title>Active Object-Oriented Databases: From Conceptual Design to Logical Design</title><link>https://big.tuwien.ac.at/phd-thesis/archive/active-object-oriented-databases-from-conceptual-design-to-logical-design/</link><pubDate>Tue, 19 May 2020 12:38:23 +0000</pubDate><guid>https://big.tuwien.ac.at/phd-thesis/archive/active-object-oriented-databases-from-conceptual-design-to-logical-design/</guid><description>&lt;p>This work has been finished in February 1998.&lt;/p>
&lt;p>The design of active object-oriented databases includes modeling the structure of objects, their passive behavior in the form of operations that can be performed on them, and their active behavior in the form of business rules. Business rules are statements about business policies and can be formulated according to the event-condition-action structure of rules provided by active database systems, which allow to react to predefined situations by performing an operation if a certain condition is satisfied when the event occurs.&lt;/p>
&lt;p>An approach that has been followed successfully in conventional database design is to perform database design in two phases: In the first phase, the conceptual design, a high-level graphical representation of the database schema is developed. In the second phase, the logical design, the developed schema is mapped to the data model of the system used for the implementation. We adopt this approach for the design of active object-oriented databases.&lt;/p>
&lt;p>We introduce Active Object/Behavior Diagrams for the conceptual design of active object-oriented databases. Active Object/Behavior Diagrams seamlessly extend Object/Behavior Diagrams, an existing high-level graphical language for modeling the structure and the passive behavior of objects, with concepts for modeling business rules. Modeling business rules at the conceptual level requires different concepts than currently provided by active object-oriented database systems and by recent approaches to active object-oriented database design. Active Object/Behavior Diagrams introduce a graphical rule and event language the meets the identified requirements.&lt;/p>
&lt;p>During logical design, a schema developed with Active Object/Behavior Diagrams is mapped to a logical schema of an existing active object-oriented database system. We present such a mapping for TriGS, a prototype of an active object-oriented database system built on top of the commercial object-oriented database system GemStone (GemStone Systems, Inc.). The mapping decomposes the high-level constructs of Active Object/Behavior Diagrams into lower-level constructs of TriGS. The presented mapping covers all three dimensions of a schema specified with Active Object/Behavior Diagrams: object structure, passive object behavior, and active object behavior.&lt;/p>
&lt;p> &lt;/p></description></item><item><title>Handling Variants of Business Document Models</title><link>https://big.tuwien.ac.at/phd-thesis/archive/handling-variants-of-business-document-models/</link><pubDate>Tue, 19 May 2020 12:38:23 +0000</pubDate><guid>https://big.tuwien.ac.at/phd-thesis/archive/handling-variants-of-business-document-models/</guid><description>&lt;p>This work has been finished in December 2011.&lt;/p>
&lt;p>The United Nations Centre for Trade Facilitation and Electronic Business (UN/CEFACT) envisions seamless information exchange between business partners in electronic commerce. Therefore, UN/CEFACT provides the UML Profile for Core Components for the definition of document models based on UML class diagrams.&lt;/p>
&lt;p>Having used this approach for three years in practice, it became evident that managing document model versions is a prerequisite for successfully utilizing Core Components. While managing software versions in the area of Software Engineering is well understood and successfully applied in industrial projects, the direct application of the same techniques for versioning models is conditionally appropriate. The thesis presents a model registry based on combining techniques from traditional Software Configuration Management with the concepts of Reference Modeling, where similar problems are addressed based on a different background. The benefits of such a registry include a repository for storing models and their variants, proper concepts for preserving consistency across model variants, as well as detecting similar model variants in order to reduce model complexity and duplication.&lt;/p>
&lt;p> &lt;/p></description></item><item><title>Context Aware Core Components Modeling</title><link>https://big.tuwien.ac.at/phd-thesis/archive/context-aware-core-components-modeling/</link><pubDate>Tue, 19 May 2020 12:38:22 +0000</pubDate><guid>https://big.tuwien.ac.at/phd-thesis/archive/context-aware-core-components-modeling/</guid><description>&lt;p>This work has been finished in October 2012.&lt;/p>
&lt;p>Business document standards usually cover a hierarchical structure of thousands of elements that may be relevant in any business context (any industry, any geopolitical region, etc.). In order to use a business document standard in a specific context, user groups define so-called implementation guidelines based on a subset consisting usually of 3 – 5% of the overall elements. When one defines a new implementation guideline for a specific context, one has always to start from scratch, which is time-consuming and also leads to somewhat heterogeneous interpretations of the standard. It is our goal to speed up the development process and to create more homogeneous implementation guidelines by learning from existing models. If we could assign a formal context to existing implementation guidelines, one may guess the subset of a new implementation guideline for a given context. Accordingly, the Ph.D. thesis looks for an approach to model the context of business document standards and for an algorithm to calculate the content model (subset) of a message implementation guideline.&lt;/p>
&lt;p> &lt;/p>
&lt;p>Download the
&lt;a href="https://www.big.tuwien.ac.at/app/uploads/2016/10/Novakovic_D.pdf" target="_blank" rel="noopener">paper&lt;/a>&lt;/p></description></item><item><title>The Model Morphing Approach - Horizontal Transformation of Business Process Models</title><link>https://big.tuwien.ac.at/phd-thesis/archive/the-model-morphing-approach-horizontal-transformation-of-business-process-models/</link><pubDate>Tue, 19 May 2020 12:38:22 +0000</pubDate><guid>https://big.tuwien.ac.at/phd-thesis/archive/the-model-morphing-approach-horizontal-transformation-of-business-process-models/</guid><description>&lt;p>This work has been finished in February 2008.&lt;/p>
&lt;p>Owing to company mergers and business to business interoperability, there is a need for model transformation in the area of business process modeling to facilitate model integration and model synchronisation. This need arises, on one hand, from the fact that there are many different business process modeling formalisms, for example the ADONIS R Standard Modeling Method , UML 2.1 Activity Diagram, the Event-driven Process Chain Method, and, the Business Process Modeling Notation. These formalisms provide different ways to express and represent the same aspects of business process modeling. On the other hand, existing model transformation approaches, like ATL, QVT, and Fujaba, use very general concepts for transforming models for different purposes. However, recurring structures have been observed when transforming models in the area of business process modeling. This leads to the assumption, that there are similar transformation problems in a distinct area. These recurring structures, however, are only inadequately supported by existing transformation approaches.&lt;/p>
&lt;p>This thesis analyzes the different ways of how business process modeling aspects are represented in various business process modeling formalisms. Furthermore, existing transformation approaches are evaluated concerning their suitability for transforming models in the area of business process modeling. Based on this evaluation, special requirements and solutions for model transformations in the area of business process modeling are derived. These solutions lead to the construction of the Model Morphing approach, which consists of an integrated metamodel and morphing methods which operate based on this metamodel. The Model Morphing approach makes it possible to concentrate on the specific transformation problems within a distinct domain. Furthermore, it reuses existing model transformation approaches and reduces the need for excellent programming skills when defining model transformations.&lt;/p>
&lt;p> &lt;/p>
&lt;p>Download the
&lt;a href="https://www.big.tuwien.ac.at/app/uploads/2016/10/Murzek_M.pdf" target="_blank" rel="noopener">paper&lt;/a>&lt;/p></description></item><item><title>Ant Algorithms for Self-Organization in Social Networks</title><link>https://big.tuwien.ac.at/phd-thesis/archive/ant-algorithms-for-self-organization-in-social-networks/</link><pubDate>Tue, 19 May 2020 12:38:21 +0000</pubDate><guid>https://big.tuwien.ac.at/phd-thesis/archive/ant-algorithms-for-self-organization-in-social-networks/</guid><description>&lt;p>This work has been finished in May 2007.&lt;/p>
&lt;p>Peer-to-peer networks and folksonomies are like living organisms, ever growing and changing as time goes on. This thesis addresses the applicability of algorithms derived from the self-organizing and emergent behavior observed from ant colonies to these complex networks for two specific purposes, namely (1) content-based search in unstructured peer-to- peer networks, and (2) the extraction of adaptive user profiles from folksonomies.&lt;/p>
&lt;p>For search in unstructured peer-to-peer networks, the main goal is to find the shortest path from every querying peer to one or more answering peers that possess resources which are appropriate answers for the given query. The S EM A NT algorithm, which is designed for this task, is based on reputation learning. In reputation learning, the information about the remote peers’ resources is gained passively by observing the user queries and their answers that are forwarded through the local peer. Every successful query evokes small updates in the routing tables of those peers that are included in the path between the querying and the answering peer. The routing tables are used for subsequent queries to decide which link to follow in order to find appropriate resources. The S EM A NT algorithm is compliant with the Ant Colony Optimization meta-heuristic, and it employs a probabilistic procedure to select outgoing links for query forwarding. This procedure combines an exploiting strategy, which selects those links currently known as the most appropriate ones, with an exploring strategy, which also follows links not currently known as the best ones with the aim of finding better paths not yet explored. A weight defines the ratio between the strategies.&lt;/p>
&lt;p>Since the S EM A NT algorithm is a content-based approach to peer-to-peer search, its performance depends on how the content is distributed in the network. The evaluation of the algorithm includes an investigation to which extent this is the case. Based on these results, we develop strategies for improvement. Under the assumption that the resources in the network are annotated according to a taxonomy, and that the query vocabulary is restricted to the leaf topics from the same taxonomy, it is possible to consider also the upper-level topics in the query routing procedure of the algorithm in order to increase its performance.&lt;/p>
&lt;p>Ant algorithms include an evaporation feature for integrating a time factor when incrementally creating solutions. This feature is beneficial for the task of learning adaptive user profiles from tagging data. For this purpose we design the Add-A-Tag algorithm, which is based on a combination of an evaporation feature for adapting the user profile to trends over time, and the co-occurrence technique for determining the relationships between tags. The user profiles created with the Add-A-Tag algorithm are semantic networks derived from the structure of the tagging data, and they are adaptive in the sense that they change according to changes in a user’s tagging behavior. In addition to the long-term interests of a user, also his or her short-term interests are included in the profile at any given point of time. We present a tool for visualizing the changes in the profile over time, and we show how to exploit the profile for personalized browsing of annotated data sources.&lt;/p>
&lt;p> &lt;/p>
&lt;p>Download the
&lt;a href="https://www.big.tuwien.ac.at/app/uploads/2016/10/Michlmayr_E.pdf" target="_blank" rel="noopener">paper&lt;/a>&lt;/p></description></item><item><title>High Performance Computing in Finance - On the Parallel Implementation of Pricing and Optimization Models</title><link>https://big.tuwien.ac.at/phd-thesis/archive/high-performance-computing-in-finance-on-the-parallel-implementation-of-pricing-and-optimization-models/</link><pubDate>Tue, 19 May 2020 12:38:21 +0000</pubDate><guid>https://big.tuwien.ac.at/phd-thesis/archive/high-performance-computing-in-finance-on-the-parallel-implementation-of-pricing-and-optimization-models/</guid><description>&lt;p>This work has been finished in May 2006.&lt;/p>
&lt;p>High Performance Computing is useful in the field of finance for solving problems which are defined on models of financial variables in the form of sequences of scenarios along with their realization probabilities. Both the evolution of stock prices and interest rates is frequently described in this manner. Starting from a known state, and covering a future time horizon of multiple periods, these models take the form of scenario trees. As a special case, the structure collapses into a lattice, if the tree is “recombining”. This work deals with the two problem classes of determining prices of financial instruments, and of determining optimal portfolios of assets, with respect to some objective function and constraints. Dynamic optimization techniques allow for multiple planning periods, whereas stochastic dynamic optimization problems take into account also probabilities and exhibit (exponentially growing) tree structures, which can become very large. As an example, a model of ten years of three assets, each of which is described by the extents and probabilities of rising or falling of their respective prices within a year, results in a scenario tree with more than one billion (23 )10 = 1 073 741 824 terminal nodes. Computation times for solving these problems can extend to hours and days, hence high performance computing techniques of achieving speed up are desirable.&lt;/p>
&lt;p>The major approach for performance improvement in this work is parallel computing. It includes the parallel implementation of Monte Carlo simulation techniques as well as of backward induction methods for pricing path dependent interest rate derivatives, in particular constant maturity floaters with embedded options. In the optimization part, the nested Benders decomposition method of multistage stochastic optimization has been parallelized in a synchronous as well as in an asynchronous version. The parallel implementations obtain speedups ranging from reasonable to excellent and demonstrate the potential of high performance computing for financial applications. In addition, they served as case studies in the development of software tools for high performance computing within the framework of the Special Research Program No. F011 Aurora “Advanced Models, Applications and Software Systems for High Performance Computing” of the Austrian Science Fund (FWF).&lt;/p>
&lt;p>The data parallel programming language HPF+, with extensions for clusters of SMPs, has been successfully employed in the implementation of pricing algorithms. A path notation has been specified as an extension to Fortran 95, allowing for the high level formulation of parallel algorithms operating on lattice structures. The parallel programming model of a distributed active tree has been designed and implemented on top of Java’s threads and RMI. Parallel implementations of the nested Benders decomposition algorithm in Java demonstrate that this is a suitable language for high performance computing. The OpusJava component framework, as well as the JavaSymphony class library, and the distributed active tree model proved their usefulness as programming support environments in the implementation of parallel tree structured algorithms.&lt;/p>
&lt;p>In addition to the parallelization of sequential existing algorithms, the improvement of known parallelization approaches, and the use of specialized parallel programming languages and programming models, an increase in performance has been achieved by algorithmic developments. The generalization of the classical backward induction method allows for the faster calculation, i.e., in linear instead of exponential time, of prices of a class of instruments exhibiting “limited” path dependence, demonstrating that highly effective approaches of performance improvement combine the levels of algorithms and parallel implementation.&lt;/p>
&lt;p> &lt;/p>
&lt;p>Download the
&lt;a href="https://www.big.tuwien.ac.at/app/uploads/2016/10/Moritsch_H.pdf" target="_blank" rel="noopener">paper&lt;/a>&lt;/p></description></item><item><title>Testing of UML Activity Diagrams</title><link>https://big.tuwien.ac.at/phd-thesis/archive/testing-of-uml-activity-diagrams/</link><pubDate>Tue, 19 May 2020 12:38:21 +0000</pubDate><guid>https://big.tuwien.ac.at/phd-thesis/archive/testing-of-uml-activity-diagrams/</guid><description>&lt;p>In model-driven development, modeling languages provide the means for software development on a higher level of abstraction than traditional general purpose languages. However, compared to general purpose languages, these modeling languages often lack the proper tool support, such as tools for debugging and testing. Especially testing is essential to achieve a high quality of the final software product. In this work, we propose an approach for testing UML models at the model level to ensure the validation of their quality before the executable code is produced out of these models. In particular, we propose a dedicated testing language for specifying and executing test scenarios of UML activity diagrams based on OMG’s fUML standard.&lt;/p></description></item><item><title>REA-DSL: Business Model Driven Data Engineering</title><link>https://big.tuwien.ac.at/phd-thesis/archive/rea-dsl-business-model-driven-data-engineering/</link><pubDate>Tue, 19 May 2020 12:38:20 +0000</pubDate><guid>https://big.tuwien.ac.at/phd-thesis/archive/rea-dsl-business-model-driven-data-engineering/</guid><description>&lt;p>This work has been finished in June 2012.&lt;/p>
&lt;p>Accounting Information Systems (AIS) are essential for companies not only to record and track what events are happening or what events have happened in the past, they are also one of the most important tools for management to predict the financial future of a firm and take according actions. To enable an AIS to precisely record economic data and apply reasoning on them, it is crucial that the data structure of an AIS is built upon the economic phenomenas of a company’s business. Accordingly, it is already important to have a detailed understanding of the company’s economic actions at the design time of an AIS.&lt;/p>
&lt;p>Like in most software development projects, the dilemma during design time of an IT product is the language barrier between the domain expert, providing vital input for defining the requirements, and the IT professional, designing and developing the IT product. In most cases the domain expert is not capable of understanding IT specific terms, and the IT professional is not capable of completely understanding the specific area of the domain expert. Nevertheless, to successfully complete an IT product, these two groups still need to unambiguously communicate with each other by using a common language.&lt;/p>
&lt;p>When designing an AIS, the domain at hand is the accounting/business domain. Thus, a business modeling language describing economic phenomenas of a company can be used as such a common language to define requirements. One powerful business modeling language today is the Resource-Event-Agent ontology (REA). It not only allows describing events of the present and the past, it also allows specification of commitments made for future events. Consequently, it perfectly fits our requirement to capture the economic phenomenas of an AIS. However, REA is somewhat vague in the definition of its concepts and the current representation is merely IT related, which makes it hard to be understood by business experts. Accordingly, REA still cannot be used as a common communication language for the AIS design phase.&lt;/p>
&lt;p>Given these limitations, in this thesis we have taken upon the challenge to develop an unambiguous and intuitive graphical domain-specific representation for the REA ontology called the REA-DSL. First, we formalize the REA ontology by providing a REA-DSL meta-model incorporating the REA concepts resources, events, agents, commitments, and types as well as concepts known from database modeling. Subsequently, we create a graphical notation for the REA-DSL using different shapes for different REA concepts. Additionally, to reduce the complexity of the models, we split the REA-DSL into five interlinked views. A serialization format for the REA-DSL is provided by the REA-XML language. Furthermore, we specify a mapping between the conceptual REA-DSL and a database description language. This enables the semi-automatic generation of database structures for an AIS.&lt;/p>
&lt;p>The presented REA-DSL serves as an unambiguous and powerful business modeling language which can be used by IT and business experts for faster designing a robust AIS.&lt;/p>
&lt;p>Abstract and paper may be found in our &lt;a class="external" href="http://publik.tuwien.ac.at/showentry.php?ID=223117&amp;amp;lang=2">publication database&lt;/a>.&lt;/p></description></item><item><title>Self-Organization of Software Libraries: An Artificial Neural Network Approach</title><link>https://big.tuwien.ac.at/phd-thesis/archive/self-organization-of-software-libraries-an-artificial-neural-network-approach/</link><pubDate>Tue, 19 May 2020 12:38:20 +0000</pubDate><guid>https://big.tuwien.ac.at/phd-thesis/archive/self-organization-of-software-libraries-an-artificial-neural-network-approach/</guid><description>&lt;p>This work has been finished in November 1994.&lt;/p></description></item><item><title>Adaptable Model Versioning based on Model Transformation By Demonstration</title><link>https://big.tuwien.ac.at/phd-thesis/archive/adaptable-model-versioning-based-on-model-transformation-by-demonstration/</link><pubDate>Tue, 19 May 2020 12:38:19 +0000</pubDate><guid>https://big.tuwien.ac.at/phd-thesis/archive/adaptable-model-versioning-based-on-model-transformation-by-demonstration/</guid><description>&lt;p>This work has been finished in December 2011.&lt;/p>
&lt;p>&lt;em>Model-driven engineering&lt;/em> (MDE) is evermore adopted in academia and industry for being a new paradigm helping software developers to cope with the ever increasing complexity of software systems being developed. In MDE, software models constitute the central artifacts in the software engineering process, going beyond their traditional use as blueprints, and act as the single source of information for automatically generating executable software.&lt;/p>
&lt;p>Although MDE is a promising approach to master the &lt;em>complexity&lt;/em> of software systems, so far it lacks proper concepts to deal with the ever growing &lt;em>size&lt;/em> of software systems in practice. Developing a large software system entails the need for a large number of collaborating developers. Unfortunately, &lt;em>collaborative development of models&lt;/em> is currently not sufficiently supported. Traditional versioning systems for code fail for models, because they treat models just as plain text files and, as a consequence, neglect the graph-based nature of models.&lt;/p>
&lt;p>A few dedicated &lt;em>model versioning approaches&lt;/em> have been proposed, which directly operate on the models and not on the models‘ textual representation. However, these approaches suffer from four major deficiencies. First, they either support only one modeling language or, if they are &lt;em>generic&lt;/em>, they do not consider important specifics of a modeling language. Second, they do not allow the specification of &lt;em>composite operations&lt;/em> such as refactorings and thus, third, they &lt;em>neglect&lt;/em> the importance of respecting the original intention behind composite operations for detecting conflicts and constructing a merged model. Fourth, the types of &lt;em>detectable conflicts&lt;/em> among concurrently applied operations is &lt;em>insufficient&lt;/em> and &lt;em>not extensible by users&lt;/em>.&lt;/p>
&lt;p>To tackle these deficiencies, we present four major contributions in this thesis. First, we introduce an &lt;em>adaptable model versioning framework&lt;/em>, which aims at combining the advantages of two worlds; the proposed framework is generic and offers out-of-the-box support for &lt;em>all modeling languages&lt;/em> conforming to a common meta-metamodel, but also allows to be &lt;em>adapted&lt;/em> for enhancing the versioning support for &lt;em>specific modeling languages&lt;/em>. Second, we propose a novel technique, called &lt;em>model transformation by demonstration&lt;/em>, for easily specifying composite operations. Besides being executable, these composite operation specifications also constitute the &lt;em>adaptation artifacts&lt;/em> for enhancing the proposed versioning system. More precisely, with our third contribution, we present a novel approach for &lt;em>detecting applications of specified composite operations&lt;/em> without imposing any dependencies on the employed modeling environment. Fourth, we present a novel approach for detecting &lt;em>additional types of conflicts&lt;/em> caused by &lt;em>concurrently applied composite operations&lt;/em>. Furthermore, we contribute additional techniques for revealing potentially obfuscated or unfavorable merge results. Besides introducing the contributions from a conceptual point of view, we provide an open source implementation of these concepts and present empirical case studies and experiments for evaluating their usefulness and ease of use.&lt;/p>
&lt;p>Download the
&lt;a href="http://www.slideshare.net/PhilipLanger/adaptable-model-versioning-using" title="Slides on Slideshare" target="_blank" rel="noopener">slides&lt;/a>&lt;/p>
&lt;p>Abstract and paper may be found in our &lt;a class="external" href="http://publik.tuwien.ac.at/showentry.php?ID=203931&amp;amp;lang=2">publication database&lt;/a>.&lt;/p>
&lt;p>Download the
&lt;a href="https://www.big.tuwien.ac.at/app/uploads/2016/10/Langer_P.pdf" target="_blank" rel="noopener">paper&lt;/a>&lt;/p></description></item><item><title>Business Documents for Inter-Organisational Business Processes</title><link>https://big.tuwien.ac.at/phd-thesis/archive/business-documents-for-inter-organisational-business-processes/</link><pubDate>Tue, 19 May 2020 12:38:19 +0000</pubDate><guid>https://big.tuwien.ac.at/phd-thesis/archive/business-documents-for-inter-organisational-business-processes/</guid><description>&lt;p>This work has been finished in December 2009.&lt;/p>
&lt;p>Automated business-to-business (B2B) interactions between companies are constantly superseding old paper-based processes. This automation of inter-organizational processes requires a two-fold agreement between the participating business partners. First of all, business partners must agree on a common process choreography, unambiguously defining the exact exchange order of business documents in an inter-organizational business process. Consequently, business partners must agree on the structure of the exchanged business information as well. The two main business document paradigms, which are we elaborate on in this thesis, are top-down business document standards and bottom-up business document standards. The research question, this thesis aims to solve, is how to provide appropriate methods for the definition of business documents for inter-organizational business processes. Due to their special characteristics, such as the involvement of various stakeholders from different companies, the definition of business documents for inter-organizational business processes is not as straightforward as the definition of business documents for intra-organizational business processes. For the definition of inter-organizational business documents we employ two different approaches – a top-down approach and a bottom-up approach. For both approaches we provide appropriate methods for the definition of business documents, the mapping between different business document definitions, and the derivation of XML-based deployment artifacts from business document definitions. We thoroughly cover state-of-the art in the domain of inter-organizational business documents and inter-organizational business processes. This thesis starts by giving an introduction to the domain of Electronic Data Interchange (EDI) and shows the transition of data-centric EDI solutions to modern B2B systems in Chapter 1. Thereby, the specific requirements for B2B interactions are elaborated – in particular in regard to the definition of the exchanged business information. We motivate the findings of this thesis using an accompanying example from the domain of pan-European waste transport, which is introduced in Chapter 2. In Chapter 3 we provide a survey of current state-of-the-art in business documents standards. Chapter 4 provides an introduction to UN/CEFACT’s Core Components, a top-down business document standard which is key to this thesis. In a nutshell, core components are implementation neutral building blocks for assembling business documents. Although this implementation neutrality is one of the strengths of core components, it hinders a broad diffusion of the standard, since no common representation format for core components is available. To address this issue, this thesis provides three reference representation formats for core components: (i) a UML Profile for Core Components (Chapter 5), (ii) a Domain Specific Language for Core Components (Chapter 6), (iii) and a Web Ontology Language representation for Core Components (Chapter 7). The derivation of XML Schema artifacts from core components, which may be deployed to IT systems, is covered in Chapter 8. A successful diffusion of core Components may only be achieved if a broad user community has access to the necessary core component definitions. Consequently, we provide a registry meta-model for core components in Chapter 9. Bottom-up business document standards are subject to discussion in the second part of this thesis. Thereby, domain specific extensions to bottom-up document standards are introduced in Chapter 10. Consequently, we examine how to map bottom-up standard definitions to core component based top-down standard definitions in Chapter 11. Finally, we show how to combine business choreography models and business document models in Chapter 12. Related work is discussed in Chapter 13 and Chapter 14 concludes the contributions of this thesis. In summary this thesis provides the following seven contributions: (1) An overview of business document standards, based on standard clusters; (2) three reference representation formats for core components using the Unified Modeling Language, Domain Specific Languages, and Web Ontology Language for Core Components; (3) an unambiguous derivation of XML Schema artifacts from UML based core component models; (4) a registry meta-model for a core component registry; (5) domain specific extensions for an XML based bottom-up business document standard; (6) a mapping of bottom-up business document standards to top-down business documents standards; (7) an integration of UML based core component models in UML based business choreography models. In short the overall approach facilitates the definition of business documents in an inter-organizational context and fosters reuse of existing business document definitions.&lt;/p>
&lt;p>Abstract and paper may be found in our &lt;a class="external" href="http://publik.tuwien.ac.at/showentry.php?ID=183994&amp;amp;lang=2">publication database&lt;/a>.&lt;/p></description></item><item><title>Defining Executable Modeling Languages with fUML</title><link>https://big.tuwien.ac.at/phd-thesis/archive/defining-executable-modeling-languages-with-fuml/</link><pubDate>Tue, 19 May 2020 12:38:19 +0000</pubDate><guid>https://big.tuwien.ac.at/phd-thesis/archive/defining-executable-modeling-languages-with-fuml/</guid><description>&lt;p>This work has been finished in December 2014.&lt;/p>
&lt;p>Model-driven engineering (MDE) is a software development paradigm aiming to cope with the growing complexity of software systems by raising the level of abstraction. In this paradigm, a system is defined by means of models using modeling languages that enable developers to abstract away from implementation and platform details. From the models, complete implementations may be (semi-)automatically generated by utilizing model transformation techniques. As MDE puts models into the center of software development, adequate methods for creating, analyzing, and utilizing models are crucial. Due to the large body of used modeling languages, means for efficiently developing adequate tool support for modeling languages are needed. To address this need, the automation techniques provided by MDE may also be applied to automate the development of such tool support. This is current practice for developing syntax-based tools. However, the automated development of semantics-based tools has not reached the same level of maturity yet. The goal of this thesis is to fill this gap and provide a solution for automating the development of semantics-based tools for executable modeling languages. Therefore, a language and methodology for developing behavioral semantics specifications based on the standardized language fUML are proposed. To provide the basis for developing semantics-based tools, the execution environment of fUML was extended with means for execution control, runtime observation, and runtime analysis. Based on these extensions, a generic model execution environment for modeling languages whose behavioral semantics is defined with fUML was developed. This environment provides the foundation for developing semantics-based tools for executable modeling languages, which has been shown by the implementation of a semantic model differencing tool and other semantics-based tools.&lt;/p>
&lt;p>Abstract and paper may be found in our &lt;a class="external" href="http://publik.tuwien.ac.at/showentry.php?ID=233990&amp;amp;lang=2">publication database&lt;/a>.&lt;/p>
&lt;p>Download the
&lt;a href="https://www.big.tuwien.ac.at/app/uploads/2016/10/Mayerhofer_T.pdf" target="_blank" rel="noopener">paper&lt;/a>&lt;/p></description></item><item><title>Conceptual Design of Active Object-Oriented Databases</title><link>https://big.tuwien.ac.at/phd-thesis/archive/conceptual-design-of-active-object-oriented-databases/</link><pubDate>Tue, 19 May 2020 12:38:18 +0000</pubDate><guid>https://big.tuwien.ac.at/phd-thesis/archive/conceptual-design-of-active-object-oriented-databases/</guid><description>&lt;p>This work has been finished in September 1997.&lt;/p>
&lt;p>Business rules are statements about business policies and can be formulated according to the event-condition-action structure of rules provided by active database systems, which allow to react to predefined situations by performing an operation if a certain condition is satisfied when the event occurs.&lt;/p>
&lt;p>The conceptual design of active object-oriented databases includes modeling the structure of objects, their passive behavior (the operations that can be peformed on objects), and their active behavior (rules that allow objects to react autonomously to predefined situations by performing an operation). Modeling business rules at the conceptual level by means of the active behavior of objects requires different concepts than currently provided by active object-oriented database systems and by recent approaches to active object-oriented database design.&lt;/p>
&lt;p>This thesis presents a high-level graphical language called Active Object/Behavior Diagrams, which meets the requirements identified for modeling business rules at the conceptual level. Active Object/Behavior Diagrams extend the already introduced Object/Behavior Diagrams with Situation/Activation Diagrams, a graphical rule and event language.&lt;/p>
&lt;p>In order to cope with the complex domain of business applications, concepts for specializing the object structure and the passive behavior have been elaborated and presented in the diverse literature. Specializing active behavior (business rules) has received little attention so far. This thesis extends the specialization concepts already defined for Object/Behavior Diagrams with the concepts for specializing Situation/Activation Diagrams.&lt;/p>
&lt;p>The usage of modeling concepts is constrained by a set of consistency rules. They have the designer stick to a correct usage of the modeling concepts in order to achieve a consistent database schema. Even if all consistency rules are obeyed, different designers may yield different consistent database schemata, which may differ in their quality. This thesis presents guidelines for the conceptual design of active behavior in active object-oriented databases. These design guidelines should help the designer to achieve a consistent as well as a high-quality database schema, i.e., a comprehensible and maintainable database schema.&lt;/p>
&lt;p> &lt;/p></description></item><item><title>Monitoring von verteilten Systemen</title><link>https://big.tuwien.ac.at/phd-thesis/archive/monitoring-von-verteilten-systemen/</link><pubDate>Tue, 19 May 2020 12:38:18 +0000</pubDate><guid>https://big.tuwien.ac.at/phd-thesis/archive/monitoring-von-verteilten-systemen/</guid><description>&lt;p>This work has been finished in June 2000.&lt;/p>
&lt;p>Enhancements to computer systems and networking technologies have lead to an increasing decentralization of services and data which implies the usage of common resources (e.g. networks) and more parallelization of processes in application systems to a greater extent. One of the advantages of these systems is that they can be better adapted to physical, organizational and software-technological requirements.&lt;/p>
&lt;p>Developers of distributed systems are confronted in the construction process with problems which do not appear or only appear in a restricted form in the development of non-distributed systems. Examples of such problems are: mapping distributed resources and/or processes onto a set of computers; paralleling process steps; identification and handling of faults, etc. Monitoring and dynamic program analysis should support software development of distributed systems. The support should occur in such a way that system requirements can be met, the above mentioned problems can be solved, and distributed systems can be observed.&lt;/p>
&lt;p>The work is divided into seven chapters. Besides the chapters introduction and conclusion, there are five chapters with the following topics: terms of distributed systems; distributed systems requirements and problems during the development of such systems; monitoring concepts; existing monitoring systems; and the monitoring system Orwell.&lt;/p>
&lt;p>The second chapter describes important terms of distributed systems. Starting with the term »system« , a characterization of distributed system will be made, to discuss important properties of these systems. Based on the properties and terms, we discuss important concepts and mechanisms, which play an important role in the construction of distributed systems.&lt;/p>
&lt;p>The third chapter describes on the basis of the above mentioned concepts and mechanisms, important aspects of distributed systems from the view of software engineering. Such aspects are reliability, fault tolerance, efficiency, scalability and security. After that, we discuss problems of the development process of distributed systems. Additionally, object-oriented systems will be discussed. Furthermore, we will discuss aspects like time and causality, which are important for monitoring distributed systems.&lt;/p>
&lt;p>The fourth chapter consists of a discussion of basic monitoring-system requirements. The main part of the chapter is about the general monitoring model of Mansouri-Samani[95] and its concepts, activities, and strategies for the observation and analysis of distributed systems.&lt;/p>
&lt;p>The fifth chapter consists of a presentation of selected monitoring research approaches and tools.&lt;/p>
&lt;p>The sixth chapter describes the monitoring system Orwell. The architecture of the distributed and object-oriented analysis environment and its functionality will be discussed. Finally it contains a comparison and evaluation with other approaches.&lt;/p>
&lt;p>This work concludes with a summary of results as well as a discussion of future developments and possible research directions.&lt;/p>
&lt;p> &lt;/p></description></item><item><title>Business Process Modelling - Languages, Goals, and Variabilities</title><link>https://big.tuwien.ac.at/phd-thesis/archive/business-process-modelling-languages-goals-and-variabilities/</link><pubDate>Tue, 19 May 2020 12:38:17 +0000</pubDate><guid>https://big.tuwien.ac.at/phd-thesis/archive/business-process-modelling-languages-goals-and-variabilities/</guid><description>&lt;p>This work has been finished in January 2008.&lt;/p>
&lt;p>Over the last decade more and more companies started to optimize their business processes in a way to meet its business goals. They develop business process models defining which activities have to be executed in which order under which conditions by whom and by using which resources. For this purpose a lot of different approaches to business process modelling have been developed, which resulted in many different Business Process Modelling Languages (BPMLs).&lt;/p>
&lt;p>The definition of a business process has to cover many different aspects (e.g. control flow, organizational view, data view, etc.). A perfect business process modelling approach would address all the different aspects. Unfortunately, none of the existing approaches provides concepts for addressing all of these aspects. Each of them concentrates on some aspects. The focus on certain aspects is mainly due to the different applications areas, e.g. business engineering or software engineering etc.&lt;/p>
&lt;p>Although BPMLs are well established in industry and science, a comprehensive evaluation or a framework for an evaluation to compare the different BPMLs is still missing. Thus, it is the goal of this thesis to provide an evaluation framework for the comparison of BPMLs and to apply this framework in the evaluation of the currently most popular BPMLs. The resulting framework is based on a generic metamodel that captures all of the concepts appearing in any of the state-of-the-art BPMLs. On a high level this framework addresses the following views: Business Process Context Perspective, Behavioural Perspective, Functional Perspective, Informational Perspective, and Organisational Perspective. An evaluation based on this framework checks whether the certain aspects in each of these perspectives is supported by the concepts of each of the considered BPMLs. In the evaluation of this thesis, we used the following languages: UML 2 Activity Diagram, Business Process Modelling Notation, Event Driven Process Chain, IDEF3, Petri Net, Role Activity Diagram.&lt;/p>
&lt;p>According to the evaluation we were able to identify three main problems in current BPMLs. The first problem is that the definition of the dependency between business processes and their supporting software systems is inadequately supported. In our approach we support the elicitation of requirements from business process models for the software systems to be developed by extending current BPMLs with software requirements and components to ensure a business-goal oriented software development.&lt;/p>
&lt;p>The second problem concerns the variability of similar, but well-distinguished software products within a software product line. These software products not only differ in its structural definition, but also in the process to create them. Today, variability modelling is a domain specific modelling technique that is limited to the structural definition of similar software products. In our approach we extend the concepts of variability modeling to integrate the dynamical aspects into the UML. The resulting approach is based on a well defined dependency between UML class diagrams and UML activity diagrams.&lt;/p>
&lt;p>The third problem is that current conceptual BPMLs do not provide explicit modelling means for process goals and their measures. The modelling of goals and its monitoring is a critical step in business process modeling. Hence, we extend the metamodels of UML 2 AD, EPC and BPMN with business process goals and performance measures. These concepts become explicitly visible in the corresponding models. Furthermore, a mapping of the performance measures onto the Business Process Execution Language (BPEL) enables their monitoring in an execution environment.&lt;/p>
&lt;p> &lt;/p>
&lt;p>Download the
&lt;a href="https://www.big.tuwien.ac.at/app/uploads/2016/10/Korherr_B.pdf" target="_blank" rel="noopener">paper&lt;/a>&lt;/p></description></item><item><title>Model Driven Development of Inter-organizational Workflows</title><link>https://big.tuwien.ac.at/phd-thesis/archive/model-driven-development-of-inter-organizational-workflows/</link><pubDate>Tue, 19 May 2020 12:38:17 +0000</pubDate><guid>https://big.tuwien.ac.at/phd-thesis/archive/model-driven-development-of-inter-organizational-workflows/</guid><description>&lt;p>This work has been finished in May 2004.&lt;/p>
&lt;p>The rise of the web has spurred automation of cooperation among organizations. Interorganizational workflows support such cooperations in a way similar to traditional intraorganizational workflows that support business processes within an organization. The distinct characteristics of inter-organizational workflows, such as heterogeneity and autonomy of the participating software systems, has lead to the development of several new XML-based technologies supporting inter-organizational cooperation. These technologies, however, introduce additional complexity into the development of inter-organizational workflows. Model driven development is an approach to master these complexities by using higher-level models as main development artifacts. In the model driven architecture (MDA), UML can be employed as common modelling language for models at various levels of abstraction and various technologies.&lt;/p>
&lt;p>The goal of this thesis is to exploit the application of MDA for model driven development of inter-organizational workflows. In this respect, several contributions are made. First, a survey of current XML-based technologies is given, discussing the commonalities and differences of the various languages and identifying requirements on any modelling language supporting them as target technologies. Second, an extension of UML for platform-specific modelling of XML documents is defined, specifically addressing the problem of round-trip engineering. Third, different ways of extending schema specifications for XML documents are investigated, addressing the lack of expressiveness of XML schemas as compared to UML models.&lt;/p>
&lt;p> &lt;/p>
&lt;p>Download the
&lt;a href="https://www.big.tuwien.ac.at/app/uploads/2016/10/Kramler_G.pdf" target="_blank" rel="noopener">paper&lt;/a>&lt;/p></description></item><item><title>Oberon-D - On Adding Database Funktionality to an Object-Oriented Development Environment</title><link>https://big.tuwien.ac.at/phd-thesis/archive/oberon-d-on-adding-database-funktionality-to-an-object-oriented-development-environment/</link><pubDate>Tue, 19 May 2020 12:38:17 +0000</pubDate><guid>https://big.tuwien.ac.at/phd-thesis/archive/oberon-d-on-adding-database-funktionality-to-an-object-oriented-development-environment/</guid><description>&lt;p>This work has been finished in October 1997.&lt;/p></description></item><item><title>Metadata-Based Middleware for Integrating Information Systems</title><link>https://big.tuwien.ac.at/phd-thesis/archive/metadata-based-middleware-for-integrating-information-systems/</link><pubDate>Tue, 19 May 2020 12:38:16 +0000</pubDate><guid>https://big.tuwien.ac.at/phd-thesis/archive/metadata-based-middleware-for-integrating-information-systems/</guid><description>&lt;p>This work has been finished in April 1999.&lt;/p>
&lt;p>Today, information systems are widely employed for administrating large amounts of data of various application areas. Due to historical, organizational, and technical reasons, their infrastructure is usually characterized by the keywords distribution and heterogeneity, in the sense that an organization comprises several physically distributed and heterogeneous information system components. In fact, particulary within an organization, such system components are frequently interrelated. To enable their cooperation and to ensure one common access, it is required to achieve interoperability and to further integrate them logically. However, distribution and heterogeneity represent the most relevant barriers against the development of interoperable, logically integrated information systems.&lt;/p>
&lt;p>This thesis presents three systems realizing middleware to overcome these barriers, called COMan, IRO-DB, and OASIS. COMan integrates an object-oriented application and a relational database, providing persistence for complex objects and object-oriented manipulation of relational data. IRO-DB focuses on the integration of arbitrary relational as well as object-oriented database systems and constitutes a database federation. OASIS deals with the integration of arbitrary security concepts at an abstract description level, enabling their central monitoring and administration despite heterogeneity.&lt;/p>
&lt;p>All these systems achieve logical integration. They provide transparency with respect to distribution and heterogeneity while preserving the autonomy of the system components being integrated as far a possible. To allow for a flexible and generic integration all systems realize a metadata-based approach. This metadata-based approach prevents the hard-coding and distribution of the transformation knowledge, required due to distribution and heterogeneity aspects, over various system components. Rather, it is centralized in a reified way within a repository, thus, resulting in a system able to perform the essential transformations automatically and open to adapt to changing requirements.&lt;/p>
&lt;p>Based on the experience gained by developing these three systems, a criteria catalogue is developed allowing to categorize and evaluate different kinds of metadata-based middleware. The applicability of this catalogue is demonstrated by comparing the three introduced approaches by means of the proposed criteria.&lt;/p>
&lt;p> &lt;/p></description></item><item><title>Smart Matching – An Approach for the Automatic Generation of Executable Schema Mappings</title><link>https://big.tuwien.ac.at/phd-thesis/archive/smart-matching-an-approach-for-the-automatic-generation-of-executable-schema-mappings/</link><pubDate>Tue, 19 May 2020 12:38:16 +0000</pubDate><guid>https://big.tuwien.ac.at/phd-thesis/archive/smart-matching-an-approach-for-the-automatic-generation-of-executable-schema-mappings/</guid><description>&lt;p>This work has been finished in September 2008.&lt;/p>
&lt;p>Information integration has a long history in computer science [1]. It has started with theintegration of database schemas in the early eighties. With the rise of the Semantic Web andthe emerging abundance of ontologies, the need for an automatic information integration increased further.&lt;/p>
&lt;p>Information integration in general and automatic information integration in particular is a huge and challenging research area. One of the main problems is handling semantic heterogeneity and schema heterogeneity. Manually finding the semantically overlapping parts of schemas is a tedious problem. Furthermore, writing integration code is a labor intensive, error-prone, and cumbersome task. A lot of approaches have already been developed to automate this work. Nevertheless, not all integration problems have been solved so far.&lt;/p>
&lt;p>Matching tools are used to automatically find similarities between schemas. The results of these tools are simple correspondences. Based on these correspondences, one is able to write integration code. However, the simple correspondences are just suggestions and must be verified manually. Hence, the completeness and correctness of the resulting correspondences may not be assured. Furthermore, it is not possible to automatically derive transformation code for all found simple correspondences.&lt;/p>
&lt;p>In order to write transformation code, different kinds of transformation languages have been developed. The produced code is too customized for a specific type of schema to be easily reused for other integration problems. Hence, to the best of our knowledge, there exists no transformation language to develop reusable transformation patterns for different kinds of heterogeneity problems.&lt;/p>
&lt;p>This thesis addresses the heterogeneity problems, as well as the lack of reusable transformation code, and the need for establishing correct and complete correspondences between schemas. The first two problems are tackled by developing an executable declarative mapping language, which is able to cope with the core of schema heterogeneity problems. In contrast to simple correspondences, this mapping language is able to express more constraints. Based on these more expressive mappings, the execution code is automatically derived. The third problem is tackled by a self-tuning, iterative matching approach. This approach is based on the developed mapping language. Mapping strategies are responsible for the application of mapping operators. Based on the executable mapping suggestion, completeness and correctness are achieved for a provided set of instance models by a test-driven approach. These instance models are used to evaluate the produced mapping model. The prototype of this self-tuning approach is called SmartMatcher.&lt;/p>
&lt;p>[1] Laura Haas. Beauty and the Beast: The Theory and Practice of Information Integration. In 11th International Conference on Database Theory, Springer LNCS 4353, 2007, pp. 28-43.&lt;/p>
&lt;p> &lt;/p>
&lt;p>Download the
&lt;a href="https://www.big.tuwien.ac.at/app/uploads/2016/10/Kargl_H.pdf" target="_blank" rel="noopener">paper&lt;/a>&lt;/p></description></item><item><title>A Univied Peer-to-Peer Database Framework for XQueries over Dynamic Distributed Content and its Application for Scalable Service Discovery</title><link>https://big.tuwien.ac.at/phd-thesis/archive/a-univied-peer-to-peer-database-framework-for-xqueries-over-dynamic-distributed-content-and-its-application-for-scalable-service-discovery/</link><pubDate>Tue, 19 May 2020 12:38:15 +0000</pubDate><guid>https://big.tuwien.ac.at/phd-thesis/archive/a-univied-peer-to-peer-database-framework-for-xqueries-over-dynamic-distributed-content-and-its-application-for-scalable-service-discovery/</guid><description>&lt;p>This work has been finished in March 2002.&lt;/p>
&lt;p>In a large distributed system spanning administrative domains such as a Grid, it is desirable to maintain and query dynamic and timely information about active participants such as services, resources and user communities. The web services vision promises that programs are made more flexible and powerful by querying Internet databases (registries) at runtime in order to discover information and network attached third-party building blocks. Services can advertise themselves and related metadata via such databases, enabling the assembly of distributed higher-level components. In support of this vision, this thesis shows how to support expressive general-purpose queries over a view that integrates autonomous dynamic database nodes from a wide range of distributed system topologies.&lt;/p>
&lt;p>We motivate and justify the assertion that realistic ubiquitous service and resource discovery requires a rich general-purpose query language such as XQuery or SQL. Next, we introduce the Web Service Discovery Architecture (WSDA), which subsumes an array of dis- parate concepts, interfaces and protocols under a single semi-transparent umbrella. WSDA specifies a small set of orthogonal multi-purpose communication primitives (building blocks) for discovery. These primitives cover service identification, service description retrieval, data publication as well as minimal and powerful query support. The individual primitives can be combined and plugged together by specific clients and services to yield a wide range of be- haviors and emerging synergies. Based on WSDA, we introduce the hyper registry, which is a centralized database node for discovery of dynamic distributed content, supporting XQueries over a tuple set from an XML data model. We address the problem of maintaining dynamic and timely information populated from a large variety of unreliable, frequently changing, autonomous and heterogeneous remote data sources.&lt;/p>
&lt;p>However, in a large cross-organizational system, the set of information tuples is partitioned over many such distributed nodes, for reasons including autonomy, scalability, availability, performance and security. This suggests the use of Peer-to-Peer (P2P) query technology. Consequently, we take the first steps towards unifying the fields of database management systems and P2P computing. As a result, we propose the WSDA based Unified Peer-to-Peer Database Framework (UPDF) and its associated Peer Database Protocol (PDP), which are unified in the sense that they allow to express specific applications for a wide range of data types (typed or untyped XML, any MIME type), node topologies (e.g. ring, tree, graph), query languages (e.g. XQuery, SQL), query response modes (e.g. Routed, Direct and Referral Response), neighbor selection policies, pipelining, timeout and other scope characteristics.&lt;/p>
&lt;p>The uniformity and wide applicability of our approach is distinguished from related work, which (1) addresses some but not all problems, and (2) does not propose a unified framework.&lt;/p>
&lt;p> &lt;/p>
&lt;p>Download the
&lt;a href="https://www.big.tuwien.ac.at/app/uploads/2016/10/Hoschek_W.pdf" target="_blank" rel="noopener">paper&lt;/a>&lt;/p></description></item><item><title>Adaptivity in Learning Management Systems focussing on Learning Styles</title><link>https://big.tuwien.ac.at/phd-thesis/archive/adaptivity-in-learning-management-systems-focussing-on-learning-styles/</link><pubDate>Tue, 19 May 2020 12:38:15 +0000</pubDate><guid>https://big.tuwien.ac.at/phd-thesis/archive/adaptivity-in-learning-management-systems-focussing-on-learning-styles/</guid><description>&lt;p>his work has been finished in December 2007.&lt;/p>
&lt;p>Learning management systems (LMSs) such as WebCT, Blackboard, and Moodle are commonly and successfully used in e-education. While they focus on supporting teachers in creating and holding online courses, they typically do not consider the individual differences of learners. However, learners have different needs and characteristics such as prior knowledge, motivation, cognitive traits, and learning styles. Recently, increasing attention is paid to characteristics such as learning styles, their impact on learning, and how these individual characteristics can be supported by learning systems. These investigations are motivated by educational theories, which argue that providing courses which fit the individual characteristics of students makes learning easier for them and thus, increases their learning progress.&lt;/p>
&lt;p>This thesis focuses on extending LMSs to provide adaptivity by incorporating learning styles according to the Felder-Silverman learning style model. An automated approach for identifying learning styles from the behaviour and actions of learners has been designed, implemented, and evaluated, demonstrating that the proposed approach is suitable for identifying learning styles. Based on this approach, a standalone tool for automatic detection of learning styles in LMSs has been implemented.&lt;/p>
&lt;p>Furthermore, investigations have been conducted on improving the automatic detection of learning styles by using additional information from cognitive traits. The potential of working memory capacity is investigated. Results of a comprehensive literature review and two comprehensive evaluation studies show that relationships between working memory capacity and learning styles exist and that these relationships can provide additional information for the detection process of learning styles.&lt;/p>
&lt;p>Moreover, a concept for extending LMSs by enabling them to automatically generate and present courses that fit the students’ learning styles has been developed, implemented, and evaluated, using Moodle as a prototype. Results show that the proposed concept for providing adaptive courses is successful in supporting students in learning.&lt;/p>
&lt;p>By extending LMSs with adaptivity, a learning environment is built that supports teachers as well as learners. In such an adaptive LMS, teachers can continue using the advantages of LMSs and learners can additionally benefit from adaptive courses. This research opens ways for advanced learning systems, which are able to learn the needs and characteristics of learners, respond to them immediately, and provide learners with courses where adaptation is frequently improved and updated to the learners’ needs.&lt;/p>
&lt;p> &lt;/p>
&lt;p>Download the
&lt;a href="https://www.big.tuwien.ac.at/app/uploads/2016/10/Graf_S.pdf" target="_blank" rel="noopener">paper&lt;/a>&lt;/p></description></item><item><title>Formal Verification Techniques in Model Evolution</title><link>https://big.tuwien.ac.at/phd-thesis/archive/formal-verification-techniques-in-model-evolution/</link><pubDate>Tue, 19 May 2020 12:38:14 +0000</pubDate><guid>https://big.tuwien.ac.at/phd-thesis/archive/formal-verification-techniques-in-model-evolution/</guid><description>&lt;p>This work has been finished in July 2015.&lt;/p>
&lt;p>Correctness with respect to its specification is, with varying degree, crucial for all software developed today. Software that is developed following the model based development (MBD) approach is no exception to this observation. Consider a typical MBD workflow: a model is successively altered and refined up to the point when the model is transformed into executable code. Suppose an error has been introduced in the course of the various refinements. Without proper verification techniques this error can propagate through all subsequent refinements and into the executable code. Clearly, this circumstance is undesirable. In this thesis I will thus develop a model checking-based framework for the verification of MBD artifacts that (a) offers a high-degree of automation as compared to existing approaches and (b) allows the user to model the software and write the specification in the same familiy of languages, e.g., the system is modeled using UML and the specification is written in OCL.&lt;/p>
&lt;p> &lt;/p></description></item><item><title>Search-Based Model Transformations</title><link>https://big.tuwien.ac.at/phd-thesis/archive/search-based-model-transformations/</link><pubDate>Tue, 19 May 2020 12:38:14 +0000</pubDate><guid>https://big.tuwien.ac.at/phd-thesis/archive/search-based-model-transformations/</guid><description>&lt;p>This work has been finished in April 2016.&lt;/p>
&lt;p>Model-Driven Engineering (MDE) is a paradigm that promotes the use of models as the central artifacts for solving problems. In MDE, problem domains are specified using domain-specific modeling languages and models are concrete problem instances that abstract from reality to reduce complexity. At the heart of MDE, model transformations are used to systematically manipulate these problem models to find good solutions to the problem at hand. However, reasoning about how the transformation needs to be orchestrated to find good solutions is a non-trivial task due to the large or even infinite transformation space. As a result, this task is either performed automatically, e.g., by following an apply-as-long-as-possible approach, which does not necessarily produce satisfactory results, or it is carried out manually by the respective engineer. This, in turn, hampers the application of MDE techniques on complex problems which usually cannot be solved manually or by enumerating all possible solutions.&lt;/p>
&lt;p>Therefore, we present in this thesis an approach that facilitates to solve these problems by stating clear objectives operationalized through model-based analysis techniques and elevating search-based optimization methods to the model level to find optimal transformation orchestrations. As first contribution, we introduce a model-based analysis approach that measures dynamic, timed properties that consider the contention of resources directly on the model level using the fUML standard. As second contribution, we provide a generic encoding of the transformation orchestration problem on which many different optimization methods can be applied. Using this encoding, we propose an approach that enables to solve problems by providing a model, a set of transformation rules, a set of objectives that are optimized during the process and a set of constraints that mark invalid solutions. The optimization process is configured through a dedicated language which provides information on the optimization concepts and immediate feedback for the concrete configuration. The results consist of the respective orchestrated transformations, the solution models, the objective and constraint values as well as analysis details about the optimization process. Our approach is based on graph transformations and has been implemented as an open-source framework called MOMoT. Based on this implementation, we provide an extensive evaluation of our approach using several case studies from the area of model-driven software engineering as well as two novel problem formulations that tackle the modularization of model transformations and the generic modularization of modeling languages. The obtained evaluation results validate the effectiveness of our approach and give rise to interesting lines of research.&lt;/p>
&lt;p>Abstract and paper may be found in our &lt;a class="external" href="http://publik.tuwien.ac.at/showentry.php?ID=249363&amp;amp;lang=2">publication database&lt;/a>.&lt;/p></description></item><item><title>Conceptual Design of Secure Workflow Systems: An Object-Oriented Approach to the Uniform Modeling of Workflows, Organizations, and Security</title><link>https://big.tuwien.ac.at/phd-thesis/archive/conceptual-design-of-secure-workflow-systems-an-object-oriented-approach-to-the-uniform-modeling-of-workflows-organizations-and-security/</link><pubDate>Tue, 19 May 2020 12:38:13 +0000</pubDate><guid>https://big.tuwien.ac.at/phd-thesis/archive/conceptual-design-of-secure-workflow-systems-an-object-oriented-approach-to-the-uniform-modeling-of-workflows-organizations-and-security/</guid><description>&lt;p>This work has been finished in May 1998.&lt;/p>
&lt;p>The conceptual design of workflow systems comprises the modeling of organizational processes, organization structures, and security requirements. We present a comprehensive, conceptual workflow model that is to be used in early phases of the design of workflow systems that have high demands on security. The workflow model follows a uniform object-oriented approach.&lt;/p>
&lt;p>The processes of organizations need often be adapted to changed requirements in the business environments of organizations. We propose a novel schema architecture for the modeling of organizational processes. The so-called „two-schema architecture“ separates, according to its origin, knowledge on organizational processes into external knowledge, e.g., natural facts and law, and internal knowledge, i.e., organizational commitments. Since organizations have no influence on external knowledge – at least no direct influence -, most adaptions of organizational processes cause only changes to internal knowledge. The „two-schema architecture“ supports to a high degree the reuse of knowledge on organizational processes and eases the adaption of organizational processes to changed requirements in the business environments of organizations.&lt;/p>
&lt;p>The structure of organizations is typically organized around business functions of organizations. The structure of modern organizations is organized around the processes of organizations. As a result, the vertical hierarchy of organizations is flattened. Typically, actors work in network-like groups, which may be easily adapted to changed requirements. We support the modeling of both forms of organization structures, i.e., hierarchies and networks.&lt;/p>
&lt;p>The security requirements of organizational processes say to which actors authorizations can be issued, in which form particular authorizations must be represented (e.g., key cards), and how authorizations that have been issued to actors must be maintained. Basic security requirements for workflow systems are: (1) Accesses of actors that do not possess appropriate authorizations must be denied. (2) Authorizations that are in conflict with the security requirements of organizational processes must not be issued. We specify the security requirements of a workflow system in an authorization schema. A workflow management system can use such an authorization schema as a filter to exclude authorizations that are illegal wrt. the protection requirements of organizational processes from its authorization base.&lt;/p>
&lt;p> &lt;/p></description></item><item><title>Conflict Resolution in Model Versioning</title><link>https://big.tuwien.ac.at/phd-thesis/archive/conflict-resolution-in-model-versioning/</link><pubDate>Tue, 19 May 2020 12:38:13 +0000</pubDate><guid>https://big.tuwien.ac.at/phd-thesis/archive/conflict-resolution-in-model-versioning/</guid><description>&lt;p>This work has been finished in July 2012.&lt;/p>
&lt;p>In most engineering disciplines, models are built as pragmatic, yet precise abstractions of huge systems. The model building process requires multiple people jointly elaborating on artifacts, which are analyzed, used to communicate among stakeholders, and act finally as construction plan for realizing the modeled system. In the field of software engineering, modeling languages such as the &lt;em>Unified Modeling Language&lt;/em> (UML) provide multiple diagrams to describe various viewpoints of a system in a concrete graphical notation. While the code-centric software engineering discipline adopted those models as visual language for describing the system under study, the increasing complexity of modern software systems accompanied by ever shorter time to market constraints has asked for new techniques. The upcoming &lt;em>Model-Driven Engineering&lt;/em> (MDE) approach aims at additionally exploiting models to automatically generate executable code. This paradigm shift lifts models to first-class citizens within the whole engineering process, effectively shaping the primary artifact of change undergoing the collaborative refinement from informal sketches to blueprints. This upgrowth intrinsically demands tool support for managing the models‘ history including merging of parallel evolved models. Optimistic versioning systems, which are already successfully applied for the management of source code, handle both issues. However, applying those systems to models fails due to the models‘ graph-based structure. Consequently, first dedicated model versioning systems emerged. Although current model versioning systems provide decent conflict detection facilities, they (1) ignore the graphical representation of the models, and (2) neglect conflict resolution by totally shifting the responsibility to the user. Yet, the central role of models unifying the human-centric, collaborative abstraction and design process with the computation-centric process of generating executable systems, demands proper mechanisms to foster validity and quality of the merged model.&lt;/p>
&lt;p>In this thesis, we first analyze specifics of model versioning and elaborate on the notion of conflict to improve conflict resolution respecting the central role of models. To cope with the human-centric aspect, we present a conflict aware merge strategy to calculate a tentatively merged &lt;em>conflict diagram&lt;/em> as accelerator for conflict resolution retaining the graphical representation of the model. The conflict diagram unifies non-conflicting changes and materializes merge conflicts in form of annotations, rendering a coherent picture of the model’s evolution. To further support the conflict resolution process, we elaborate on a &lt;em>conflict resolution recommender system&lt;/em> on top of the conflict diagram, which recommends automatically executable conflict resolution patterns. Finally, to satisfy validity conditions of the computation-centric aspect, we establish a &lt;em>formal framework&lt;/em> based on graph transformation theory, to showcase the feasibility of our approach.&lt;/p>
&lt;p>Abstract and paper may be found in our &lt;a class="external" href="http://publik.tuwien.ac.at/showentry.php?ID=208975&amp;amp;lang=2">publication database&lt;/a>.&lt;/p></description></item><item><title>Model integration by virtualization</title><link>https://big.tuwien.ac.at/phd-thesis/archive/model-integration-by-virtualization/</link><pubDate>Tue, 19 May 2020 12:38:13 +0000</pubDate><guid>https://big.tuwien.ac.at/phd-thesis/archive/model-integration-by-virtualization/</guid><description>&lt;p>Model integration has been a recurring problem for several years now and gets even more impact due to the large amount of big, heterogenous model used in today’s industries. Virtualization has been successfully applied to data integration for a long time now and already received some attention in the modeling community, but is typically limited to providing read–only integrated information. Thus, it is proposed to go one step further and use virtualization for more aspects of model integration like synchronization and transformation. Models to be synchronized are de- fined as virtual models over their common and custom parts which might reduce the need of explicit synchronization. This new approach will need a theoretical foundation of virtual models, a new virtualization language, and implementation of this language in a framework and various strategies concerning the handling of virtual models&lt;/p></description></item><item><title>An Architecture Style for Cloud Application Modeling</title><link>https://big.tuwien.ac.at/phd-thesis/archive/an-architecture-style-for-cloud-application-modeling/</link><pubDate>Tue, 19 May 2020 12:38:12 +0000</pubDate><guid>https://big.tuwien.ac.at/phd-thesis/archive/an-architecture-style-for-cloud-application-modeling/</guid><description>&lt;p>UML is a widely adopted open standard to create architectural models from multiple viewpoints for various domains. Its language-inherent extension mechanism is being applied to systematically integrate domain-specific concepts via libraries and profiles because they are indispensable for model-based engineering (MBE). Cloud computing is an appealing target domain for MBE. Modern cloud environments support a relatively high degree of automation in service provisioning, which allows cloud users to dynamically acquire services required for deploying cloud applications. On the other hand, MBE aims at increasing the automation of application development by a systematic tool-supported refinement of high-level models towards a target platform and the environment underneath. The selected platform and environment designate the technical target domain whose concepts have to be captured on the model level in order to enable the refinement of architectural models. Modeling concepts and tools along with a set of constraints on how they can be used denote an architecture style. Providing an architecture style for cloud application modeling based on UML including tools that exploit automated processes of both cloud computing and MBE is thus highly desirable. Due to the generic nature of UML, it does however not provide cloud modeling concepts by default and existing UML tools do not yet adequately support cloud-specific model refinement.&lt;br>
To address these deficiencies, the goal of this thesis is to realize cloud-specific extensions to UML and a toolset that together form an architecture style for developing cloud applications. In particular, we place emphasis on the automation of development processes and their effectiveness in producing truly useful models. Four main contributions are presented to achieve this goal. First we systematically review current cloud modeling languages (CMLs) and investigate major cloud environments to derive a core set of features inherent to the cloud computing domain. They serve as the basis for developing the UML- based cloud application modeling language (CAML), which is the second contribution. CAML supports semi-automatic model refinement towards the Java platform and three major cloud environments via dedicated libraries and profiles. The third contribution addresses the automatic translation of UML architecture models refined by CAML into TOSCA, a recently adopted standard that aims at automating application provisioning and management. Combining UML and TOSCA closes the gap between architecture modeling and application provisioning. As model transformations are key to automate the refinement and translation of model-based artifacts, maintaining those transformations and their produced artifacts is addressed by the fourth contribution. We exploit incremental transformation to co- evolve existing models with changes to transformations. In addition to the conceptual contributions, we provide proof-of-concept implementations as open-source projects and present case studies for evaluating not only their practical relevance but also aspects such as quality and performance.&lt;/p>
&lt;p>Download the
&lt;a href="https://www.big.tuwien.ac.at/app/uploads/2016/09/Diss_Bergmayr.pdf" target="_blank" rel="noopener">paper&lt;/a>&lt;/p></description></item><item><title>Maintaining Consistency of Data on the Web</title><link>https://big.tuwien.ac.at/phd-thesis/archive/maintaining-consistency-of-data-on-the-web/</link><pubDate>Tue, 19 May 2020 12:38:12 +0000</pubDate><guid>https://big.tuwien.ac.at/phd-thesis/archive/maintaining-consistency-of-data-on-the-web/</guid><description>&lt;p>This work has been finished in December 2004.&lt;/p>
&lt;p>Increasingly more data is becoming available on the Web, estimates speaking of 1 billion documents in 2002. Most of the documents are Web pages whose data is considered to be in XML format, expecting it to eventually replace HTML, the current lingua franca of the Web, e.g., by XHTML.&lt;/p>
&lt;p>A common problem in designing and maintaining a Web site is that data on a Web page often replicates or derives from other data, the so-called base data, that is usually not contained in the deriving or replicating page. Two properties of Web sites account for this situation. First, the hypertext structure of a Web site not necessarily coincides with the structure of its underlying conceptual domain model, thus it may be necessary to present a single data item on several pages. Second, the content of pre-generated Web pages is often drawn from legacy systems, usually relational databases. In this case Web pages replicate data items from databases.&lt;/p>
&lt;p>Consequently, replicas and derivations become inconsistent upon modifying base data in a Web page or a relational database. For example, after modifying a product’s price in the database, already pre-generated Web pages offer the product at an out-dated price. Or, after assigning a thesis to a student and modifying the Web page that describes it in detail, the thesis is still incorrectly contained in the list of offered thesis, missing in the list of ongoing thesis, and missing in the advisor’s teaching record.&lt;/p>
&lt;p>The thesis presents a solution by proposing a combined approach that provides for maintaining consistency of data in Web pages that (i) replicate data in relational databases, or (ii) replicate or derive from data in Web pages. Upon modifying base data, the modification is immediately pushed to affected Web pages. There, maintenance is performed incrementally by only modifying the affected part of the page instead of re-generating the whole page from scratch.&lt;/p>
&lt;p>The proposed approach provides for consistent, up-to-date Web pages any time. It is efficient by providing incremental page maintenance techniques, generic by maintaining consistency of XML data in general, flexible by reacting to modifications in Web pages of other businesses, transparent by maintaining a business’ autonomy in managing its data, open by allowing future extensions to be built on top of it, and extensible by enabling the integration of arbitrary legacy systems.&lt;/p>
&lt;p> &lt;/p>
&lt;p>Download the
&lt;a href="https://www.big.tuwien.ac.at/app/uploads/2016/10/Bernauer_M.pdf" target="_blank" rel="noopener">paper&lt;/a>&lt;/p></description></item><item><title>Formal Specification of Distributed Systems - A Discrete Space-Time Logic</title><link>https://big.tuwien.ac.at/phd-thesis/archive/formal-specification-of-distributed-systems-a-discrete-space-time-logic/</link><pubDate>Tue, 19 May 2020 12:38:11 +0000</pubDate><guid>https://big.tuwien.ac.at/phd-thesis/archive/formal-specification-of-distributed-systems-a-discrete-space-time-logic/</guid><description>&lt;p>This work has been finished in April 1995.&lt;/p></description></item><item><title>Optimizing Configuration Data using Prescriptive Analytics</title><link>https://big.tuwien.ac.at/phd-thesis/optimizing-configuration-data-using-prescriptive-analytics/</link><pubDate>Tue, 19 May 2020 12:38:11 +0000</pubDate><guid>https://big.tuwien.ac.at/phd-thesis/optimizing-configuration-data-using-prescriptive-analytics/</guid><description>&lt;p>The dissertation project CODA addresses new, important research questions to combine operation data and configuration models/data for optimization of system configuration (engineering, planning, construction, maintenance) and operation. The results of CODA will be novel analytics methods and algorithms which will be exemplary evaluated for railway automation, but will be applicable to other domains as well. CODA will help Siemens to make rail traffic safer and more efficient, and support a promising young researcher to develop a career in industrial research.&lt;/p></description></item><item><title>A Runtime Model for SysML</title><link>https://big.tuwien.ac.at/phd-thesis/a-runtime-model-for-sysml/</link><pubDate>Tue, 19 May 2020 12:38:10 +0000</pubDate><guid>https://big.tuwien.ac.at/phd-thesis/a-runtime-model-for-sysml/</guid><description>&lt;p>Sabine Wolny ist Dissertantin im Doktorratskolleg CPPS – &lt;a href="https://dc-cpps.tuwien.ac.at/home/" rel="noopener" target="_blank">Doctoral College Cyber-Physical Production Systems&lt;/a>.&lt;/p>
&lt;p>Details ihrer Arbeit finden sich &lt;a href="https://dc-cpps.tuwien.ac.at/dissertation_subjects/modeling_of_cpps/" rel="noopener" target="_blank">hier&lt;/a>.&lt;/p>
&lt;p> &lt;/p></description></item><item><title>Leveraging Industry Standards and Model-Driven Engineering Techniques for Vertical Integration in Smart Manufacturing Environments</title><link>https://big.tuwien.ac.at/phd-thesis/leveraging-industry-standards-and-model-driven-engineering-techniques-for-vertical-integration-in-smart-manufacturing-environments/</link><pubDate>Tue, 19 May 2020 12:38:10 +0000</pubDate><guid>https://big.tuwien.ac.at/phd-thesis/leveraging-industry-standards-and-model-driven-engineering-techniques-for-vertical-integration-in-smart-manufacturing-environments/</guid><description>&lt;p>Smart manufacturing requires deeply integrated IT systems in order to foster flexibility in the setup, re-arrangement and use of attached physical manufacturing systems. In a vertical integration scenario, IT systems of different vendors might be in use and proprietary interfaces need to defined in order to allow the exchange of relevant information from one system to another. A model-driven approach for vertical integration of IT systems is proposed in this work. It is based on the application of industry standards for the representation of hierarchy level specific system properties and an alignment of their key concepts in order to provide bridging functions (transformations) for the conversion of data between the different systems.&lt;/p></description></item><item><title>Leveraging Semantic Web Technologies in Configuration Management</title><link>https://big.tuwien.ac.at/phd-thesis/leveraging-semantic-web-technologies-in-configuration-management/</link><pubDate>Tue, 19 May 2020 12:38:10 +0000</pubDate><guid>https://big.tuwien.ac.at/phd-thesis/leveraging-semantic-web-technologies-in-configuration-management/</guid><description>&lt;p>Although the concept of Semantic Web and Semantic Web technologies (SWT) in particular have been investigated over several years now, they were mainly seen as an interesting research topic having its application domain primarily in the World Wide Web (WWW) rather than be matured enough to be used within a productive environment that might have no direct relation to the WWW at all. With recent developments in the area of Web 3.0 (the Web of Data) including the emerging trends of Big Data and Linked (Open/Closed) Data, SWTs have proven to be able to process and consume large amounts of data, whilst at the same time offering extended reasoning capabilities. Configuration management (CM) on the contrary, deals with software systems in complex technological environments and faces highly complex challenges, such as (i) configuring and incorporating heterogeneous components into complete systems, or (ii) providing elaborated change management for such components. To tackle those challenges, sophisticated solution approaches which utilize available semantic information about components, systems, and the relationships among them are required. The aim of the proposed dissertation is to leverage the use of Semantic Web technologies in configuration management, i.e. address the identified challenges of CM by offering elaborated solutions based on Semantic Web technologies.&lt;/p></description></item><item><title>Concurrent Multi-Viewpoint Building Information modeling (COMBINE)</title><link>https://big.tuwien.ac.at/phd-thesis/concurrent-multi-viewpoint-building-information-modeling-combine/</link><pubDate>Tue, 19 May 2020 12:38:09 +0000</pubDate><guid>https://big.tuwien.ac.at/phd-thesis/concurrent-multi-viewpoint-building-information-modeling-combine/</guid><description>&lt;p>The processes in the Architecture, Engineering and Construction (AEC) and Facility Management (FM) industries are iterative – components are created, revised or discarded. There are many stakeholders with a multitude of domain-specific requirements and tools – for calculation, information visualisation and exchange, using a variety of standards (e.g. DXF, STEP, IFC, COLLADA, XML, etc.). This makes efficient and timely communication critical. The project COMBINE explores some of its requirements, such as selectivity in the communication, domain-specific adaptation to changes as well as monitoring and versioning, with a particular focus on the loss- and corruption-free translation between standards. The challenges this translation has to address are, among others, the rapid development of new technologies and the relatively slow adaptation of the relevant standards, the varying and disparate levels of detail across standards, and the lack of common ontological platform. The project COMIBINE aims to apply the tools of multilevel model driven development in the search for ontological similarities between standards on various meta-levels. It examines the methods of extracting semantics not only from the formal specification but also from the artefacts of a standard. Finally, it examines visualization techniques that enable the understanding and development of complex multilevel modelling hierarchies.&lt;/p></description></item><item><title>Model-Driven Language Modernization</title><link>https://big.tuwien.ac.at/phd-thesis/model-driven-language-modernization/</link><pubDate>Tue, 19 May 2020 12:38:09 +0000</pubDate><guid>https://big.tuwien.ac.at/phd-thesis/model-driven-language-modernization/</guid><description>&lt;p>The introduction of Extensible Markup Language (XML) represented a tremendous leap towards the design of Domain-Specific Languages (DSLs). Although XML-based languages are well adopted and flexible, their generic editors miss modern DSL editor functionality. Additionally, artifacts defined with such languages lack comprehensibility and, therefore, maintainability, because XML has primarily been designed as a machine-processable format with immutable concrete syntax. While there exist techniques to migrate XML-based languages to modeling languages, they are composed of manual steps demanding complex language engineering skills that are usually not part of a domain engineer’s skill set. To tackle these shortcomings, we propose a bridge between XML-based languages and text-based modeling languages. This includes the automated and customizable generation of Xtext-based editors from XML schema definitions (XSDs) providing advanced editor functionality, individualized textual concrete syntax style, and round-trip transformations enabling the exchange of data between the two languages. For the evaluation of the approach, we plan to conduct case studies as well as user studies based on industrial-strength markup languages that will be transformed to textual modeling languages including editors that are intended to be at least as powerful as those manually built for XML-based languages.&lt;/p>
&lt;p>
&lt;a href="https://publik.tuwien.ac.at/showentry.php?ID=251010" target="_blank" rel="noopener">Patrick Neubauer. Towards Model-Driven Software Language Modernization. Joint Proceedings of the Doctoral Symposium and Projects Showcase Held as Part of STAF 2016 co-located with Software Technologies: Applications and Foundations (STAF 2016): 11-20.&lt;/a>&lt;/p></description></item><item><title>A Generic and Generative White-Box Testing Framework for Model Transformations</title><link>https://big.tuwien.ac.at/phd-thesis/a-generic-and-generative-white-box-testing-framework-for-model-transformations/</link><pubDate>Tue, 19 May 2020 12:38:08 +0000</pubDate><guid>https://big.tuwien.ac.at/phd-thesis/a-generic-and-generative-white-box-testing-framework-for-model-transformations/</guid><description>&lt;p>&lt;span style="font-family: 'Calibri',sans-serif; color: black;">The aim of this work is to provide a comprehensive model transformation testing framework supporting all testing phases, ranging from test source model generation to fault localization.&lt;/span>&lt;/p>
&lt;p>&lt;span style="font-family: 'Calibri',sans-serif; color: black;">Test model generation will be done following a white-box approach, leveraging the code of the transformation to achieve better results.&lt;/span>&lt;/p>
&lt;p>&lt;span style="font-family: 'Calibri',sans-serif; color: black;">As the framework is aimed to be generic to any model transformation languages and to any domain-specific language, this opens up challenges such as defining generic coverage criteria.&lt;/span>&lt;/p></description></item><item><title>Web of Needs: An Open Decentralized Web Based Marketplace and Cooperation Infrastructure</title><link>https://big.tuwien.ac.at/phd-thesis/web-of-needs-an-open-decentralized-web-based-marketplace-and-cooperation-infrastructure/</link><pubDate>Tue, 19 May 2020 12:38:08 +0000</pubDate><guid>https://big.tuwien.ac.at/phd-thesis/web-of-needs-an-open-decentralized-web-based-marketplace-and-cooperation-infrastructure/</guid><description/></item></channel></rss>